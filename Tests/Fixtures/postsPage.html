<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US" >
<head>
<title>
Submitted by ScottL - Less Wrong
</title>
<meta name="keywords" content="
rationality, optimal philanthropy, critical thinking, heuristics and biases, skeptic
" />
<meta name="title" content="
Submitted by ScottL - Less Wrong
" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
</head>
<body onclick="close_menus()" class='profile_page'>
<div id="wrapper">
<div id="header" class='lesswrong'>
<a href="http://lesswrong.com/" id="logo" >
</a>
<a id="fhi" href="http://www.fhi.ox.ac.uk/" target="_blank">Future of Humanity Institute</a>
<a id="miri" href="http://intelligence.org/" target="_blank">Machine Intelligence Research Institute</a>
<a id="cfar" href="http://rationality.org/" target="_blank">Center for Applied Rationality</a>
</div><!-- #header -->
<div id="main" class="clear">
<div id="content" class="clear ">
<ul class="clear"
id='nav'>
<li >
<a href="http://lesswrong.com/user/ScottL/" >Profile</a>
&#32;
</li>
<li >
<a href="http://lesswrong.com/user/ScottL/overview/" >Overview</a>
&#32;
</li>
<li >
<a href="http://lesswrong.com/user/ScottL/comments/" >Comments</a>
&#32;
</li>
<li class='active'>
<a href="http://lesswrong.com/user/ScottL/submitted/" >Submitted</a>
&#32;
</li>
</ul>
<div id="siteTable" class="sitetable">
<div id="ajaxHook" class="ajaxhook">
</div>
<div id="thingrow_t3_mxb" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mxb/systems_theory_terms/">
Systems Theory Terms
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mxb'
title="100% positive"
>
14
</span>

</span>
<span class="author">
<a id="author_t3_mxb" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">20 November 2015 12:50PM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mxb" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>Below are some notes that I took while trying to understanding what exactly Systems theory is all about.</p>
<p></p></div>
<a id="read_more_t3_mxb"
onmousedown="setClick(this, 'more')"
class="more click"
href="/lw/mxb/systems_theory_terms/#more"
>
continue reading &raquo;
</a>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mxb/systems_theory_terms/#comments">Comments (27)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mxb' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mr3" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mr3/useful_wiki_and_special_pages/">
Useful Wiki and special pages
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mr3'
title="100% positive"
>
6
</span>

</span>
<span class="author">
<a id="author_t3_mr3" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">13 September 2015 04:33AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mr3" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>This is a list of what I think are the most useful wiki and special pages on less wrong. If you know of any other pages that you think are useful, let me know and I will add them in. After I think enough time has passed, I will add the links below into the FAQ "Stuff to know about" section, if they are not already there.</p>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Sequences">Sequences</a>&#xA0;- provides information on the main sequences</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationality_materials">Rationality Materials</a>&#xA0;- like the sequences page, but also has some links to standalone posts that are worth reading.</li>
<li><a href="/r/all/recentposts/">Unified list of new posts</a> from both main and discussion</li>
<li><a href="http://wiki.lesswrong.com/wiki/Special:PopularPages">Popular pages</a>&#xA0;- most viewed pages (includes wiki pages). You can also click on the "Main" and "Discussion" buttons and there will be a button for <a href="/top/">top scoring main posts</a> and <a href="/r/discussion/top/">top scoring discussion posts</a>. You can also change the filter for the time period (three months, this year, all time etc.). It is also possible to get the&#xA0;top scoring posts from <a href="/r/all/top/">both discussion and main</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Less_Wrong/Article_summaries">Article summaries</a>&#xA0;-&#xA0;&#xA0;contains a list of summaries of the articles on Less Wrong, in chronological order</li>
<li><a href="http://wiki.lesswrong.com/wiki/Less_Wrong_Canon_on_Rationality">Less Wrong Canon on Rationality</a>&#xA0;- short abstracts of most of the topics on less wrong</li>
<li><a href="http://wiki.lesswrong.com/wiki/Special_threads">Special threads</a>&#xA0;- This is a collection of interesting discussion threads that have appeared on Less Wrong.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Categories">Categories</a> - This page contains a list of categories for the pages on the wiki</li>
<li><a href="http://wiki.lesswrong.com/wiki/Jargon">Jargon</a> - This is a short list of common terms and phrases used on LessWrong</li>
<li><a href="http://wiki.lesswrong.com/wiki/FAQ">FAQ page</a>&#xA0;- main FAQ on wiki</li>
<li><a href="http://wiki.lesswrong.com/wiki/User:John_Maxwell_IV/FAQ">John Maxwell IV/FAQ</a>&#xA0;- another FAQ</li>
<li><a href="http://wiki.lesswrong.com/wiki/Comment_formatting">Comment Formatting</a> - information on how to use comment formatting</li>
<li><a href="http://wiki.lesswrong.com/wiki/External_resources">External resources</a> - links to non less wrong resources that may be useful</li>
<li><a href="http://wiki.lesswrong.com/wiki/Open_problems_on_Less_Wrong">Open problems on less wrong</a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups">Less Wrong meetup groups</a>&#xA0;- information on all of the less wrong meetup groups</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationality_power_tools">Rationality power tools</a> - list of computer programs, e.g. anki, that assist with rationality.</li>
</ul>
<ul>
</ul></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mr3/useful_wiki_and_special_pages/#comments">Comments (0)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mr3' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mpg" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mpg/what_exactly_do_we_mean_by_rationality/">
What Exactly Do We Mean By &quot;Rationality&quot;?
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mpg'
title="100% positive"
>
3
</span>

</span>
<span class="author">
<a id="author_t3_mpg" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">11 September 2015 01:16PM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mpg" class="content clear">
<div class="md">
<div itemprop="description">
<div><p align="start">In summary, the goal of this post is to start a discussion on the current meaning of 'rationality' as it is defined on less wrong. I am specifically trying to find out:</p>
<ol>
<li>What people think of the current definition&#xA0;of 'rationality'&#xA0;on less wrong</li>
<li>What people think a better definition of 'rationality' would include. I am not necessarily looking for a perfect definition. I am more looking for a definition that would better highlight the areas that people should look into if they wish to become less wrong.</li>
</ol>
<p align="start">I think that the description below from the <a href="/lw/31/what_do_we_mean_by_rationality/">What Do We Mean By 'Rationality'</a>&#xA0;post sums up the current meaning of 'rationality' as it is used on this site:</p>
<blockquote>
<p align="start"><strong>Epistemic rationality</strong>: believing, and updating on evidence, so as to systematically improve the correspondence between <a style="color: #8a8a8b;" href="http://yudkowsky.net/rational/the-simple-truth">your map and the territory</a>. The art of obtaining beliefs that correspond to reality as closely as possible. This correspondence is commonly termed "truth" or "accuracy", and we're happy to call it that.</p>
<p align="justify"><strong>Instrumental rationality</strong>: achieving your values. <em>Not </em>necessarily "your values" in the sense of being <em>selfish </em>values or <em>unshared</em> values: "your values" means <em>anything you care about</em>. The art of choosing actions that steer the future toward outcomes ranked higher in your preferences. On LW we sometimes refer to this as "winning".</p>
<p align="justify">...</p>
<p align="justify">"X is rational!" is usually just a more strident way of saying "I think X is true" or "I think X is good". So why have an additional word for "rational" as well as "true" and "good"? Because we want to talk about <em>systematic methods </em>for obtaining truth and winning.</p>
<p align="justify">The word "rational" has potential pitfalls, but there are plenty of <em>non</em>-borderline cases where "rational" works fine to <em>communicate</em> what one is getting at, likewise "irrational". In these cases we're not afraid to use it.</p>
</blockquote>
<p align="justify">Now, I think that the definition or description of 'rationality' above is pretty good. In fact, if I wanted to introduce someone to the concept of rationality then I would probably refer to it, but I would explain that it is a working definition. This means that it conveys the general idea and that most of the time this suffices. I have no problems with working definitions. One of my favorite ideas on less wrong is the idea that words and concepts are pointers to areas in concept space. This idea allows you to use working definitions and to not waste your time on semantic issues. But, I think that an often neglected aspect of this idea is that you still need to ensure that the words you use point to the right and restricted areas in concept space. When people say "I am not here to argue about definitions", this does not abdicate their responsibility to create decent definitions. It is like saying: "hey, I know that this definition is not perfect, but I think that it's close enough that it will be able to convey the general idea that I am getting at". If that is all that you are trying to do, then avoiding refining your definitions is fine, but it should be noted that the more important and cited the concept becomes the more neccesary it is to improve the definitions of the concept.</p>
<p align="left">I think the definition of rationality above has two major problems:</p>
<ul>
<li>it doesn't highlight all of the important areas, but it can be extended to cover them. If something is highlighted, then it would mean that it was obvious and clear that you were referring to it. When I think of instrumental rationality, I don't, for example, think of seeing things from multiple perspectives, finding the best way to interpret situations, aligning your values, training creativity etc. (there are probably better examples). The point I am getting at is that Instrumental rationality ("winning") seems to me like it can be expanded to include almost anything, but it doesn't necessarily point to all the important points that I think a more explicit definition of 'rationality' would.</li>
<li>it describes methods to achieve rationality, not what rationality is. The way that 'rationality' is defined is kind of like defining 'fit' by referring to 'exercise' and 'eating right'. This is because Epistemic rationality is only valuable instrumentally. It helps you to create truer beliefs, but these beliefs need to be applied before they can actually be useful. If you spend lots of effort creating truer beliefs or trying to understand what rationality means and then compartmentalize that knowledge, you have effectively gained nothing. An example is <a href="/r/discussion/lw/mnh/robert_aumann_on_judaism/">Robert&#xA0;Aumann</a>, he knows a lot about rationality, but he doesn't seem to be too rational as it looks like he believes in non overlapping magisteria.</li>
</ul>
<p>Perhaps the biggest issue I have with the definition is not anything to do with how it currently is, but instead with how hard it is to improve. This sounds like a good thing, but it's not. The definition is hard to improve, not because it is perfect, but because instrumental rationality is just too big. Any ideas or improvements to the definition that would seem plausible are likely to be quickly discarded as they can be made to fall into the instrumental rationality category.&#xA0;</p>
<p>I am not going to be providing a better definition of 'rationality' as the goal of this post is just to start a discussion, but I do think that a lot of the problems I have mentioned above can be best solved by first choosing a simple core definition of what it means to be rational and then having a seperate myriad of areas in which improvements lead to increases in rationality. In general, the more granularised, results-orientated and verified each of these areas is the better.</p>
<p>A possible parent or base definition for 'rationality' is already on the <a href="http://wiki.lesswrong.com/wiki/Rationality">wiki</a>. It says that 'rationality' is the: "characteristic of thinking and acting optimally". This, to me, seems like a pretty good starting point, although, I do admit that the definition itself is too concise and that it doesn't really tell us much since 'optimal' is also hard to define. &#xA0;</p>
<p>That is not to say that we don't have any idea of what 'optimal' means, we do. It is just that this understanding (logic, probability and decision theory etc.) is mostly related to the normative sense of the word. This is a problem because we are agents with certain limitations and adaptations which make it so that our attempts to do things the normative way are often impractical, cumbersome and flawed. It is for this reason that any definition of 'rationality' should be about more than just: 'get closer to the normative model'. Of course, getting closer to the results of the normative model is always good, but I still think that a decent definition of 'rationality' should take into account, for example, ecological and bounded rationality as well as the values of the agent under consideration.&#xA0;</p>
<ul>
<li>Ecological rationality takes into account the context and representation of information. If a certain representation of information has been recurrent and stable during an agents evolution, then that agents cognitive processes are likely to be better adapted to those representations. There is a big difference between being irrational and performing poorly at specific types of problems because your cognitive processes have not adapted to information in a particular format.&#xA0;</li>
<li>Bounded rationality takes into account the fact that most agents are limited by the information they have, the cognitive limitations of their minds, and the time available for them to make decisions. For limited agents, the fast and frugal heuristical approach to a problem may be what is optimal or at least not as bad as it seems. From,&#xA0;<a href="http://www.ucl.ac.uk/lagnado-lab/publications/harris/Hahn_Harris_L&amp;M2014.pdf">What Does It Mean to be Biased: Motivated Reasoning and Rationality</a></li>
<blockquote>The rather surprising conclusion from a century of research purporting to show humans as poor at judgment and decision making, prone to motivational distortions, and inherently irrational is that it is far from clear to what extent human cognition exhibits systematic bias that comes with a genuine accuracy cost.</blockquote>
<li>It is also important to take into account what the agent values. An alien is not irrational just because it values things differently than we do.</li>
</ul>
<div>It is possible that 'rationality' isn't the best word to be using since there already exists an extremely large number of varied opinions on what it means. I would not be against choosing a different word if this would help to better illuminate what allows people to become less wrong. At the end of day, I don't really care about 'rationality', persay, all I care about is becoming less wrong. If for whatever reason 'rationality' and 'becoming lesswrong' become different or divergent, then I will move away from 'rationality'.</div>
<div><br></div>
<div>
<div>To start of the discussion here are a few questions that I have in regards to the current meaning of 'rationality' on less wrong:</div>
<div><ol>
<li>Do you think that a discussion on the meaning of 'rationality' would be helpful?</li>
<li>Do you have any issues that were not mentioned above with how 'rationality' is currently defined on less wrong?</li>
<li>Do you think that the issues of 'rationality' that I describe above make sense and are valid criticisms.&#xA0;</li>
<li>Do you think that explaining general areas and topics that lead to improvements in rationality would be helpful?</li>
<li>Is there anything you can think of that is related to becoming less wrong and you also think has nothing or very little to do with becoming more rational?</li>
</ol></div>
</div></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mpg/what_exactly_do_we_mean_by_rationality/#comments">Comments (12)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mpg' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mpm" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mpm/rudimentary_categorization_of_less_wrong_topics/">
Rudimentary Categorization of Less Wrong Topics
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mpm'
title="100% positive"
>
19
</span>

</span>
<span class="author">
<a id="author_t3_mpm" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">05 September 2015 07:32AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mpm" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>I find the below list to be useful, so I thought I would post it. This list includes short abstracts of all of the wiki items and a few other topics on less wrong. I grouped the items into some rough categories just to break up the list. I tried to put the right items into the right categories, but there may be some items that can be in multiple categories or that would be better off in a different category. The wiki page from which I got all the items is <a href="http://wiki.lesswrong.com/wiki/Category:Topics">here</a>.</p>
<p>The categories are:</p>
<p>Property Attribution</p>
<ul>
<li><a href="#propertyB">Barriers,biases, fallacies, impediments and problems</a></li>
<li><a href="#propertyT">Techniques/concepts</a></li>
</ul>
<p>Epistemic</p>
<ul>
<li><a href="#epistemicB">Barriers,biases, fallacies, impediments and problems</a></li>
<li><a href="#epistemicT">Techniques/concepts</a></li>
</ul>
<p>Instrumental</p>
<ul>
<li><a href="#instrumentalB">Barriers,biases, fallacies, impediments and problems</a></li>
<li><a href="#instrumentalT">Techniques/concepts</a></li>
</ul>
<p><a href="#positions">Positions</a></p>
<h1>Property Attribution</h1>
<h2><a name="propertyB"></a>Barriers, biases, fallacies, impediments and problems</h2>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Affective_death_spiral"><span style="text-decoration: underline;">Affective death spiral</span></a> - positive attributes of a theory, person, or organization combine with the <a href="http://wiki.lesswrong.com/wiki/Halo_effect">Halo effect</a> in a feedback loop, resulting in the subject of the affective death spiral being held in higher and higher regard.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Anthropomorphism"><span style="text-decoration: underline;">Anthropomorphism</span></a> - the error of attributing distinctly human characteristics to nonhuman processes.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bystander_effect"><span style="text-decoration: underline;">Bystander effect</span></a> - a social psychological phenomenon in which individuals are less likely to offer help in an emergency situation when other people are present.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Connotation"><span style="text-decoration: underline;">Connotation</span></a> - emotional association with a word. You need to be careful that you are not conveying different connotation, then you mean to.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Correspondence_bias"><span style="text-decoration: underline;">Correspondence bias</span></a> (also known as the fundamental attribution error) - is the tendency to overestimate the contribution of lasting traits and dispositions in determining people's behavior, as compared to situational effects.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Death_Spirals_and_the_Cult_Attractor"><span style="text-decoration: underline;">Death Spirals and the Cult Attractor</span></a> - Cultishness is an empirical attractor in human groups, roughly an affective death spiral, plus peer pressure and outcasting behavior, plus (quite often) defensiveness around something believed to have been perfected</li>
<li><a href="http://wiki.lesswrong.com/wiki/Detached_lever_fallacy"><span style="text-decoration: underline;">Detached lever fallacy</span></a> &#x2013;the assumption that something simple for one system will be simple for others. This assumption neglects to take into account that something may only be simple because of complicated underlying machinery which is triggered by a simple action like pulling a lever. Adding this lever to something else won&#x2019;t allow the action to occur because the underlying complicated machinery is not there.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Giant_cheesecake_fallacy"><span style="text-decoration: underline;">Giant cheesecake fallacy</span></a>- occurs when an argument leaps directly from capability to actuality, without considering the necessary intermediate of motive. An example of the fallacy might be: a sufficiently powerful Artificial Intelligence could overwhelm any human resistance and wipe out humanity. (Belief without evidence: the AI would decide to do so.) Therefore we should not build AI.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Halo_effect"><span style="text-decoration: underline;">Halo effect</span></a> &#x2013; specific type of <a href="https://en.wikipedia.org/wiki/Confirmation_bias">confirmation bias</a>, wherein positive feelings in one area cause ambiguous or neutral traits to be viewed positively.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Illusion_of_transparency"><span style="text-decoration: underline;">Illusion of transparency</span></a> - misleading impression that your words convey more to others than they really do.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Inferential_distance"><span style="text-decoration: underline;">Inferential distance</span></a> - a gap between the background knowledge and epistemology of a person trying to explain an idea, and the background knowledge and epistemology of the person trying to understand it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Information_cascade">Information cascade</a>&#xA0;- occurs when people signal that they have information about something, but actually based their judgment on other people's signals, resulting in a self-reinforcing community opinion that does not necessarily reflect reality.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Mind_projection_fallacy">Mind projection fallacy</a></span> - occurs when someone thinks that the way they see the world reflects the way the world really is, going as far as assuming the real existence of imagined objects.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Other-optimizing"><span style="text-decoration: underline;">Other-optimizing</span></a> - a failure mode in which a person vastly overestimates their ability to optimize someone else's life, usually as a result of underestimating the differences between themselves and others, for example through the <a href="http://wiki.lesswrong.com/wiki/Typical_mind_fallacy">typical mind fallacy</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Peak-end_rule"><span style="text-decoration: underline;">Peak-end rule</span></a> - we do not judge our experiences on the net pleasantness of unpleasantness or on how long the experience lasted, but instead on how they were at their peak (pleasant or unpleasant) and how they ended.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Stereotype"><span style="text-decoration: underline;">Stereotype</span></a> - a fixed, over generalized belief about a particular group or class of people.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Typical_mind_fallacy"><span style="text-decoration: underline;">Typical mind fallacy</span></a> - the mistake of making biased and overconfident conclusions about other people's experience based on your own personal experience; the mistake of assuming that other people are more like you than they actually are.</li>
</ul>
<h2><a name="propertyT"></a>Techniques/Concepts</h2>
<ul>
<li><a href="/lw/4h/when_truth_isnt_enough/">ADBOC</a> - Agree Denotationally, But Object Connotatively</li>
<li><a href="http://wiki.lesswrong.com/wiki/Alien_values">Alien Values</a> - There are no rules requiring minds to value life, liberty or the pursuit of happiness. An alien will have, in all probability, alien values. If an "alien" isn't evolved, the <a href="http://wiki.lesswrong.com/wiki/Mind_design_space">range of possible values</a> increases even more, allowing such <a href="http://wiki.lesswrong.com/wiki/Absurdity_heuristic">absurdities</a> as a <a href="http://wiki.lesswrong.com/wiki/Paperclip_maximizer">Paperclip maximizer</a>. Creatures with alien values might as well value <em>only</em> non-sentient life, or they might spend all their time building <a href="/lw/sy/sorting_pebbles_into_correct_heaps/">heaps of prime numbers of rocks</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Chronophone"><span style="text-decoration: underline;">Chronophone</span></a> &#x2013; is a parable that is meant to convey the idea that it&#x2019;s really hard to get somewhere when you don't already know your destination. If there were some simple cognitive policy you could follow to spark moral and technological revolutions, without your home culture having advance knowledge of the destination, you could execute that cognitive policy today.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Empathic_inference"><span style="text-decoration: underline;">Empathic inference</span></a> &#x2013; is every-day common mind-reading. It&#x2019;s an inference made about other person&#x2019;s mental states using your own brain as reference, by making your brain feel or think in the same way as the other person you can emulate their mental state and predict their reactions.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Epistemic_luck">Epistemic luck</a>&#xA0;- you would have different beliefs if certain events in your life were different. How should you react to this fact?</li>
<li><a href="http://wiki.lesswrong.com/wiki/Future">Future</a>&#xA0;- If it hasn't happened yet but is going to, then it's part of the future. Checking whether or not something is going to happen is notoriously difficult. Luckily, the field of&#xA0;<a href="http://wiki.lesswrong.com/wiki/Heuristics_and_biases">heuristics and biases</a>&#xA0;has given us some insights into what can go wrong. Namely, one problem is that the future elicits&#xA0;<a href="http://wiki.lesswrong.com/wiki/Near/far_thinking">far mode</a>, which isn't about truth-seeking or gritty details.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Mental_models">Mental models</a>&#xA0;- a hypothetical form of representation of knowledge in human mind. Mental models form to approximately describe dynamics of observed situations, and reuse parts of existing models to represent novel situations</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Mind_design_space">Mind design space</a></span> - refers to the <a href="http://wiki.lesswrong.com/wiki/Configuration_space">configuration space</a> of possible minds. As humans living in a human world, we can safely make all sorts of assumptions about the minds around us without even realizing it. Each human might have their own unique personal qualities, so it might naively seem that there's nothing you can say about people you <a href="http://wiki.lesswrong.com/wiki/I_don%27t_know">don't know</a>. But there's actually quite a lot you can say (with high or very high probability) about a random human: that they have <a href="http://wiki.lesswrong.com/wiki/Human_universal">standard</a> emotions like happiness, sadness, and anger; standard senses like sight, vision, and hearing; that they speak a language; and no doubt any number of other subtle features that are even harder to <a href="http://wiki.lesswrong.com/wiki/Inferential_distance">quickly explain in words</a>. These things are the specific results of <a href="http://wiki.lesswrong.com/wiki/Evolutionary_psychology">adaptation pressures in the ancestral environment</a> and can't be expected to be shared by a random alien or <a href="http://wiki.lesswrong.com/wiki/Artificial_general_intelligence">AI</a>. That is, humans are packed into a tiny dot in the configuration space: there is vast range over of other ways a mind can be.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Near/far_thinking"><span style="text-decoration: underline;">Near/far thinking</span></a> - Near and far are two modes (or a spectrum of modes) in which we can think about things. We choose which mode to think about something is based on its distance from us, or on the level of detail we need. This property of human mind is studied in <a href="http://www.psych-it.com.au/Psychlopedia/article.asp?id=79"><span style="text-decoration: underline;">construal level theory</span></a>. <ul>
<li>NEAR: All of these bring each other more to mind: here, now, me, us; trend-deviating likely real local events; concrete, context-dependent, unstructured, detailed, goal-irrelevant incidental features; feasible safe acts; secondary local concerns; socially close folks with unstable traits.</li>
<li>FAR: Conversely, all these bring each other more to mind: there, then, them; trend-following unlikely hypothetical global events; abstract, schematic, context-freer, core, coarse, goal-related features; desirable risk-taking acts, central global symbolic concerns, confident predictions, polarized evaluations, socially distant people with stable traits</li>
</ul>
</li>
<li><a href="http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics"><span style="text-decoration: underline;">No-Nonsense </span><span style="text-decoration: underline;">Metaethics</span></a> - A <a href="http://wiki.lesswrong.com/wiki/Sequence">sequence</a> by <a href="/user/lukeprog/">lukeprog</a> that explains and defends a naturalistic approach to metaethics and what he calls <a href="/lw/5u2/pluralistic_moral_reductionism/">pluralistic moral reductionism</a>. We know that people can mean different things, but use the same word, e.g. sound can mean auditory experience or acoustic vibrations in the air. Pluralistic moral reductionism is the idea that we do the same thing when we talk about what it moral.</li>
<li><a href="/lw/lk/superhero_bias/">Only the vulnerable are heroes</a> - &#x201C;Vulnerability is our most accurate measurement of courage.&#x201D; &#x2013; <a href="http://brenebrown.com/">Bren&#xE9; Brown</a> To be as heroic as a man stopping a group of would-be thieves from robbing a store. Superman has to be defending the world from someone powerful enough to harm and possibly even kill him, such as <a href="http://en.wikipedia.org/wiki/Darkseid">Darkseid</a>.</li>
</ul>
<h1>Epistemic</h1>
<h2><a name="epistemicB"></a>Barriers, biases, fallacies, impediments and problems</h2>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Absurdity_heuristic"><span style="text-decoration: underline;">Absurdity heuristic</span></a> &#x2013; is a mental shortcut where highly untypical situations are classified as absurd or <a href="http://wiki.lesswrong.com/wiki/Antiprediction">impossible</a>. Where you don't expect intuition to construct an <a href="http://wiki.lesswrong.com/wiki/Technical_explanation">adequate model</a> of reality, classifying an idea as impossible may be <a href="http://wiki.lesswrong.com/wiki/Overconfidence">overconfident</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Affect_heuristic"><span style="text-decoration: underline;">Affect heuristic</span></a> - a mental shortcut that makes use of current <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> to make decisions and solve problems quickly and efficiently.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Arguing_by_analogy"><span style="text-decoration: underline;">Arguing by analogy</span></a> &#x2013; is arguing that since things are alike in some ways, they will probably be alike in others. While careful application of argument by analogy can be a powerful tool, there are limits to the method after which it breaks down.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Arguing_by_definition"><span style="text-decoration: underline;">Arguing by definition</span></a> &#x2013; is arguing that something is part of a class because it fits the definition of that class. It is recommended to avoid this wherever possible and instead treat words as labels that cannot capture the <a href="http://wiki.lesswrong.com/wiki/Detached_lever_fallacy">rich cognitive content</a> that actually constitutes its meaning. As Feynman said: &#x201C;You can know the name of a bird in all the languages of the world, but when you're finished, you'll know absolutely nothing whatever about the bird... So let's look at the bird and see what it's doing -- that's what counts.&#x201D; It is better to keep the focus on the facts of the matter and try to understand what your interlocutor is trying to communicate, then to get lost in a pointless discussion of definitions, bearing nothing.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Arguments_as_soldiers"><span style="text-decoration: underline;">Arguments as soldiers</span></a> &#x2013; is a problematic scenario where arguments are treated like war or battle. Arguments get treated as soldiers, weapons to be used to defend your <a href="http://wiki.lesswrong.com/wiki/Color_politics">side</a> of the debate, and to attack the other side. They are no longer instruments of the <a href="http://wiki.lesswrong.com/wiki/Truth">truth</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Availability_heuristic"><span style="text-decoration: underline;">Availability heuristic</span></a> &#x2013; a mental shortcut that treats easily recalled information as important or at least more important than alternative solutions which are not as readily recalled</li>
<li><a href="/lw/i6/professing_and_cheering/">Belief as cheering</a>&#xA0;- People can bind themselves as a group by believing "crazy" things together. Then among outsiders they could show the same pride in their crazy belief as they would show wearing "crazy" group clothes among outsiders. The belief is more like a banner saying "<a href="/lw/gt/a_fable_of_science_and_politics/">GO BLUES</a>". It isn't a statement of fact, or an attempt to persuade; it doesn't have to be convincing&#x2014;it's a cheer.</li>
<li><a href="/lw/od/37_ways_that_words_can_be_wrong/29or">Beware of Deepities</a>&#xA0;- A deepity is a proposition that seems both important and true&#x2014;and profound&#x2014;but that achieves this effect by being ambiguous. An example is "love is a word". One interpretation is that &#x201C;love&#x201D;, the word, is a word and this is trivially true. The second interpretation is that love is nothing more than a verbal construct. This interpretation is false, but if it were true would be profound. The "deepity" seems profound due to a conflation of the two interpretations. People see the trivial but true interpretation and then think that there must be some kind of truth to the false but profound one.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Bias">Bias</a></span> - is a systematic deviation from <a href="http://wiki.lesswrong.com/wiki/Rationality">rationality</a> committed by our cognition. They are specific, predictable error patterns in the human mind.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Burdensome_details"><span style="text-decoration: underline;">Burdensome details</span></a> - Adding more details to a theory may make it sound more plausible to human ears because of the <a href="http://wiki.lesswrong.com/wiki/Representativeness_heuristic">representativeness heuristic</a>, even as the story becomes normatively less probable, as burdensome details drive the probability of the conjunction down (this is known as <a href="http://wiki.lesswrong.com/wiki/Conjunction_fallacy">conjunction fallacy</a>). Any detail you add has to be pinned down by a sufficient amount of evidence; all the details you make no claim about can be summed over.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Compartmentalization"><span style="text-decoration: underline;">Compartmentalization</span></a> - a tendency to restrict application of a generally-applicable skill, such as scientific method, only to select few contexts. More generally, the concept refers to not following a piece of knowledge to its logical conclusion, or not taking it seriously.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Conformity_bias"><span style="text-decoration: underline;">Conformity bias</span></a> - a tendency to behave similarly to the others in a group, even if doing so goes against your own judgment.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Conjunction_fallacy"><span style="text-decoration: underline;">Conjunction fallacy</span></a> &#x2013; involves the assumption that specific conditions are more probable than more general ones.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Contagion_heuristic"><span style="text-decoration: underline;">Contagion heuristic</span></a> - leads people to avoid contact with people or objects viewed as "contaminated" by previous contact with someone or something viewed as bad&#x2014;or, less often, to seek contact with objects that have been in contact with people or things considered good.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Costs_of_rationality"><span style="text-decoration: underline;">Costs of rationality</span></a> - Becoming more <a href="http://wiki.lesswrong.com/wiki/Rationality#Epistemic_rationality">epistemically rational</a> can only guarantee one thing: what you believe will include more of the <a href="http://wiki.lesswrong.com/wiki/Truth">truth</a>. Knowing that truth might <a href="http://wiki.lesswrong.com/wiki/Instrumental_rationality">help you achieve your goals</a>, or cause you to become a pariah. Be sure that you really want to know the truth before you commit to finding it; otherwise, you may flinch from it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Defensibility"><span style="text-decoration: underline;">Defensibility</span></a> - arguing that a policy is defensible rather than optimal or that it has some benefit compared to the null action rather than the best benefit of any action.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Fake_simplicity"><span style="text-decoration: underline;">Fake simplicity</span></a> &#x2013; if you have a simple answer to a complex problem then it is probably a case whereby your beliefs appear to match the evidence much more strongly than they actually do. &#x201C;Explanations exist; they have existed for all time; there is always a well-known solution to every human problem &#x2014; neat, plausible, and wrong.&#x201D; &#x2014;H. L. Mencken</li>
<li><a href="http://wiki.lesswrong.com/wiki/Fallacy_of_gray"><span style="text-decoration: underline;">Fallacy of gray</span></a> also known as Continuum fallacy &#x2013;is the false belief that because nothing is <a href="http://wiki.lesswrong.com/wiki/Absolute_certainty">certain</a>, everything is equally uncertain. It does not take into account that some things are more certain than others.</li>
<li><a href="http://wiki.lesswrong.com/wiki/False_dilemma">False dilemma</a>&#xA0;- occurs when only two options are considered, when there may in fact be many.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Filtered_evidence">Filtered evidence</a></span> &#x2013; is <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> that was selected for the purpose of proving (disproving) a hypothesis. Filtered evidence may be highly misleading, but can still be useful, if considered with care.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Generalization_from_fictional_evidence"><span style="text-decoration: underline;">Generalization from fictional evidence</span></a> &#x2013; logical fallacy that consists of drawing real-world conclusions based on statements invented and selected for the purpose of writing fiction.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Groupthink"><span style="text-decoration: underline;">Groupthink</span></a> - tendency of humans to tend to agree with each other, and hold back objections or dissent even when the group is wrong.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Hindsight_bias"><span style="text-decoration: underline;">Hindsight bias</span></a> &#x2013; is the tendency to overestimate the foreseeability of events that have actually happened.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Information_hazard">Information hazard</a>&#xA0;&#x2013; is a risk that arises from the dissemination or the potential dissemination of (true) information that may cause harm or enable some agent to cause harm.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/In-group_bias">In-group bias</a></span> - preferential treatment of people and ideas associated with your own group.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Mind-killer"><span style="text-decoration: underline;">Mind-killer</span></a> - a name given to topics (such as <a href="http://wiki.lesswrong.com/wiki/Color_politics">politics</a>) that tend to produce extremely <a href="http://wiki.lesswrong.com/wiki/Bias">biased</a> discussions. Another cause of mind-killers is social taboo. Negative <a href="http://wiki.lesswrong.com/wiki/Connotation">connotations</a> are associated with some topics, thus creating a strong bias supported by <a href="http://wiki.lesswrong.com/wiki/Signaling">signaling</a> drives that makes non-negative characterization of these topics appear <a href="http://wiki.lesswrong.com/wiki/Absurdity_heuristic">absurd</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Motivated_cognition"><span style="text-decoration: underline;">Motivated cognition</span></a> &#x2013; is the unconscious tendency of individuals to fit their processing of information to conclusions that suit some end or goal.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Motivated_skepticism"><span style="text-decoration: underline;">Motivated </span><span style="text-decoration: underline;">skepticism</span></a> also known as <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Disconfirmation_bias&amp;action=edit&amp;redlink=1">disconfirmation bias</a> - the mistake of applying more skepticism to claims that you don't like (or intuitively disbelieve), than to claims that you do like</li>
<li><a href="http://wiki.lesswrong.com/wiki/Narrative_fallacy"><span style="text-decoration: underline;">Narrative fallacy</span></a> &#x2013; is a vulnerability to over interpretation and our predilection for compact stories over raw truths.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Overconfidence"><span style="text-decoration: underline;">Overconfidence</span></a> - the state of being more certain than is justified, given your <a href="http://wiki.lesswrong.com/wiki/Priors">priors</a> and the <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> available.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Planning_fallacy"><span style="text-decoration: underline;">Planning fallacy</span></a> - predictions about how much time will be needed to complete a future task display an optimistic bias (underestimate the time needed).</li>
<li><a href="http://wiki.lesswrong.com/wiki/Politics_is_the_Mind-Killer"><span style="text-decoration: underline;">Politics is the Mind-Killer</span></a> &#x2013; Politics is not a good area for rational debate. It is often about status and power plays where arguments are soldiers rather than tools to get closer to the truth.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Positive_bias"><span style="text-decoration: underline;">Positive bias</span></a> - tendency to test hypotheses with positive rather than negative examples, thus risking to miss obvious disconfirming tests.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Priming"><span style="text-decoration: underline;">Priming</span></a> - psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Privileging_the_hypothesis"><span style="text-decoration: underline;">Privileging the hypothesis</span></a> &#x2013; is <a href="http://wiki.lesswrong.com/wiki/Locate_the_hypothesis">singling out a particular hypothesis for attention</a> when there is insufficient <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> already in hand to justify such special attention.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Problem_of_verifying_rationality">Problem of verifying rationality</a>&#xA0;&#x2013; is the single largest problem for those desiring to create methods of systematically training for increased epistemic and instrumental&#xA0;<a href="http://wiki.lesswrong.com/wiki/Rationality">rationality</a>&#xA0;- how to verify that the training actually worked.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Rationalization">Rationalization</a></span> &#x2013; starts from a conclusion, and then works backward to arrive at arguments apparently favouring that conclusion. Rationalization argues for a side already selected. The term is misleading as it is the very opposite and antithesis of rationality, as if lying were called "truthization".</li>
<li><a href="/lw/18b/reason_as_memetic_immune_disorder/">Reason as memetic immune disorder</a>.- is problem that when you are rational you deem your conclusions more valuable than those of non-rational people. This can end up being a problem as you are less likely to update your beliefs when they are opposed. This adds the risk that if you make a one false belief and then rationally deduce a plethora of others from it you will be less likely to update any erronous conclusions.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Representativeness_heuristic"><span style="text-decoration: underline;">Representativeness heuristic</span></a> &#x2013;a mental shortcut where people judge the probability or frequency of a hypothesis by considering how much the hypothesis resembles available data as opposed to using a Bayesian calculation.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Scales_of_justice_fallacy"><span style="text-decoration: underline;">Scales of justice fallacy</span></a> - the error of using a simple polarized scheme for deciding a complex issue: each piece of evidence about the question is individually categorized as <a href="http://wiki.lesswrong.com/wiki/Arguments_as_soldiers">supporting exactly one</a> of the two opposing positions.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Scope_insensitivity"><span style="text-decoration: underline;">Scope insensitivity</span></a> &#x2013; a phenomenon related to the representativeness heuristic where subjects based their willingness-to-pay mostly on a mental image rather than the effect on a desired outcome. An environmental measure that will save 200,000 birds doesn't conjure anywhere near a hundred times the emotional impact and willingness-to-pay of a measure that would save 2,000 birds, even though in fact the former measure is two orders of magnitude more effective.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Self-deception"><span style="text-decoration: underline;">Self-deception</span></a> - state of preserving a wrong <a href="http://wiki.lesswrong.com/wiki/Belief">belief</a>, often facilitated by denying or <a href="http://wiki.lesswrong.com/wiki/Rationalization">rationalizing away</a> the relevance, significance, or importance of opposing <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> and logical arguments.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Status_quo_bias"><span style="text-decoration: underline;">Status quo bias</span></a> - people tend to avoid changing the established behavior or beliefs unless the pressure to change is sufficiently strong.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Sunk_cost_fallacy"><span style="text-decoration: underline;">Sunk cost fallacy</span></a> - Letting past investment (of time, energy, money, or any other resource) interfere with decision-making in the present in deleterious ways.</li>
<li><a href="http://wiki.lesswrong.com/wiki/The_top_1%25_fallacy"><span style="text-decoration: underline;">The top 1% fallacy</span></a> - related to not taking into account the idea that a small sample size is not always reflective of a whole population and that sample populations with certain characteristics, e.g. made up of repeat job seekers, are not reflective of the whole population.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Underconfidence"><span style="text-decoration: underline;">Underconfidence</span></a> - the state of being more uncertain than is justified, given your <a href="http://wiki.lesswrong.com/wiki/Prior">priors</a> and the evidence you are aware of.</li>
<li><a href="/lw/og/wrong_questions/">Wrong Questions</a> - A question about your map that wouldn&#x2019;t make sense if you had a more accurate map.</li>
</ul>
<h2><a name="epistemicT"></a>Techniques/Concepts</h2>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Absolute_certainty"><span style="text-decoration: underline;">Absolute certainty</span></a> &#x2013; equivalent of <a href="http://wiki.lesswrong.com/wiki/Bayesian_probability">Bayesian probability</a> of 1. Losing an epistemic bet made with absolute certainty corresponds to receiving infinite negative payoff, according to the logarithmic <a href="http://wiki.lesswrong.com/wiki/Scoring_rule">proper scoring rule</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Adaptation_executors"><span style="text-decoration: underline;">Adaptation executors</span></a> - Individual organisms are best thought of as adaptation-executers rather than as fitness-maximizers. Our taste buds do not find lettuce delicious and cheeseburgers distasteful once we are fed a diet too high in calories and too low in micronutrients. Tastebuds are adapted to an ancestral environment in which calories, not micronutrients, were the limiting factor. Evolution operates on <a href="http://wiki.lesswrong.com/wiki/Slowness_of_evolution">too slow a timescale</a> to re-adapt to adapt to a new conditions (such as a diet).</li>
<li><a href="http://wiki.lesswrong.com/wiki/Adversarial_process"><span style="text-decoration: underline;">Adversarial process</span></a> - a form of <a href="http://wiki.lesswrong.com/wiki/Truth">truth</a>-seeking or conflict resolution in which identifiable <a href="http://wiki.lesswrong.com/wiki/Faction">factions</a> hold one-sided positions.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Altruism"><span style="text-decoration: underline;">Altruism</span></a> - Actions undertaken for the benefit of other people. If you do something to feel good about helping people, or even to be a better person in some spiritual sense, it isn't truly altruism.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Amount_of_evidence"><span style="text-decoration: underline;">Amount of evidence</span></a> - to a Bayesian, evidence is a quantitative concept. The more complicated or a priori improbable a hypothesis is, the more evidence you need just to justify it, or even just <a href="http://wiki.lesswrong.com/wiki/Locate_the_hypothesis">single it out</a> of the amongst the mass of competing theories.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Anti-epistemology"><span style="text-decoration: underline;">Anti-epistemology</span></a>- is bad explicit beliefs about rules of reasoning, usually developed in the course of protecting an existing false belief - false beliefs are opposed not only by true beliefs (that must then be obscured in turn) but also by good rules of systematic reasoning (which must then be denied). The explicit defense of fallacy as a general rule of reasoning is anti-epistemology.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Antiprediction"><span style="text-decoration: underline;">Antiprediction</span></a> - is a statement of confidence in an event that sounds startling, but actually isn't far from a maxentropy <a href="http://wiki.lesswrong.com/wiki/Prior">prior</a>. For example, if someone thinks that our state of knowledge implies strong ignorance about the speed of some process X on a logarithmic scale from nanoseconds to centuries, they may make the startling-sounding statement that X is very unlikely to take 'one to three years'.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Applause_light"><span style="text-decoration: underline;">Applause light</span></a> - is an empty statement which evokes positive affect without providing new information</li>
<li><a href="http://wiki.lesswrong.com/wiki/Artificial_general_intelligence"><span style="text-decoration: underline;">Artificial general intelligence</span></a> &#x2013; is a machine capable of behaving intelligently over many domains.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian"><span style="text-decoration: underline;">Bayesian</span></a> - Bayesian <a href="http://wiki.lesswrong.com/wiki/Probability_theory">probability theory</a> is the math of <a href="http://wiki.lesswrong.com/wiki/Epistemic_rationality">epistemic rationality</a>, Bayesian <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a> is the math of <a href="http://wiki.lesswrong.com/wiki/Instrumental_rationality">instrumental rationality</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Aumann%27s_agreement_theorem"><span style="text-decoration: underline;">Aumann's</span><span style="text-decoration: underline;">&#xA0;agreement theorem</span></a>&#xA0;&#x2013; roughly speaking, says that two agents acting rationally (in a certain precise sense) and with&#xA0;<a href="http://wiki.lesswrong.com/wiki/Common_knowledge">common knowledge</a>&#xA0;of each other's beliefs cannot agree to disagree. More specifically, if two people are genuine&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bayesian">Bayesians</a>, share common&#xA0;<a href="http://wiki.lesswrong.com/wiki/Priors">priors</a>, and have common knowledge of each other's current probability assignments, then they must have equal probability assignments.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian_decision_theory"><span style="text-decoration: underline;">Bayesian decision theory</span></a> &#x2013; is a <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a> which is informed by <a href="http://wiki.lesswrong.com/wiki/Bayesian_probability">Bayesian probability</a>. It is a statistical system that tries to quantify the tradeoff between various decisions, making use of probabilities and costs.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian_probability"><span style="text-decoration: underline;">Bayesian probability</span></a> - represents a level of certainty relating to a potential outcome or idea. This is in contrast to a <a href="http://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> probability that represents the frequency with which a particular outcome will occur over any number of trials. An <a href="http://en.wikipedia.org/wiki/Event_(probability_theory)">event</a> with Bayesian probability of .6 (or 60%) should be interpreted as stating "With confidence 60%, this event contains the true outcome", whereas a frequentist interpretation would view it as stating "Over 100 trials, we should observe event X approximately 60 times." The difference is more apparent when discussing ideas. A frequentist will not assign probability to an idea; either it is true or false and it cannot be true 6 times out of 10.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayes%27_theorem"><span style="text-decoration: underline;">Bayes</span><span style="text-decoration: underline;">' theorem</span></a>&#xA0;- A law of probability that describes the proper way to incorporate new&#xA0;<a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a>&#xA0;into&#xA0;<a href="http://wiki.lesswrong.com/wiki/Prior_probabilities">prior probabilities</a>&#xA0;to form an&#xA0;<a href="http://wiki.lesswrong.com/wiki/Belief_update">updated</a>&#xA0;probability estimate.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Belief"><span style="text-decoration: underline;">Belief</span></a> - the mental state in which an individual holds a proposition to be true. Beliefs are often metaphorically referred to as maps, and are considered valid to the extent that they correctly correspond to the <a href="http://wiki.lesswrong.com/wiki/Truth">truth</a>. A person's knowledge is a subset of their beliefs, namely the beliefs that are also true and justified. Beliefs can be second-order, concerning propositions about other beliefs.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Belief_as_attire"><span style="text-decoration: underline;">Belief as attire</span></a> &#x2013; is a example of an <a href="http://wiki.lesswrong.com/wiki/Improper_belief">improper belief</a> promoted by identification with a group or other <a href="http://wiki.lesswrong.com/wiki/Signaling">signaling</a> concerns, not by how well it reflects the <a href="http://wiki.lesswrong.com/wiki/Territory">territory</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Belief_in_belief"><span style="text-decoration: underline;">Belief in belief</span></a> - Where it is difficult to believe a thing, it is often much easier to believe that you ought to believe it. Were you to <a href="http://wiki.lesswrong.com/wiki/Bite_the_bullet">really believe</a> and not just believe in belief, the consequences of error would be much more severe. When someone makes up excuses in advance, it would seem to require that belief, and belief in belief, have become unsynchronized.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Belief_update"><span style="text-decoration: underline;">Belief update</span></a> - what you do to your beliefs, opinions and cognitive structure when new <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> comes along.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bite_the_bullet"><span style="text-decoration: underline;">Bite the bullet</span></a> - is to accept the consequences of a hard choice, or unintuitive conclusions of a formal reasoning procedure.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Black_swan"><span style="text-decoration: underline;">Black swan</span></a> &#x2013; is a high-impact event that is hard to predict (but not necessarily of low probability). It is also an event that is not accounted for in a model and therefore causes the model to break down when it occurs.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Cached_thought"><span style="text-decoration: underline;">Cached thought</span></a> &#x2013; is an answer that was arrived at by recalling a previously-computed conclusion, rather than performing the reasoning from scratch.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Causal_Decision_Theory"><span style="text-decoration: underline;">Causal Decision Theory</span></a> &#x2013; a branch of <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a> which advises an agent to take actions that maximizes the causal consequences on the probability of desired outcomes</li>
<li><a href="http://wiki.lesswrong.com/wiki/Causality"><span style="text-decoration: underline;">Causality</span></a> - refers to the relationship between an event (the cause) and a second event (the effect), where the second event is a direct consequence of the first.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Church-Turing_thesis"><span style="text-decoration: underline;">Church-Turing thesis</span></a> - states the equivalence between the mathematical concepts of algorithm or computation and Turing-Machine. It asserts that if some calculation is effectively carried out by an algorithm, then there exists a Turing machines which will compute that calculation.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Coherent_Aggregated_Volition"><span style="text-decoration: underline;">Coherent Aggregated Volition</span></a> - is one of <a href="http://wiki.lesswrong.com/wiki/Ben_Goertzel">Ben Goertzel</a>'s responses to <a href="http://wiki.lesswrong.com/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a>'s <a href="http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition">Coherent Extrapolated Volition</a>, the other being <a href="http://wiki.lesswrong.com/wiki/Coherent_Blended_Volition">Coherent Blended Volition</a>. CAV would be a combination of the goals and beliefs of humanity at the present time.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Coherent_Blended_Volition"><span style="text-decoration: underline;">Coherent Blended Volition</span></a> - Coherent Blended Volition is a recent concept coined in a 2012 paper by <a href="http://wiki.lesswrong.com/wiki/Ben_Goertzel">Ben Goertzel</a> with the aim to clarify his <a href="http://wiki.lesswrong.com/wiki/Coherent_Aggregated_Volition">Coherent Aggregated Volition</a> idea. This clarifications follows the author's attempt to develop a comprehensive alternative to <a href="http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition">Coherent Extrapolated Volition</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition"><span style="text-decoration: underline;">Coherent Extrapolated Volition</span></a> &#x2013; is a term developed by <a href="http://wiki.lesswrong.com/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a> while discussing <a href="http://wiki.lesswrong.com/wiki/Friendly_AI">Friendly AI</a> development. It&#x2019;s meant as an argument that it would not be sufficient to explicitly program our desires and motivations into an AI. Instead, we should find a way to program it in a way that it would act in our best interests &#x2013; what we want it to do and not what we tell it to.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Color_politics"><span style="text-decoration: underline;">Color</span><span style="text-decoration: underline;"> politics</span></a> - the words "Blues" and "Greens" are often used to refer to two opposing political factions. Politics commonly involves an <a href="http://wiki.lesswrong.com/wiki/Adversarial_process">adversarial process</a>, where factions usually identify with political positions, and use <a href="http://wiki.lesswrong.com/wiki/Arguments_as_soldiers">arguments as soldiers</a> to defend their side. The dichotomies presented by the opposing sides are often <a href="http://wiki.lesswrong.com/wiki/False_dilemma">false dilemmas</a>, which can be shown by presenting <a href="http://wiki.lesswrong.com/wiki/Third_option">third options</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Common_knowledge"><span style="text-decoration: underline;">Common knowledge</span></a> - n the context of <a href="http://wiki.lesswrong.com/wiki/Aumann%27s_agreement_theorem">Aumann's agreement theorem</a>, a fact is part of the common knowledge of a group of agents when they all know it, they all know that they all know it, and so on ad infinitum.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Conceptual_metaphor"><span style="text-decoration: underline;">Conceptual metaphor</span></a> &#x2013; are neurally-implemented mappings between concrete <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Domain_of_discourse&amp;action=edit&amp;redlink=1">domains of discourse</a> (often related to our body and perception) and more abstract domains. These are a well-known source of <a href="http://wiki.lesswrong.com/wiki/Bias">bias</a> and are often exploited in the <a href="http://wiki.lesswrong.com/wiki/Dark_Arts">Dark Arts</a>. An example is &#x201C;argument is war&#x201D;.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Configuration_space"><span style="text-decoration: underline;">Configuration space</span></a> - is an isomorphism between the attributes of something, and its position on a multidimensional graph. Theoretically, the attributes and precise position on the graph should contain the same information. In practice, the concept usually appears as a suffix, as in "walletspace", where "walletspace" refers to the configuration space of all possible wallets, arranged by similarity. Walletspace would intersect with leatherspace, and the set of leather wallets is a subset of both walletspace and leatherspace, which are both subsets of thingspace.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Conservation_of_expected_evidence"><span style="text-decoration: underline;">Conservation of expected evidence</span></a> - a theorem that says: "for every expectation of evidence, there is an equal and opposite expectation of counterevidence". 0 = (P(H|E)-P(H))*P(E) + (P(H|~E)-P(H))*P(~E)</li>
<li><a href="http://wiki.lesswrong.com/wiki/Control_theory"><span style="text-decoration: underline;">Control theory</span></a> - a control system is a device that keeps a variable at a certain value, despite only knowing what the current value of the variable is. An example is a cruise control, which maintains a certain speed, but only measures the current speed, and knows nothing of the system that produces that speed (wind, car weight, grade).</li>
<li><a href="http://wiki.lesswrong.com/wiki/Corrupted_hardware"><span style="text-decoration: underline;">Corrupted hardware</span></a> - our brains do not always allow us to act the way we should. Corrupted hardware refers to those behaviors and thoughts that act for ancestrally relevant purposes rather than for stated moralities and preferences.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Counterfactual_mugging"><span style="text-decoration: underline;">Counterfactual mugging</span></a> - is a thought experiment for testing and differentiating <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theories</a>, stated as follows:</li>
<li><a href="/lw/bk/the_trouble_with_good/7x4">Counter man syndrome</a> - wherein a person behind a counter comes to believe that they know things they don't know, because, after all, they're the person behind the counter. So they can't just answer a question with "I don't know"... and thus they make something up, without really paying attention to the fact that they're making it up. Pretty soon, they don't know the difference between the facts and their made up stories</li>
<li><a href="http://wiki.lesswrong.com/wiki/Cox%27s_theorem">Cox's theorem</a> says, roughly, that if your beliefs at any given time take the form of an assignment of a numerical "plausibility score" to every proposition, and if they satisfy a few plausible axioms, then your plausibilities must effectively be probabilities obeying the usual laws of probability theory, and your updating procedure must be the one implied by <a href="http://wiki.lesswrong.com/wiki/Bayes%27_theorem">Bayes' theorem</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Crisis_of_faith"><span style="text-decoration: underline;">Crisis of faith</span></a> - a combined technique for recognizing and eradicating the whole systems of mutually-supporting false beliefs. The technique involves systematic application of introspection, with the express intent to check the reliability of beliefs independently of the other beliefs that support them in the mind. The technique might be useful for the victims of <a href="http://wiki.lesswrong.com/wiki/Affective_death_spiral">affective death spirals</a>, or any other systematic confusions, especially those supported by <a href="http://wiki.lesswrong.com/wiki/Anti-epistemology">anti-epistemology</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Cryonics"><span style="text-decoration: underline;">Cryonics</span></a> - is the practice of preserving people who are dying in liquid nitrogen soon after their heart stops. The idea is that most of your brain's information content is still intact right after you've "died". If humans invent molecular nanotechnology or brain emulation techniques, it may be possible to reconstruct the consciousness of cryopreserved patients.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Curiosity"><span style="text-decoration: underline;">Curiosity</span></a> - The first virtue is curiosity. A burning itch to know is higher than a solemn vow to pursue truth. To feel the burning itch of curiosity requires both that you be ignorant, and that you desire to relinquish your ignorance. If in your heart you believe you already know, or if in your heart you do not wish to know, then your questioning will be purposeless and your skills without direction. Curiosity seeks to annihilate itself; there is no curiosity that does not want an answer. The glory of glorious mystery is to be solved, after which it ceases to be mystery. Be wary of those who speak of being open-minded and modestly confess their ignorance. There is a time to confess your ignorance and a time to relinquish your ignorance. &#x2014;<a href="http://yudkowsky.net/rational/virtues"><span style="text-decoration: underline;">Twelve Virtues of Rationality</span></a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Dangerous_knowledge">Dangerous knowledge</a> - Intelligence, in order to be useful, must be used for something other than defeating itself.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Dangling_Node">Dangling Node</a> - A label for something that isn't "actually real".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Death"><span style="text-decoration: underline;">Death</span></a> - First you're there, and then you're not there, and they can't change you from being not there to being there, because there's nothing there to be changed from being not there to being there. That's death. <a href="http://wiki.lesswrong.com/wiki/Cryonics">Cryonicists</a> use the concept of <a href="http://en.wikipedia.org/wiki/information-theoretic_death">information-theoretic death</a>, which is what happens when the information needed to reconstruct you even in principle is no longer present. Anything less, to them, is just a flesh wound.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Debiasing">Debiasing</a> - The process of overcoming <a href="http://wiki.lesswrong.com/wiki/Bias">bias</a>. It takes serious study to gain meaningful benefits, half-hearted attempts may accomplish nothing, and partial knowledge of bias may do more <a href="http://wiki.lesswrong.com/wiki/Dangerous_knowledge">harm</a> than good.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Decision_theory"><span style="text-decoration: underline;">Decision theory</span></a> &#x2013; is the study of principles and algorithms for making correct decisions&#x2014;that is, decisions that allow an agent to achieve better outcomes with respect to its goals.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Defying_the_data"><span style="text-decoration: underline;">Defying the data</span></a> - Sometimes, the results of an experiment contradict what we have strong theoretical reason to believe. But experiments can go wrong, for various reasons. So if our theory is strong enough, we should in some cases defy the data: know that there has to be something wrong with the result, even without offering ideas on what it might be.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Disagreement"><span style="text-decoration: underline;">Disagreement</span></a> - <a href="http://wiki.lesswrong.com/wiki/Aumann%27s_agreement_theorem">Aumann's agreement theorem</a> can be <a href="http://wiki.lesswrong.com/wiki/Aumann_agreement">informally interpreted</a> as suggesting that if two people are honest seekers of truth, and both believe each other to be honest, then they should update on each other's opinions and quickly reach agreement. The very fact that a person believes something is <a href="http://wiki.lesswrong.com/wiki/Rational_evidence">Rational evidence</a> that that something is true, and so this fact <a href="http://www.overcomingbias.com/2007/01/extraordinary_c.html">should be taken into account</a> when forming your belief. Outside of well-functioning <a href="http://wiki.lesswrong.com/wiki/Prediction_market">prediction markets</a>, Aumann agreement can probably only be approximated by careful deliberative discourse. Thus, fostering effective deliberation should be seen as a key goal of <a href="http://wiki.lesswrong.com/wiki/Less_Wrong">Less Wrong</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Doubt"><span style="text-decoration: underline;">Doubt</span></a>- The proper purpose of a doubt is to destroy its target belief <a href="http://wiki.lesswrong.com/wiki/Litany_of_Tarski">if and only if</a> it is false. The mere feeling of crushing uncertainty is not virtuous unto an aspiring rationalist; probability theory is the law that says we must be uncertain to the exact extent to which the evidence merits uncertainty.</li>
<li><a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect">Dunning&#x2013;Kruger effect</a> - is a <a href="https://en.wikipedia.org/wiki/Cognitive_bias">cognitive bias</a> wherein unskilled individuals suffer from <a href="https://en.wikipedia.org/wiki/Illusory_superiority">illusory superiority</a>, mistakenly assessing their ability to be much higher than is accurate. This bias is attributed to a <a href="https://en.wikipedia.org/wiki/Metacognition">metacognitive</a> inability of the unskilled to recognize their ineptitude. Conversely, highly skilled individuals tend to underestimate their relative competence, erroneously assuming that tasks that are easy for them are also easy for others</li>
<li><a href="http://wiki.lesswrong.com/wiki/Emulation_argument_for_human-level_AI"><span style="text-decoration: underline;">Emulation argument for human-level AI</span></a> &#x2013; argument that since <a href="http://wiki.lesswrong.com/wiki/Whole_brain_emulation"><span style="text-decoration: underline;">whole brain emulation</span></a> seems feasible then human-level <a href="http://wiki.lesswrong.com/wiki/AGI"><span style="text-decoration: underline;">AI</span></a> must also be feasible.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Epistemic_hygiene"><span style="text-decoration: underline;">Epistemic hygiene</span></a> - consists of practices meant to allow accurate beliefs to spread within a community and keep less accurate or biased beliefs contained. The practices are meant to serve an analogous purpose to normal hygiene and sanitation in containing disease. "Good cognitive citizenship" is another phrase that has been proposed for this concept<a href="#cite_note-1"><sup>[1]</sup></a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Error_of_crowds"><span style="text-decoration: underline;">Error of crowds</span></a> - is the idea that under some scoring rules, the average error becomes less than the error of the average, thus making the average belief tautologically worse than a belief of a random person. Compare this to the ideas of <a href="http://wiki.lesswrong.com/wiki/Modesty_argument">modesty argument</a> and <a href="http://wiki.lesswrong.com/wiki/Wisdom_of_the_crowd">wisdom of the crowd</a>. A related idea is that a popular belief is likely to be wrong because the less popular ones couldn't maintain support if they were worse than the popular one.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Ethical_injunction"><span style="text-decoration: underline;">Ethical injunction</span></a> - are rules not to do something even when it's the right thing to do. (That is, you refrain "even when your brain has computed it's the right thing to do", but this will just seem like "the right thing to do".) For example, you shouldn't rob banks even if you plan to give the money to a good cause. This is to protect you from your own cleverness (especially taking bad black swan bets), and the <a href="http://wiki.lesswrong.com/wiki/Corrupted_hardware">Corrupted hardware</a> you're running on.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evidence"><span style="text-decoration: underline;">Evidence</span></a> - for a given theory is the observation of an event that is more likely to occur if the theory is true than if it is false. (The event would be evidence against the theory if it is less likely if the theory is true.)</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evidence_of_absence"><span style="text-decoration: underline;">Evidence of absence</span></a> - <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> that allows you to conclude some phenomenon isn't there. It is often said that "absence of evidence is not evidence of absence". However, if evidence is expected, but not present, that is evidence of absence.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evidential_Decision_Theory"><span style="text-decoration: underline;">Evidential Decision Theory</span></a> - a branch of <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a> which advises an agent to take actions which, conditional on it happening, maximizes the chances of the desired outcome.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evolution"><span style="text-decoration: underline;">Evolution</span></a> - The brainless, mindless <a href="http://wiki.lesswrong.com/wiki/Optimization_process">optimization process</a> responsible for the production of all biological life on Earth, including human beings. Since the design signature of evolution is <a href="http://wiki.lesswrong.com/wiki/Evolution_as_alien_god">alien and counterintuitive</a>, it takes some study to get to know your accidental Creator.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evolution_as_alien_god"><span style="text-decoration: underline;">Evolution as alien god</span></a> &#x2013; is a thought experiment in which evolution is imagined as a god. The though experiment is meant to convey the idea that evolution doesn&#x2019;t have a mind. The god in though experiment would be a tremendously powerful, unbelievably stupid, <a href="http://wiki.lesswrong.com/wiki/Slowness_of_evolution">ridiculously slow</a>, and utterly uncaring god; a god monomaniacally focused on the relative fitness of genes within a species; a god whose attention was completely separated and working at cross-purposes in rabbits and wolves.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evolutionary_argument_for_human-level_AI"><span style="text-decoration: underline;">Evolutionary argument for human-level AI</span></a> - an argument that uses the fact that <a href="http://wiki.lesswrong.com/wiki/Evolution">evolution</a> produced human level intelligence to argue for the feasibility of human-level <a href="http://wiki.lesswrong.com/wiki/AGI">AI</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Evolutionary_psychology"><span style="text-decoration: underline;">Evolutionary psychology</span></a> - the idea of evolution as the idiot designer of humans - that our brains are not consistently well-designed - is a key element of many of the explanations of human errors that appear on this website.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Existential_risk"><span style="text-decoration: underline;">Existential risk</span></a> &#x2013; is a risk posing permanent large negative consequences to humanity which can never be undone.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Expected_value"><span style="text-decoration: underline;">Expected value</span></a> - The expected value or expectation is the (weighted) average of all the possible outcomes of an event, weighed by their <a href="http://wiki.lesswrong.com/wiki/Probability">probability</a>. For example, when you roll a die, the expected value is (1+2+3+4+5+6)/6 = 3.5. (Since a die doesn't even have a face that says 3.5, this illustrates that very often, the "expected value" isn't a value you actually expect.)</li>
<li><a href="http://wiki.lesswrong.com/wiki/Extensibility_argument_for_greater-than-human_intelligence"><span style="text-decoration: underline;">Extensibility argument for greater-than-human intelligence</span></a> &#x2013;is an argument that once we get to a human level <a href="http://wiki.lesswrong.com/wiki/AGI">AGI</a>, extensibility would make an AGI of greater-than-human-intelligence feasible.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Extraordinary_evidence">Extraordinary evidence</a> - is <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> that turns an <a href="http://wiki.lesswrong.com/wiki/Prior">a priori</a> highly unlikely event into an a posteriori likely event.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Free-floating_belief"><span style="text-decoration: underline;">Free-floating belief</span></a> &#x2013; is a <a href="http://wiki.lesswrong.com/wiki/Belief">belief</a> that both <a href="http://wiki.lesswrong.com/wiki/Beliefs_require_observations">doesn't follow from observations</a> and doesn't restrict <a href="http://wiki.lesswrong.com/wiki/Making_beliefs_pay_rent">which experiences to anticipate</a>. It is both unfounded and useless.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Free_will">Free will</a>&#xA0;- means our algorithm's ability to determine our actions. People often get confused over free will because they picture themselves as being restrained rather than part of physics. Yudowsky calls this view&#xA0;<a href="/lw/r0/thou_art_physics/">Requiredism</a>, but most people just view this essentially as&#xA0;<a href="https://www.google.com.au/url?url=https://en.wikipedia.org/wiki/Compatibilism&amp;rct=j&amp;frm=1&amp;q=&amp;esrc=s&amp;sa=U&amp;ved=0CBQQFjAAahUKEwiiwP7E-dnGAhWI3aYKHTzKD2Q&amp;usg=AFQjCNFSZ6suRdyDzeDQf_Q1zs6Z_MRbTA">Compatibilism</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence"><span style="text-decoration: underline;">Friendly artificial intelligence</span></a> &#x2013; is a <a href="http://wiki.lesswrong.com/wiki/Superintelligence">superintelligence</a> (i.e., a <a href="http://wiki.lesswrong.com/wiki/Really_powerful_optimization_process">really powerful optimization process</a>) that produces good, beneficial outcomes rather than harmful ones.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Fully_general_counterargument"><span style="text-decoration: underline;">Fully general counterargument</span></a> - an argument which can be used to discount any conclusion the arguer does not like. Being in possession of such an argument leads to irrationality because it allows the arguer to avoid updating their beliefs in the light of new evidence. Knowledge of cognitive biases can itself allow someone to form fully general counterarguments ("you're just saying that because you're exhibiting X bias").</li>
<li><a href="http://wiki.lesswrong.com/wiki/Great_Filter"><span style="text-decoration: underline;">Great Filter</span></a> - is a proposed explanation for the <a href="http://en.wikipedia.org/wiki/Fermi_paradox">Fermi Paradox</a>. The development of intelligent life requires many steps, such as the emergence of single-celled life and the transition from unicellular to multicellular life forms. Since we have not observed intelligent life beyond our planet, there seems to be a developmental step that is so difficult and unlikely that it "filters out" nearly all civilizations before they can reach a space-faring stage.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Group_rationality">Group rationality</a>&#xA0;- In almost anything, individuals are inferior to groups.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Group_selection">Group selection</a></span>&#xA0;&#x2013; is an incorrect belief about evolutionary theory that a feature of the organism is there for the good of the group.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Heuristic"><span style="text-decoration: underline;">Heuristic</span></a> - quick, intuitive strategy for reasoning or decision making, as opposed to more formal methods. Heuristics require much less time and energy to use, but sometimes go awry, producing <a href="http://wiki.lesswrong.com/wiki/Bias">bias</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Heuristics_and_biases"><span style="text-decoration: underline;">Heuristics and biases</span></a> - program in cognitive psychology tries to work backward from <a href="http://wiki.lesswrong.com/wiki/Biases">biases</a> (experimentally reproducible human errors) to <a href="http://wiki.lesswrong.com/wiki/Heuristic">heuristics</a> (the underlying mechanisms at work in the brain).</li>
<li><a href="/lw/ka/hold_off_on_proposing_solutions/">Hold Off on Proposing Solutions</a> - "Do not propose solutions until the problem has been discussed as thoroughly as possible without suggesting any." It is easy to show that this edict works in contexts where there are objectively defined good solutions to problems.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Hollywood_rationality">Hollywood rationality</a>- What Spock does, not what actual rationalists do.</li>
<li><a href="http://wiki.lesswrong.com/wiki/How_an_algorithm_feels"><span style="text-decoration: underline;">How an algorithm feels</span></a> - Our philosophical intuitions are generated by algorithms in the human brain. To dissolve a philosophical dilemma, it often suffices to understand the cognitive algorithm that generates the appearance of the dilemma - if you understand the algorithm in sufficient detail. It is not enough to say "An algorithm does it!" - this <a href="/lw/op/fake_reductionism/">might as well be magic</a>. It takes a detailed step-by-step walkthrough.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Hypocrisy"><span style="text-decoration: underline;">Hypocrisy</span></a> - the act of claiming to motives, morals and standards one does not possess. Informally, it refers to not living up the standards that one espouses, whether or not one sincerely believes those standards.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Impossibility"><span style="text-decoration: underline;">Impossibility</span></a>- Careful use of language dictates that we distinguish between several senses in which something can be said to be impossible. Some things are logically impossible: you can't have a square circle or an object that is both perfectly black and perfectly not-black. Also, in our <a href="http://wiki.lesswrong.com/wiki/Reductionism">reductionist</a> universe operating according to <a href="http://wiki.lesswrong.com/wiki/Universal_law">universal physical laws</a>, some things are physically impossible based on our model of how things work, even they are not <a href="http://wiki.lesswrong.com/wiki/Mind_projection_fallacy">obviously</a> contradictory or contrary to reason: for example, the laws of thermodynamics give us a strong guarantee that there can never be a perpetual motion machine. It can be tempting to label as impossible very difficult problems which you have no idea how to solve. But the apparent lack of a solution is not a strong guarantee that no solution can exist in the way that the laws of thermodynamics, or Godel's incompleteness results, give us proofs that something cannot be accomplished. A blank map does not correspond to a blank territory; in the absence of a proof that a problem is insolvable, you can't be confident that you're not just overlooking something that a <a href="http://wiki.lesswrong.com/wiki/Artificial_general_intelligence">greater intelligence</a> would spot in an instant.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Improper_belief"><span style="text-decoration: underline;">Improper belief</span></a> &#x2013; is a <a href="http://wiki.lesswrong.com/wiki/Belief"><span style="text-decoration: underline;">belief</span></a> that isn't concerned with describing the <a href="http://wiki.lesswrong.com/wiki/Territory"><span style="text-decoration: underline;">territory</span></a>. A proper belief, on the other hand, <a href="http://wiki.lesswrong.com/wiki/Beliefs_require_observations"><span style="text-decoration: underline;">requires observations</span></a>, gets <a href="http://wiki.lesswrong.com/wiki/Belief_update"><span style="text-decoration: underline;">updated</span></a> upon encountering new <a href="http://wiki.lesswrong.com/wiki/Evidence"><span style="text-decoration: underline;">evidence</span></a>, and <a href="http://wiki.lesswrong.com/wiki/Beliefs_pay_rent"><span style="text-decoration: underline;">provides practical benefit</span></a> in <a href="http://wiki.lesswrong.com/wiki/Technical_explanation"><span style="text-decoration: underline;">anticipated experience</span></a>. Note that the fact that a belief just happens to be true doesn't mean you're right to have it. If you buy a <a href="http://wiki.lesswrong.com/wiki/Lottery"><span style="text-decoration: underline;">lottery</span></a> ticket, certain that it's a winning ticket (for no reason), and it happens to be, believing that was still a mistake. Types of improper belief discussed in the <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions"><span style="text-decoration: underline;">Mysterious Answers to Mysterious Questions</span></a> sequence include: <a href="http://wiki.lesswrong.com/wiki/Free-floating_belief"><span style="text-decoration: underline;">Free-floating belief</span></a>, <a href="http://wiki.lesswrong.com/wiki/Belief_as_attire"><span style="text-decoration: underline;">Belief as attire</span></a>, <a href="http://wiki.lesswrong.com/wiki/Belief_in_belief"><span style="text-decoration: underline;">Belief in belief</span></a> and <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Belief_as_cheering&amp;action=edit&amp;redlink=1"><span style="text-decoration: underline;">Belief as cheering</span></a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Incredulity">Incredulity</a> - Spending emotional energy on incredulity wastes time you could be using to <a href="http://wiki.lesswrong.com/wiki/Update">update</a>. It repeatedly throws you back into the frame of the old, wrong viewpoint. It feeds your sense of righteous indignation at reality daring to contradict you.</li>
<li><a href="http://en.wikipedia.org/wiki/Intuition_pump">Intuition pump</a>&#xA0;- In summary, they are thought experiments that highlight, or pumping, certain ideas, intuitions or concepts while attenuating others so as to make some conclusion obvious and simple to reach. The intuition pump is a carefully designed persuasion tool in which you check to see if the same intuitions still get pumped when you change certain settings in a thought experiment.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Kolmogorov_complexity">Kolmogorov complexity</a> - given a string, the length of the shortest possible program that prints it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Lawful_intelligence">Lawful intelligence</a> - The startling and counterintuitive notion - contradicting both surface appearances and all <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Deep_Wisdom&amp;action=edit&amp;redlink=1">Deep Wisdom</a> - that intelligence is a manifestation of Order rather than Chaos. Even creativity and <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Outside_the_box&amp;action=edit&amp;redlink=1">outside-the-box thinking</a> are essentially lawful. While this is a complete heresy according to the standard religion of Silicon Valley, there are some good mathematical reasons for believing it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Least_convenient_possible_world"><span style="text-decoration: underline;">Least convenient possible world</span></a> &#x2013; is a technique for enforcing intellectual honesty, to be used when arguing against an idea. The essence of the technique is to assume that all the specific details will align with the idea against which you are arguing, i.e. to consider the idea in the context of a least convenient <a href="http://wiki.lesswrong.com/wiki/Possible_world">possible world</a>, where every circumstance is colluding against your objections and counterarguments. This approach ensures that your objections are <a href="http://wiki.lesswrong.com/wiki/Epistemic_hygiene">strong enough</a>, running minimal risk of being <a href="http://wiki.lesswrong.com/wiki/Rationalization">rationalizations</a> for your <a href="http://wiki.lesswrong.com/wiki/Color_politics">position</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Logical_rudeness"><span style="text-decoration: underline;">Logical rudeness</span></a> &#x2013; is a response to criticism which insulates the responder from having to address the criticism directly. For example, ignoring all the diligent work that evolutionary biologists did to dig up previous fossils, and insisting you can only be satisfied by an actual videotape, is "logically rude" because you're ignoring evidence that someone went to a great deal of trouble to provide to you.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Log_odds">Log odds</a>&#xA0;&#x2013; is an alternate way of expressing probabilities, which simplifies the process of updating them with new evidence. Unfortunately, it is difficult to convert between probability and log odds. The log odds is the log of the&#xA0;<a href="http://wiki.lesswrong.com/wiki/Odds_ratio">odds ratio</a>.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Magical_categories">Magical categories</a></span> - an English word which, although it sounds simple - hey, it's <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Minimum_message_length&amp;action=edit&amp;redlink=1">just one word</a>, right? - is actually not simple, and furthermore, may be applied in a complicated way that drags in other considerations. Physical brains are not powerful enough to search all possibilities; we have to cut down the search space to possibilities that are likely to be good. Most of the "obviously bad" methods - those that would end up violating our other values, and so ranking very low in our preference ordering - do not even occur to us as possibilities.</li>
<li><a href="/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/">Making Beliefs Pay Rent</a> - Every question of belief should flow from a question of anticipation, and that question of anticipation should be the centre of the inquiry. Every guess of belief should begin by flowing to a specific guess of anticipation, and should continue to pay rent in future anticipations. If a belief turns deadbeat, evict it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Many-worlds_interpretation">Many-worlds interpretation</a> - uses <a href="http://wiki.lesswrong.com/wiki/Decoherence">decoherence</a> to explain how the universe splits into many separate branches, each of which looks like it came out of a random collapse.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Map_and_territory"><span style="text-decoration: underline;">Map and territory</span></a>- Less confusing than saying "belief and reality", "map and territory" reminds us that a map of Texas is not the same thing as Texas itself. Saying "map" also dispenses with possible meanings of "belief" apart from "representations of some part of reality". Since our predictions don't always come true, we need different words to describe the thingy that generates our predictions and the thingy that generates our experimental results. The first thingy is called "belief", the second thingy "reality".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Meme_lineage"><span style="text-decoration: underline;">Meme lineage</span></a> &#x2013; is a set of beliefs, attitudes, and practices that all share a clear common origin point. This concept also emphasizes the means of transmission of the beliefs in question. If a belief is part of a meme lineage that transmits for primarily social reasons, it may be discounted for purposes of the <a href="http://wiki.lesswrong.com/wiki/Modesty_argument">modesty argument</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Memorization">Memorization</a> - is what you're doing when you cram for a university exam. It's not</li>
<li><a href="http://wiki.lesswrong.com/wiki/Modesty">Modesty</a>&#xA0;- admitting or boasting of flaws so as to not create perceptions of arrogance. Not to be confused with&#xA0;<a href="http://wiki.lesswrong.com/wiki/Humility">humility</a>.</li>
<li><a href="/lw/jn/how_much_evidence_does_it_take/" target="_blank">Most of science is actually done by induction</a> - To come up with something worth testing, <a href="/lw/jo/einsteins_arrogance/" target="_blank">a scientist needs to do lots of sound induction first</a> or borrow an idea from someone who already used induction. This is because induction is the only way to reliably find candidate hypotheses which deserve attention. Examples of bad ways to find hypotheses include finding something interesting or surprising to believe in and then pinning all your hopes on that thing turning out to be true.</li>
<li><a href="/lw/i4/belief_in_belief/" target="_blank">Most peoples' beliefs aren&#x2019;t worth considering</a>&#xA0;- Sturgeon's Law says that as a general rule, 90% of everything is garbage. Even if it is the case that 90% of everything produced by any field is garbage that does not mean one can dismiss the 10% that is quality work. Instead, it is important engage with that 10%, and use that as the standard of quality.</li>
<li><a href="https://en.wikipedia.org/wiki/Nash_equilibrium">Nash equilibrium</a> - a stable state of a system involving the interaction of different participants, in which no participant can gain by a unilateral change of strategy if the strategies of the others remain unchanged.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Newcomb's_problem">Newcomb's problem</a>&#xA0;- In Newcomb's problem, a superintelligence called Omega shows you two boxes, A and B, and offers you the choice of taking only box A, or both boxes A and B. Omega has put&#xA0;$1,000 in box B. If Omega thinks you will take box A only, he has put $1,000,000 in it.&#xA0;</li>
<li><a href="http://wiki.lesswrong.com/wiki/Nonapples">Nonapples</a>&#xA0;- a proposed object, tool, technique, or theory which is defined only as being not like a specific, existent example of said categories. It is a type of overly-general prescription which, while of little utility, can seem useful. It involves disguising a shallow criticism as a solution, often in such a way as to make it look profound. For instance, suppose someone says, "We don't need war, we need non-violent conflict resolution." In this way a shallow criticism (war is bad) is disguised as a solution (non-violent conflict resolution, i.e, nonwar). This person is selling nonapples because "non-violent conflict resolution" isn't a method of resolving conflict nonviolently. Rather, it is a description of all conceivable methods of non-violent conflict resolution, the vast majority of which are incoherent and/or ineffective.</li>
<li><a href="/lw/e95/">Noncentral fallacy</a> - A rhetorical move often used in political, philosophical, and cultural arguments. "X is in a category whose archetypal member gives us a certain emotional reaction. Therefore, we should apply that emotional reaction to X, even though it is not a central category member."</li>
<li><a href="http://wiki.lesswrong.com/wiki/Not_technically_a_lie"><span style="text-decoration: underline;">Not technically a lie</span></a> &#x2013; is a statement that is literally true, but causes the listener to attain false beliefs by performing incorrect inference, is not technically a lie.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Occam%27s_razor"><span style="text-decoration: underline;">Occam's razor</span></a> - principle commonly stated as "Entities must not be multiplied beyond necessity". When several theories are able to explain the same observations, Occam's razor suggests the simpler one is preferable.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Odds_ratio"><span style="text-decoration: underline;">Odds ratio</span></a> - are an alternate way of expressing probabilities, which simplifies the process of updating them with new evidence. The odds ratio of A is P(A)/P(&#xAC;A).</li>
<li><a href="http://wiki.lesswrong.com/wiki/Omega"><span style="text-decoration: underline;">Omega</span></a> - A hypothetical super-intelligent being used in philosophical problems. Omega is most commonly used as the predictor in <a href="http://wiki.lesswrong.com/wiki/Newcomb%27s_problem">Newcomb's problem</a>. In its role as predictor, Omega's predictions occur almost certainly. In some thought experiments, Omega is also taken to be super-powerful. Omega can be seen as analogous to <a href="http://en.wikipedia.org/wiki/Laplace%27s_demon">Laplace's demon</a>, or as the closest approximation to the Demon capable of existing in our universe.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Oops"><span style="text-decoration: underline;">Oops</span></a> - Theories must be bold and expose themselves to falsification; be willing to commit the heroic sacrifice of giving up your own ideas when confronted with contrary evidence; play nice in your arguments; try not to deceive yourself; and other fuzzy verbalisms. It is better to say oops quickly when you realize a mistake. The alternative is stretching out the battle with yourself over years.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Outside_view"><span style="text-decoration: underline;">Outside view</span></a> - Taking the outside view (another name for <a href="http://en.wikipedia.org/wiki/Reference_class_forecasting">reference class forecasting</a>) means using an estimate based on a class of roughly similar previous cases, rather than trying to visualize the details of a process. For example, estimating the completion time of a programming project based on how long similar projects have taken in the past, rather than by drawing up a graph of tasks and their expected completion times.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Overcoming_Bias"><span style="text-decoration: underline;">Overcoming Bias</span></a> - is a group blog on the systemic mistakes humans make, and how we can possibly correct them.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Paperclip_maximizer"><span style="text-decoration: underline;">Paperclip </span><span style="text-decoration: underline;">maximizer</span></a> &#x2013; is an AI that has been created to maximize the number of paperclips in the universe. It is a hypothetical <a href="http://wiki.lesswrong.com/wiki/Unfriendly_artificial_intelligence">unfriendly artificial intelligence</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Pascal%27s_mugging">Pascal's mugging</a>&#xA0;&#x2013; is a&#xA0;<a href="https://en.wikipedia.org/wiki/Thought-experiment">thought-experiment</a>&#xA0;demonstrating a problem in expected utility maximization. A&#xA0;<a href="https://en.wikipedia.org/wiki/Rational_agent">rational agent</a>&#xA0;should choose actions whose outcomes, when weighed by their probability, have higher&#xA0;<a href="https://en.wikipedia.org/wiki/Utility">utility</a>. But some very unlikely outcomes may have very great utilities, and these utilities can grow faster than the probability diminishes. Hence the agent should focus more on vastly improbable cases with implausibly high rewards.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Guessing_the_teacher%27s_password">Password</a>&#xA0;- The answer you guess instead of actually understanding the problem.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Philosophical_zombie">Philosophical zombie</a>&#xA0;- a hypothetical entity that looks and behaves exactly like a human (often stipulated to be atom-by-atom identical to a human) but is not actually conscious: they are often said lack&#xA0;<a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Qualia&amp;action=edit&amp;redlink=1">qualia</a>&#xA0;or phenomena consciousness.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Phlogiston"><span style="text-decoration: underline;">Phlogiston</span></a> - the 18 century's answer to the Elemental Fire of the Greek alchemists. Ignite wood, and let it burn. What is the orangey-bright "fire" stuff? Why does the wood transform into ash? To both questions, the 18th-century chemists answered, "phlogiston"....and that was it, you see, that was their answer: "Phlogiston." &#x2014;<a href="/lw/is/fake_causality/">Fake Causality</a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Possibility"><span style="text-decoration: underline;">Possibility</span></a> - words in natural language carry <a href="http://wiki.lesswrong.com/wiki/Connotation">connotations</a> that may become misleading when the words get applied with technical precision. While it's <a href="http://wiki.lesswrong.com/wiki/Not_technically_a_lie">not technically a lie</a> to say that it's possible to win a lottery, the statement is deceptive. It's much more precise, for communication of the actual fact through connotation, to say that it&#x2019;s impossible to win the <a href="http://wiki.lesswrong.com/wiki/Lottery">lottery</a>. This is an example of <a href="http://wiki.lesswrong.com/wiki/Antiprediction">antiprediction</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Possible_world"><span style="text-decoration: underline;">Possible world</span></a> - is one that is internally consistent, even if it is <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Counterfactual&amp;action=edit&amp;redlink=1">counterfactual</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Prediction_market"><span style="text-decoration: underline;">Prediction market</span></a> - speculative markets created for the purpose of making predictions. Assets are created whose final cash value is tied to a particular event or parameter. The current market prices can then be interpreted as predictions of the probability of the event or the expected value of the parameter.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Priors"><span style="text-decoration: underline;">Priors</span></a> - refer generically to the beliefs an agent holds regarding a fact, hypothesis or consequence, before being presented with evidence.</li>
<li><a href="/lw/oj/probability_is_in_the_mind/">Probability is in the Mind</a> - Probabilities express uncertainty, and it is only agents who can be uncertain. A blank map does not correspond to a blank territory. Ignorance is in the mind.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Probability_theory"><span style="text-decoration: underline;">Probability theory</span></a> - a field of mathematics which studies random variables and processes.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationality">Rationality</a>&#xA0;- the characteristic of thinking and acting optimally. An agent is rational if it wields its intelligence in such a way as to maximize the convergence between its beliefs and reality; and acts on these beliefs in such a manner as to maximize its chances of achieving whatever goals it has. For humans, this means mitigating (as much as possible) the influence of&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bias">cognitive biases</a>.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Rational_evidence">Rational evidence</a></span> - the broadest possible sense of <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a>, the <a href="http://wiki.lesswrong.com/wiki/Bayesian">Bayesian</a> sense. Rational evidence about a hypothesis H is any observation which has a different <a href="http://wiki.lesswrong.com/wiki/Likelihood">likelihood</a> depending on whether H holds in reality or not. Rational evidence is distinguished from narrower forms of evidence, such as scientific evidence or legal evidence. For a belief to be scientific, you should be able to do repeatable experiments to verify the belief. For evidence to be admissible in court, it must e.g. be a personal observation rather than hearsay.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationalist_taboo"><span style="text-decoration: underline;">Rationalist taboo</span></a> - a technique for fighting muddles in discussions. By prohibiting the use of a certain word and all the words synonymous to it, people are forced to elucidate the specific contextual meaning they want to express, thus removing ambiguity otherwise present in a single word. Mainstream philosophy has a parallel procedure called "unpacking" where doubtful terms need to be expanded out.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy"><span style="text-decoration: underline;">Rationality and Philosophy</span></a> - A <a href="http://wiki.lesswrong.com/wiki/Sequence">sequence</a> by <a href="/user/lukeprog/">lukeprog</a> examining the implications of rationality and cognitive science for philosophical method.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationality_as_martial_art">Rationality as martial art</a>&#xA0;- A metaphor for rationality as the martial art of mind; training brains in the same fashion as muscles. The metaphor is intended to have complex connotations, rather than being strictly positive. Do modern-day martial arts suffer from being&#xA0;<a href="/lw/2i/epistemic_viciousness/">insufficiently tested in realistic fighting</a>, and do attempts at&#xA0;<a href="http://wiki.lesswrong.com/wiki/Rationality">rationality</a>&#xA0;training run into the same problem?</li>
<li><a href="http://wiki.lesswrong.com/wiki/Reversal_test"><span style="text-decoration: underline;">Reversal test</span></a> - a technique for fighting <a href="http://wiki.lesswrong.com/wiki/Status_quo_bias">status quo bias</a> in judgments about the preferred value of a continuous parameter. If one deems the change of the parameter in one direction to be undesirable, the reversal test is to check that either the change of that parameter in the opposite direction (away from status quo) is deemed desirable, or that there are strong reasons to expect that the current value of the parameter is (at least locally) the optimal one.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Reductionism"><span style="text-decoration: underline;">Reductionism</span></a> - a disbelief that the higher levels of simplified multilevel models are out there in the <a href="http://wiki.lesswrong.com/wiki/Territory">territory</a>, that concepts constructed by mind in themselves play a role in the behavior of reality. This doesn't contradict the notion that the concepts used in simplified multilevel models refer to the actual clusters of configurations of reality.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Religion">Religion</a>- Religion is a complex group of human activities &#x2014; involving tribal affiliation,&#xA0;<a href="http://wiki.lesswrong.com/wiki/Belief_in_belief">belief in belief</a>, supernatural claims, and a range of shared group practices such as worship meetings, rites of passage, etc.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Reversed_stupidity_is_not_intelligence">Reversed stupidity is not intelligence</a> - "The world's greatest fool may say the Sun is shining, but that doesn't make it dark out.".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Science"><span style="text-decoration: underline;">Science</span></a> - a method for developing true beliefs about the world. It works by developing hypotheses about the world, creating experiments that would allow the hypotheses to be tested, and running the experiments. By having people publish their falsifiable predictions and their experimental results, science protects itself from individuals deceiving themselves or others.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Scoring_rule"><span style="text-decoration: underline;">Scoring rule</span></a> - a scoring rule is a measure of performance of probabilistic predictions - made under uncertainty.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes"><span style="text-decoration: underline;">Seeing with Fresh Eyes</span></a> - A <a href="http://wiki.lesswrong.com/wiki/Sequence">sequence</a> on the incredibly difficult feat of getting your brain to actually think about something, instead of instantly stopping on the first thought that comes to mind.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Semantic_stopsign"><span style="text-decoration: underline;">Semantic </span><span style="text-decoration: underline;">stopsign</span></a> &#x2013; is a meaningless generic explanation that creates an illusion of giving an answer, without actually explaining anything.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Shannon_information">Shannon information</a> - The Shannon entropy is a measure of the average information content one is missing when one does not know the value of the random variable.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Shut_up_and_multiply"><span style="text-decoration: underline;">Shut up and multiply</span></a>- the ability to trust the math <a href="http://wiki.lesswrong.com/wiki/Bite_the_bullet">even when it feels wrong</a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Signaling"><span style="text-decoration: underline;">Signaling</span></a> - "a method of conveying information among not-necessarily-trustworthy parties by performing an action which is more likely or less costly if the information is true than if it is not true".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Solomonoff_induction">Solomonoff induction</a> - A formalized version of Occam's razor based on <a href="http://wiki.lesswrong.com/wiki/Kolmogorov_complexity">Kolmogorov complexity</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Sound_argument"><span style="text-decoration: underline;">Sound argument</span></a> - an argument that is <a href="http://wiki.lesswrong.com/wiki/Valid_argument">valid</a> and whose premises are all true. In other words, the premises are true and the conclusion necessarily follows from them, making the conclusion true as well.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Spaced_repetition"><span style="text-decoration: underline;">Spaced repetition</span></a> - is a technique for building long-term knowledge efficiently. It works by showing you a flash card just before a computer model predicts you will have forgotten it. <a href="http://en.wikipedia.org/wiki/Anki">Anki</a> is Less Wrong's spaced repetition software of choice</li>
<li><a href="http://wiki.lesswrong.com/wiki/Statistical_bias"><span style="text-decoration: underline;">Statistical bias</span></a> - "Bias" as used in the field of statistics refers to directional error in an estimator. Statistical bias is error you cannot correct by repeating the experiment many times and averaging together the results.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Steel_man">Steel man</a> - A term for the opposite of a Straw Man</li>
<li><a href="http://wiki.lesswrong.com/wiki/Superstimulus"><span style="text-decoration: underline;">Superstimulus</span></a> - an exaggerated version of a <a href="https://en.wikipedia.org/wiki/Stimulation">stimulus</a> to which there is an existing response tendency, or any stimulus that elicits a response more strongly than the stimulus for which it evolved.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Surprise"><span style="text-decoration: underline;">Surprise</span></a> - Recognizing a fact that disagrees with your <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Intuition&amp;action=edit&amp;redlink=1">intuition</a> as surprising is an important step in <a href="http://wiki.lesswrong.com/wiki/Updating">updating</a> your worldview.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Sympathetic_magic"><span style="text-decoration: underline;">Sympathetic magic</span></a> - Humans seem to naturally generate a series of concepts known as sympathetic magic, a host of theories and practices which have certain principles in common, two of which are of overriding importance: the <a href="http://wiki.lesswrong.com/wiki/Contagion_heuristic">Law of Contagion</a> holds that two things which have interacted, or were once part of a single entity, retain their connection and can exert influence over each other; the Law of Similarity holds that things which are similar or treated the same establish a connection and can affect each other.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Tapping_Out"><span style="text-decoration: underline;">Tapping Out</span></a> - The appropriate way to signal that you've said all you wanted to say on a particular topic, and that you're ending your participation in a conversation lest you start saying things that are less worthwhile. It doesn't mean accepting defeat or claiming victory and it doesn't mean you get the last word. It just means that you don't expect your further comments in a thread to be worthwhile, because you've already made all the points you wanted to, or because you find yourself getting too emotionally invested, or for any other reason you find suitable.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Technical_explanation"><span style="text-decoration: underline;">Technical explanation</span></a> - A technical explanation is an explanation of a phenomenon that makes you <a href="http://wiki.lesswrong.com/wiki/Making_beliefs_pay_rent">anticipate certain experiences</a>. A proper technical explanation controls anticipation strictly, weighting your <a href="http://wiki.lesswrong.com/wiki/Priors">priors</a> and <a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a> precisely to create the justified amount of uncertainty. Technical explanations are contrasted with verbal explanations, which give the impression of understanding without actually producing the proper expectation.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Teleology">Teleology</a>&#xA0;- The study of things that happen for the sake of their future consequences. The fallacious meaning of it is that events are the result of future events. The non-fallacious meaning is that it is the study of things that happen because of their intended results, where the intention existed in an actual mind in the prior past, and so was causally able to bring about the event by planning and acting.</li>
<li><a href="http://wiki.lesswrong.com/wiki/The_map_is_not_the_territory">The map is not the territory</a>&#xA0;&#x2013; the idea that our perception of the world is being generated by our brain and can be considered as a 'map' of reality written in neural patterns. Reality exists outside our mind but we can construct models of this 'territory' based on what we glimpse through our senses.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Third_option"><span style="text-decoration: underline;">Third option</span></a> - is a way to break a <a href="http://wiki.lesswrong.com/wiki/False_dilemma">false dilemma</a>, showing that neither of the suggested solutions is a good idea.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Traditional_rationality"><span style="text-decoration: underline;">Traditional rationality</span></a> - "Traditional Rationality" refers to the tradition passed down by reading Richard Feynman's "Surely You're Joking", Thomas Kuhn's "The Structure of Scientific Revolutions", Martin Gardner's "Science: Good, Bad, and Bogus", Karl Popper on falsifiability, or other non-technical material on rationality. Traditional Rationality is a very large improvement over nothing at all, and very different from <a href="http://wiki.lesswrong.com/wiki/Hollywood_rationality">Hollywood rationality</a>; people who grew up on this belief system are definitely fellow travelers, and where most of our recruits come from. But you can do even better by adding math, science, formal epistemic and instrumental rationality; experimental psychology, cognitive science, deliberate practice, in short, all the technical stuff.There's also some popular tropes of Traditional Rationality that actually seem flawed once you start comparing them to a Bayesian standard - for example, the idea that you ought to give up an idea once definite evidence has been provided against it, but you're allowed to believe until then, if you want to. Contrast to the stricter idea of there being a certain exact probability which it is correct to assign, continually updated in the light of new evidence.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Trivial_inconvenience"><span style="text-decoration: underline;">Trivial inconvenience</span></a> - inconveniences that take few resources to counteract but have a disproportionate impact on people deciding whether to take a course of action.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Truth"><span style="text-decoration: underline;">Truth</span></a> - the correspondence between and one's beliefs about reality and reality.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Tsuyoku_naritai"><span style="text-decoration: underline;">Tsuyoku</span> <span style="text-decoration: underline;">naritai</span></a> - the will to transcendence. Japanese: "I want to become stronger."</li>
<li><a href="http://www.yudkowsky.net/rational/virtues">Twelve virtues of rationality</a><ol>
<li><em>Curiosity </em>&#x2013; the burning itch</li>
<li><em>Relenquishment</em> &#x2013; &#x201C;That which can be destroyed by the truth should be.&#x201D; -P. C. Hodgell</li>
<li><em>Lightness </em>&#x2013; follow the evidence wherever it leads</li>
<li><em>Evenness </em>&#x2013; resist selective skepticism; use reason, not rationalization</li>
<li><em>Argument </em>&#x2013; do not avoid arguing; strive for exact honesty; fairness does not mean balancing yourself evenly between propositions</li>
<li><em>Empiricism </em>&#x2013; knowledge is rooted in empiricism and its fruit is prediction; argue what experiences to anticipate, not which beliefs to profess</li>
<li><em>Simplicity </em>&#x2013; is virtuous in belief, design, planning, and justification; ideally: nothing left to take away, not nothing left to add</li>
<li><em>Humility </em>&#x2013; take actions, anticipate errors; do not boast of modesty; no one achieves perfection</li>
<li><em>Perfectionism </em>&#x2013; seek the answer that is *perfectly* right &#x2013; do not settle for less</li>
<li><em>Precision </em>&#x2013; the narrowest statements slice deepest; don&#x2019;t walk but dance to the truth</li>
<li><em>Scholarship </em>&#x2013; absorb the powers of science</li>
<li>[<em>The void</em>] (the nameless virtue) &#x2013; &#x201C;More than anything, you must think of carrying your map through to reflecting the territory.&#x201D;</li>
</ol></li>
<li><a href="http://wiki.lesswrong.com/wiki/Understanding">Understanding</a> - is more than just <a href="http://wiki.lesswrong.com/wiki/Memorization">memorization</a> of detached facts; it requires ability to see the implications across a variety of possible contexts.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Universal_law"><span style="text-decoration: underline;">Universal law</span></a> - the idea that everything in reality always behaves according to the same uniform physical laws; there are no exceptions and no alternatives.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Unsupervised_universe"><span style="text-decoration: underline;">Unsupervised universe</span></a> - a thought experiment developed to counter undue optimism, not just the sort due to explicit theology, but in particular a disbelief in the Future's vulnerability&#x2014;a reluctance to accept that things could really turn out wrong. It involves a benevolent god, a simulated universe, e.g. <a href="http://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway's Game of Life</a> and asking the mathematical question of what would happen according to the standard Life rules given certain initial conditions - so that even God cannot control the answer to the question; although, of course, God always intervenes in the actual Life universe.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Valid_argument"><span style="text-decoration: underline;">Valid argument</span></a> - An argument is valid when it contains no logical fallacies</li>
<li><a href="http://wiki.lesswrong.com/wiki/Valley_of_bad_rationality">Valley of bad rationality</a> - It has been observed that when someone is just starting to learn rationality, they appear to be worse off than they were before. Others, with more experience at rationality, claim that after you learn more about rationality, you will be better off than you were before you started. The period before this improvement is known as "the valley of bad rationality".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Wisdom_of_the_crowd"><span style="text-decoration: underline;">Wisdom of the crowd</span></a> &#x2013; is the collective opinion of a group of individuals rather than that of a single expert. A large group's aggregated answers to questions involving quantity estimation, general world knowledge, and spatial reasoning has generally been found to be as good as, and often better than, the answer given by any of the individuals within the group.</li>
<li><a href="/lw/od/37_ways_that_words_can_be_wrong/">Words can be wrong</a> &#x2013; There are many ways that words can be wrong it is for this reason that we should avoid arguing by definition. Instead, to facilitate communication we can <a href="/lw/nu/taboo_your_words/">taboo</a> and <a href="/lw/on/reductionism/">reduce</a>: we can <a href="/lw/nv/replace_the_symbol_with_the_substance/">replace the symbol with the substance</a> and talk about facts and <a href="/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/">anticipations</a>, not definitions.</li>
</ul>
<h1>Instrumental</h1>
<h2><a name="instrumentalB"></a>Barriers, biases, fallacies, impediments and problems</h2>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Akrasia"><span style="text-decoration: underline;">Akrasia</span></a> - the state of acting against one's better judgment. Note that, for example, if you are procrastinating because it's not in your best interest to complete the task you are delaying, it is not a case of akrasia.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Alief">Alief</a>&#xA0;- an independent source of emotional reaction which can coexist with a contradictory belief. For example, the fear felt when a monster jumps out of the darkness in a scary movie is based on the alief that the monster is about to attack you, even though you believe that it cannot.</li>
<li><a href="/lw/6l6/physical_and_mental_behavior/4i4c">Effort Shock</a> - the unpleasant discovery of how hard it is to accomplish something.</li>
</ul>
<h2><a name="instrumentalT"></a>Techniques/Concepts</h2>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Ambient_decision_theory">Ambient decision theory</a> - A variant of <a href="http://wiki.lesswrong.com/wiki/Updateless_decision_theory">updateless decision theory</a> that uses first order logic instead of mathematical intuition module (MIM), emphasizing the way an agent can <a href="/lw/2os/controlling_constant_programs/">control which mathematical structure a fixed definition defines</a>, an aspect of UDT separate from its own emphasis on not making the mistake of updating away things one can still acausally control.</li>
<li><a href="/lw/jis/tell_culture/">Ask, Guess and Tell culture</a>&#xA0;- The two basic rules of Ask Culture: 1) Ask when you want something. 2) Interpret things as requests and feel free to say "no". The two basic rules of Guess Culture: 1) Ask for things if, and *only* if, you're confident the person will say "yes". 2)&#xA0;<span style="white-space: pre;"> </span>Interpret requests as expectations of "yes", and, when possible, avoid saying "no".The two basic rules of Tell Culture: 1) Tell the other person what's going on in your own mind whenever you suspect&#xA0;<span style="white-space: pre;"> </span>you'd both benefit from them knowing. (Do NOT assume others will accurately model your mind without your help, or that it will even occur to them to ask you questions to eliminate their ignorance.) 2) Interpret things people tell you as attempts to create common knowledge for shared benefit, rather than as requests or as presumptions of compliance.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Burch%27s_law">Burch's law</a> &#x2013; &#x201C;I think people should have a right to be stupid and, if they have that right, the market's going to respond by supplying as much stupidity as can be sold.&#x201D; &#x2014;<a href="http://www.gregburch.net/cars/suvs.html"><em>Greg Burch</em></a> A corollary of Burch's Law is that any <a href="http://wiki.lesswrong.com/wiki/Bias">bias</a> should be regarded as a potential vulnerability whereby the market can trick one into buying something one doesn't really want.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Challenging_the_Difficult"><span style="text-decoration: underline;">Challenging the Difficult</span></a> - A <a href="http://wiki.lesswrong.com/wiki/Sequence">sequence</a> on how to do things that are difficult or "impossible".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Cognitive_style">Cognitive style</a>&#xA0;- Certain cognitive styles might tend to produce more accurate results. A common distinction between cognitive styles is that of foxes vs. hedgehogs. Hedgehogs view the world through the lens of a single defining idea and foxes draw on a wide variety of experiences and for whom the world cannot be boiled down to a single idea. Foxes tend to be better&#xA0;<a href="http://wiki.lesswrong.com/wiki/Calibration">calibrated</a>&#xA0;and more accurate.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Consequentialism"><span style="text-decoration: underline;">Consequentialism</span></a> - the ethical theory that people should choose the action that will result in the best outcome.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Crocker%27s_rules">Crocker's rules</a>&#xA0;- By declaring commitment to Crocker's rules, one authorizes other debaters to&#xA0;<a href="http://wiki.lesswrong.com/wiki/Optimization">optimize</a>&#xA0;their messages for information, even when this entails that emotional feelings will be disregarded. This means that you have accepted full responsibility for the operation of your own mind, so that if you're offended, it's your own fault.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Dark_arts">Dark arts</a>&#xA0;- refers to rhetorical techniques crafted to exploit human&#xA0;<a href="http://wiki.lesswrong.com/wiki/Cognitive_biases">cognitive biases</a>&#xA0;in order to persuade, deceive, or otherwise manipulate a person into irrationally accepting beliefs perpetuated by the practitioner of the Arts. Use of the dark arts is especially common in sales and similar situations (known as hard sell in the sales business) and promotion of political and religious views.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Egalitarianism">Egalitarianism</a>&#xA0;- the idea that everyone should be considered equal. Equal in merit, equal in opportunity, equal in morality, and equal in achievement. Dismissing egalitarianism is not opposed to&#xA0;<a href="http://wiki.lesswrong.com/wiki/Humility">humility</a>, even though from the<a href="http://wiki.lesswrong.com/wiki/Signaling">signaling</a>&#xA0;perspective it seems to be opposed to&#xA0;<a href="http://wiki.lesswrong.com/wiki/Modesty">modesty</a>.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Expected_utility">Expected utility</a></span> - the <a href="http://wiki.lesswrong.com/wiki/Expected_value">expected value</a> in terms of the <a href="http://wiki.lesswrong.com/wiki/Utility">utility</a> produced by an action. It is the sum of the utility of each of its possible consequences, individually weighted by their respective probability of occurrence. rational decision maker will, when presented with a choice, take the action with the greatest expected utility.</li>
<li><a href="/lw/oo/explaining_vs_explaining_away/">Explaining vs. explaining away</a> &#x2013; Explaining something does not subtract from its beauty. It in fact heightens it. Through understanding it, you gain greater awareness of it. Through understanding it, you are more likely to notice its similarities and interrelationships with others things. Through understanding it, you become able to see it not only on one level, but on multiple. In regards to the delusions which people are emotionally attached to, that which can be destroyed by the truth should be.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Fuzzies">Fuzzies</a>&#xA0;- A hypothetical measurement unit for "warm fuzzy feeling" one gets from believing that one has done good. Unlike&#xA0;<a href="http://wiki.lesswrong.com/wiki/Utils">utils</a>, fuzzies can be earned through psychological tricks without regard for efficiency. For this reason, it may be a good idea to separate the concerns for actually doing good, for which one might need to&#xA0;<a href="http://wiki.lesswrong.com/wiki/Shut_up_and_multiply">shut up and multiply</a>, and for earning fuzzies, to get psychological comfort.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Game_theory">Game theory</a>&#xA0;- attempts to mathematically model interactions between individuals.</li>
<li><a href="/lw/dr/generalizing_from_one_example/">Generalizing from One Example</a>&#xA0;- an incorrect generalisation when you only have direct first-person knowledge of one mind, psyche or social circle and you treat it as typical even in the face of contrary evidence.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Goodhart%27s_law">Goodhart&#x2019;s law</a>&#xA0;- states that once a certain indicator of success is made a target of a social or economic policy, it will lose the information content that would qualify it to play such a role. People and institutions try to achieve their explicitly stated targets in the easiest way possible, often obeying the letter of the law. This is often done in way that the designers of the law did not anticipate or want. For example, the soviet factories which when given targets on the basis of numbers of nails produced many tiny useless nails and when given targets on basis of weight produced a few giant nails.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Hedonism">Hedonism</a>- refers to a set of philosophies which hold that the highest goal is to maximize pleasure, or more precisely pleasure minus pain.</li>
<li><a href="/lw/2p5/humans_are_not_automatically_strategic/">Humans Are Not Automatically Strategic</a>&#xA0;- most courses of action are extremely ineffective and most of the time there has been no strong evolutionary or cultural force sufficient to focus us on the very narrow behavior patterns that would actually be effective. When this is coupled with the fact that people tend to spend a lot less effort on planning how to go about a reaching a goal rather than just trying to achieve it you end up with the conclusion that humans are not automatically strategic.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Human_universal">Human universal</a>&#xA0;- Donald E. Brown has compiled a list of&#xA0;<a href="http://condor.depaul.edu/~mfiddler/hyphen/humunivers.htm">over a hundred human universals</a>&#xA0;- traits found in every culture ever studied, most of them so universal that anthropologists don't even bother to note them explicitly.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Instrumental_value">Instrumental value</a> - a value pursued for the purpose of achieving other values. Values which are pursued for their own sake are called <a href="http://wiki.lesswrong.com/wiki/Terminal_value">terminal values</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Intellectual_roles">Intellectual roles</a>&#xA0;-&#xA0;<a href="http://wiki.lesswrong.com/wiki/Group_rationality">Group rationality</a>&#xA0;may be improved when members of the group take on specific intellectual roles. While these roles may be incomplete on their own, each embodies an aspect of proper&#xA0;<a href="http://wiki.lesswrong.com/wiki/Rationality">rationality</a>. If certain roles are biased against, purposefully adopting them might&#xA0;<a href="http://wiki.lesswrong.com/wiki/Debiasing">reduce bias</a>.</li>
<li><a href="/lw/mb/lonely_dissent/">Lonely Dissenters</a> suffer social disapproval, but are required - <a href="/lw/m9/aschs_conformity_experiment/">Asch's conformity experiment</a> showed that the presence of a single dissenter tremendously reduced the incidence of "conforming" wrong answers.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Loss_aversion">Loss Aversion</a> - is <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Risk_aversion&amp;action=edit&amp;redlink=1">risk aversion</a>'s evil twin. A loss-averse agent tends to avoid uncertain gambles, not because every unit of money brings him a bit less utility, but because he weighs losses more heavily than gains, always treating his current level of money as somehow special.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Luminosity"><span style="text-decoration: underline;">Luminosity</span></a> - reflective awareness. A luminous mental state is one that you have and know that you have. It could be an <a href="http://wiki.lesswrong.com/wiki/Emotion">emotion</a>, a <a href="http://wiki.lesswrong.com/wiki/Belief">belief</a> or <a href="http://wiki.lesswrong.com/wiki/Alief">alief</a>, a disposition, a quale, a memory - anything that might happen or be stored in your brain. What's going on in your head?</li>
<li><a href="http://wiki.lesswrong.com/wiki/Marginally_zero-sum_game">Marginally zero-sum game</a> also known as 'arms race' - A zero-sum game where the efforts of each player not just give them a benefit at the expense of the others, but decrease the efficacy of everyone's past and future actions, thus making everyone's actions extremely inefficient in the limit.</li>
<li><a href="http://www.moralfoundations.org/">Moral Foundations theory</a> (all moral rules in all human cultures appeal to the six moral foundations: care/harm, fairness/cheating, liberty/oppression,loyalty/betrayal, authority/subversion, sanctity/degradation). This makes other people's moralities easier to understand, and is an interesting lens through which to examine your own.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Moral_uncertainty"><span style="text-decoration: underline;">Moral uncertainty</span></a> &#x2013; is uncertainty about how to act given the diversity of moral doctrines. Moral uncertainty includes a level of uncertainty above the more usual uncertainty of <a href="http://wiki.lesswrong.com/wiki/Decision_theory">what to do given incomplete information</a>, since it deals also with uncertainty about which moral theory is right. Even with complete information about the world this kind of uncertainty would still remain</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Paranoid_debating">Paranoid debating</a></span>&#xA0;- a group estimation game in which one player, unknown to the others, tries to subvert the group estimate.</li>
<li><a href="/lw/2qq/politics_as_charity/" target="_blank">Politics as charity</a>: in terms of expected value, altruism is a reasonable motivator for voting (as opposed to common motivators like "wanting to be heard").</li>
<li><a href="http://wiki.lesswrong.com/wiki/Prediction">Prediction</a>&#xA0;- a statement or claim that a particular event will occur in the future in more certain terms than a&#xA0;<a href="http://wiki.lesswrong.com/wiki/Forecast">forecast</a>.</li>
<li><a href="/lw/hba/privileging_the_question/">Privileging the question</a> - questions that someone has unjustifiably brought to your attention in the same way that a privileged hypothesis unjustifiably gets brought to your attention. Examples are: should gay marriage be legal? Should Congress pass stricter gun control laws? Should immigration policy be tightened or relaxed? The problem with privileged questions is that you only have so much attention to spare. Attention paid to a question that has been privileged <a href="http://en.wikipedia.org/wiki/Fungibility">funges against</a> attention you could be paying to better questions. Even worse, it may not feel from the inside like anything is wrong: you can apply all of the epistemic rationality in the world to answering a question like "should Congress pass stricter gun control laws?" and never once ask yourself where that question came from and whether there are better questions you could be answering instead.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Radical_honesty">Radical honesty</a>- a communication technique proposed by&#xA0;<a href="http://en.wikipedia.org/wiki/Brad_Blanton">Brad Blanton</a>&#xA0;in which discussion partners are not permitted to lie or deceive at all. Rather than being designed to enhance&#xA0;<a href="http://wiki.lesswrong.com/wiki/Group_rationality">group</a>&#xA0;<a href="http://wiki.lesswrong.com/wiki/Epistemic_rationality">epistemic rationality</a>, radical honesty is designed to reduce stress and remove the layers of deceit that burden much of discourse.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Reflective_decision_theory">Reflective decision theory</a></span> - a term occasionally used to refer to a decision theory that would allow an agent to take actions in a way that does not trigger regret. This regret is conceptualized, according to the <a href="http://wiki.lesswrong.com/wiki/Causal_Decision_Theory">Causal Decision Theory</a>, as a <a href="http://wiki.lesswrong.com/wiki/Reflective_inconsistency">Reflective inconsistency</a>, a divergence between the agent who took the action and the same agent reflecting upon it after.</li>
<li><a href="/lw/14a/thomas_schellings_strategy_of_conflict/">Schelling</a>&#xA0;point &#x2013; is a solution that people will tend to use in the absence of communication, because it seems natural, special, or relevant to them.</li>
<li><a href="/lw/ase/schelling_fences_on_slippery_slopes/">Schelling fences and slippery slopes</a>&#xA0;&#x2013; a slippery slope is something that affects people's willingness or ability to oppose future policies. Slippery slopes can sometimes be avoided by establishing a "Schelling fence" - a Schelling point that the various interest groups involved - or yourself across different values and times - make a credible precommitment to defend.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Something_to_protect">Something to protect</a>&#xA0;- The Art must have a purpose other than itself, or it collapses into infinite recursion.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Status">Status</a>&#xA0;- Real or perceived relative measure of social standing, which is a function of both resource control and how one is viewed by others.</li>
<li><a href="/lw/or/joy_in_the_merely_real/">Take joy in the merely real</a> &#x2013; If you believe that science coming to know about something places it into the dull catalogue of common things, then you're going to be disappointed in pretty much everything eventually &#x2014;either it will turn out not to exist, or even worse, it will turn out to be real. Another way to think about it is that if the magical and mythical were common place they would be merely real. If dragons were common, but zebras were a rare legendary creature then there's a certain sort of person who would ignore dragons, who would never bother to look at dragons, and chase after rumors of zebras. The grass is always greener on the other side of reality. If we cannot take joy in the merely real, our lives shall be empty indeed.</li>
<li><a href="http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life"><span style="text-decoration: underline;">The Science of Winning at Life</span></a> - A <a href="http://wiki.lesswrong.com/wiki/Sequence">sequence</a> by <a href="/user/lukeprog/">lukeprog</a> that summarizes scientifically-backed advice for "<a href="http://wiki.lesswrong.com/wiki/Winning">winning</a>" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Timeless_decision_theory">Timeless decision theory</a> - a <a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a>, which in slogan form, says that agents should decide as if they are determining the output of the abstract computation that they implement. This theory was developed in response to the view that rationality should be about winning (that is, about agents achieving their desired ends) rather than about behaving in a manner that we would intuitively label as rational.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Unfriendly_artificial_intelligence">Unfriendly artificial intelligence</a>&#xA0;- is an&#xA0;<a href="http://wiki.lesswrong.com/wiki/Artificial_general_intelligence">artificial general intelligence</a>&#xA0;capable of causing&#xA0;<a href="http://wiki.lesswrong.com/wiki/Existential_risk">great harm</a>&#xA0;to humanity, and having goals that&#xA0;<a href="http://wiki.lesswrong.com/wiki/Instrumental_values">make it useful</a>&#xA0;for the AI to do so. The AI's goals don't need to be antagonistic to humanity's goals for it to be Unfriendly; there are&#xA0;<a href="http://wiki.lesswrong.com/wiki/Basic_AI_drives">strong reasons</a>&#xA0;to expect that almost any powerful AGI not explicitly programmed to be benevolent to humans is lethal.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Updateless_decision_theory">Updateless decision theory</a> &#x2013; a decision theory in which we give up the idea of doing Bayesian reasoning to obtain a posterior distribution etc. and instead just choose the action (or more generally, the probability distribution over actions) that will maximize the unconditional expected utility.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Ugh_field"><span style="text-decoration: underline;">Ugh field</span></a> - Pavlovian conditioning can cause humans to unconsciously flinch from even thinking about a serious personal problem they have. We call it an "ugh field". The ugh field forms a self-shadowing blind spot covering an area desperately in need of optimization.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Utilitarianism"><span style="text-decoration: underline;">Utilitarianism</span></a> - A moral philosophy that says that what matters is the sum of everyone's welfare, or the "greatest good for the greatest number".</li>
<li><a href="http://wiki.lesswrong.com/wiki/Utility"><span style="text-decoration: underline;">Utility</span></a> - how much a certain outcome satisfies an agent&#x2019;s preferences.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Utility_function"><span style="text-decoration: underline;">Utility function</span></a> - assigns numerical values ("utilities") to outcomes, in such a way that outcomes with higher utilities are always <a href="http://wiki.lesswrong.com/wiki/Preference">preferred</a> to outcomes with lower utilities. These do not work very well in practice for individual humans</li>
<li><a href="http://wiki.lesswrong.com/wiki/Wanting_and_liking"><span style="text-decoration: underline;">Wanting and liking</span></a> - The <a href="http://en.wikipedia.org/wiki/Reward_system">reward system</a> consists of three major components: <ul>
<li><em>Liking</em>: The 'hedonic impact' of reward, comprised of (1) neural processes that may or may not be conscious and (2) the conscious experience of pleasure.</li>
<li><em>Wanting</em>: Motivation for reward, comprised of (1) processes of 'incentive salience' that may or may not be conscious and (2) conscious desires.</li>
<li><em>Learning</em>: Associations, representations, and predictions about future rewards, comprised of (1) <em>explicit </em>predictions and (2) <em>implicit</em> knowledge and associative conditioning (e.g. <a href="http://en.wikipedia.org/wiki/Classical_conditioning">Pavlovian associations</a>).</li>
</ul>
</li>
</ul>
<h1><a name="positions"></a>Positions</h1>
<ul>
<li><a href="http://wiki.lesswrong.com/wiki/Beliefs_require_observations"><span style="text-decoration: underline;">Beliefs require observations</span></a> - To form accurate <a href="http://wiki.lesswrong.com/wiki/Belief">beliefs</a> about something, you really do have to observe it. This can be viewed as a special case of the second law of <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Thermodynamics&amp;action=edit&amp;redlink=1">thermodynamics</a>, in fact, since "knowledge" is correlation of belief with reality, which is mutual information, which is a form of negentropy.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Complexity_of_value"><span style="text-decoration: underline;">Complexity of value</span></a> - the thesis that human values have high <a href="http://wiki.lesswrong.com/wiki/Kolmogorov_complexity">Kolmogorov complexity</a> and so cannot be summed up or compressed into a few simple rules. It includes the idea of <a href="/lw/y3/value_is_fragile/">fragility of value</a> which is the thesis that losing even a small part of the rules that make up our values could lead to results that most of us would now consider as unacceptable.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Egan%27s_law"><span style="text-decoration: underline;">Egan's law</span></a> - "It all adds up to normality." &#x2014; <a href="http://en.wikipedia.org/wiki/Greg_Egan"><span style="text-decoration: underline;">Greg Egan</span></a><a href="http://en.wikipedia.org/wiki/Quarantine_(Greg_Egan_novel)">. The purpose of a theory is to add up to observed reality, rather than something else. Science sets out to answer the question "What adds up to normality?" and the answer turns out to be </a><a href="http://wiki.lesswrong.com/wiki/Quantum_mechanics">Quantum mechanics</a> adds up to normality. A weaker <a href="/lw/sk/changing_your_metaethics/">extension</a> of this principle applies to ethical and meta-ethical debates, which generally ought to end up explaining why you shouldn't eat babies, rather than why you should.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Emotion"><span style="text-decoration: underline;">Emotion</span></a> - Contrary to the stereotype, <a href="http://wiki.lesswrong.com/wiki/Rationality">rationality</a> doesn't mean denying emotion. When emotion is appropriate to the reality of the situation, it should be embraced; only when emotion isn't appropriate should it be suppressed.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Futility_of_chaos">Futility of chaos</a> - A complex of related ideas having to do with the impossibility of generating useful work from entropy &#x2014; a position which holds against the ideas that e.g: Our artistic creativity stems from the noisiness of human neurons, randomized algorithms can exhibit performance inherently superior to deterministic algorithms and the human brain is a chaotic system and this explains its power; non-chaotic systems cannot exhibit intelligence.</li>
<li><a href="http://wiki.lesswrong.com/wiki/General_knowledge"><span style="text-decoration: underline;">General knowledge</span></a> - Interdisciplinary, generally applicable knowledge is rarely taught explicitly. Yet it's important to have at least basic knowledge of many areas (as opposed to deep narrowly specialized knowledge), and to apply it to thinking about everything.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Hope"><span style="text-decoration: underline;">Hope</span></a> - Persisting in clutching to a hope may be disastrous. Be ready to admit you lost, <a href="http://wiki.lesswrong.com/wiki/Update">update</a> on the data that says you did.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Humility"><span style="text-decoration: underline;">Humility</span></a> &#x2013; &#x201C;To be humble is to take specific actions in anticipation of your own errors. To confess your fallibility and then do nothing about it is not humble; it is boasting of your modesty.&#x201D; &#x2014;<a href="http://yudkowsky.net/rational/virtues"><span style="text-decoration: underline;">Twelve Virtues of Rationality</span></a> Not to be confused with <a href="http://wiki.lesswrong.com/wiki/Social_modesty">social modesty</a>, or <a href="http://wiki.lesswrong.com/wiki/Motivated_skepticism">motivated skepticism</a> (aka <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=Disconfirmation_bias&amp;action=edit&amp;redlink=1">disconfirmation bias</a>).</li>
<li><a href="http://wiki.lesswrong.com/wiki/I_don%27t_know"><span style="text-decoration: underline;">I don't know</span></a> - in real life, you are constantly making decisions under uncertainty: <a href="http://wiki.lesswrong.com/mediawiki/index.php?title=The_null_plan_is_still_a_plan&amp;action=edit&amp;redlink=1">the null plan is still a plan</a>, refusing to choose is itself a choice, and by your choices, you implicitly take bets at some odds, whether or not you explicitly conceive of yourself as doing so.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Litany_of_Gendlin"><span style="text-decoration: underline;">Litany of </span><span style="text-decoration: underline;">Gendlin</span></a> &#x2013; &#x201C;What is true is already so. Owning up to it doesn't make it worse. Not being open about it doesn't make it go away. And because it's true, it is what is there to be interacted with. Anything untrue isn't there to be lived. People can stand what is true, for they are already enduring it.&#x201D; &#x2014;<a href="http://en.wikipedia.org/wiki/Eugene_Gendlin"><span style="text-decoration: underline;">Eugene </span><span style="text-decoration: underline;">Gendlin</span></a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Litany_of_Tarski"><span style="text-decoration: underline;">Litany of </span><span style="text-decoration: underline;">Tarski</span></a> &#x2013; &#x201C;If the box contains a diamond, I desire to believe that the box contains a diamond; If the box does not contain a diamond, I desire to believe that the box does not contain a diamond; Let me not become attached to beliefs I may not want. &#x201C; &#x2014;<a href="/lw/jz/the_meditation_on_curiosity/"><span style="text-decoration: underline;">The Meditation on Curiosity</span></a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Lottery"><span style="text-decoration: underline;">Lottery</span></a> - A tax on people who are bad at math. Also, a waste of <a href="http://wiki.lesswrong.com/wiki/Hope">hope</a>. You <a href="http://wiki.lesswrong.com/wiki/Antiprediction">will not</a> win the lottery.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Magic"><span style="text-decoration: underline;">Magic</span></a> - What seems to humans like a simple explanation, sometimes <a href="http://wiki.lesswrong.com/wiki/Occam%27s_razor">isn't at all</a>. In our own naturalistic, <a href="http://wiki.lesswrong.com/wiki/Reductionism">reductionist</a> universe, there is always a simpler explanation. Any complicated thing that happens, happens because there is some physical mechanism behind it, even if you don't know the mechanism yourself (which is most of the time). There is no magic.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Modesty_argument"><span style="text-decoration: underline;">Modesty argument</span></a> - the claim that when two or more rational agents have <a href="http://wiki.lesswrong.com/wiki/Common_knowledge">common knowledge</a> of a <a href="http://wiki.lesswrong.com/wiki/Disagreement">disagreement</a> over the likelihood of an issue of simple fact, they should each adjust their probability estimates in the direction of the others'. This process should continue until the two agents are in full agreement. Inspired by <a href="http://wiki.lesswrong.com/wiki/Aumann%27s_agreement_theorem">Aumann's agreement theorem</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/No_safe_defense"><span style="text-decoration: underline;">No safe </span><span style="text-decoration: underline;">defense</span></a> - Authorities can be trusted exactly as much as a rational evaluation of the evidence deems them trustworthy, no more and no less. There's no one you can trust absolutely; the full force of your skepticism must be applied to everything.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Offense"><span style="text-decoration: underline;">Offense</span></a> - It is hypothesized that the <a href="http://wiki.lesswrong.com/wiki/Emotion">emotion</a> of offense appears when one perceives an attempt to gain <a href="http://wiki.lesswrong.com/wiki/Status">status</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Slowness_of_evolution">Slowness of evolution</a>- The tremendously slow timescale of evolution, especially for creating new complex machinery (as opposed to selecting on existing variance), is why the behavior of evolved organisms is often better interpreted&#xA0;<a href="http://wiki.lesswrong.com/wiki/Adaptation_executers">in terms of what did in fact work yesterday, rather than what will work in the future</a>.</li>
<li><span style="text-decoration: underline;"><a href="http://wiki.lesswrong.com/wiki/Stupidity_of_evolution">Stupidity of evolution</a></span> - <a href="http://wiki.lesswrong.com/wiki/Evolution">Evolution</a> can only access a very limited area in the design space, and can only search for the new designs very slowly, for a variety of reasons. The wonder of evolution is not how intelligently it works, but that an accidentally occurring optimizer without a brain works at all.</li>
</ul></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mpm/rudimentary_categorization_of_less_wrong_topics/#comments">Comments (5)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mpm' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mkz" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mkz/rationality_compendium_principle_2_you_are/">
Rationality Compendium: Principle 2 - You are implemented on a human brain
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mkz'
title="100% positive"
>
5
</span>

</span>
<span class="author">
<a id="author_t3_mkz" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">29 August 2015 04:24PM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mkz" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>Irrationality is ingrained in our humanity. It is fundamental to who we are. This is because being human means that you are implemented on&#xA0;kludgy and limited wetware (a human brain). A consequence of this is&#xA0;that&#xA0;biases&#xA0;<a href="#bias">&#x2193;</a><a name="biasBack"></a>&#xA0;and irrational thinking&#xA0;are not mistakes, persay,&#xA0;they are not misfirings or accidental activations of neurons.&#xA0;They are the default mode of operation for wetware that has been optimized for purposes other than truth maximization.</p>
<p>&#xA0;</p>
<p>If you want something to blame for the fact that you are innately irrational, then you can blame evolution&#xA0;<a href="#evolution">&#x2193;</a><a name="evolutionBack"></a>. Evolution tends to not to produce optimal organisms, but instead produces ones that are kludgy&#xA0;<a href="#kludge">&#x2193;</a><a name="kludgeBack"></a>, limited and optimized for criteria relating to ancestral environments rather than for criteria relating to optimal thought.</p>
<p>&#xA0;</p>
<p>A kludge is a clumsy or inelegant, yet surprisingly effective, solution to a problem. The human brain is an example of a kludge. It contains many distinct substructures dating from widely separated periods of evolutionary development&#xA0;<a href="#differentSubStructures">&#x2193;</a><a name="differentSubStructuresBack"></a>. An example of this is the two kinds of processes in human cognition where one is fast (type 1) and the other is slow (type2)&#xA0;<a href="#cognitionTypes">&#x2193;</a><a name="cognitionTypesBack"></a>.&#xA0;</p>
<p>There are many other characteristics of the brain that induce irrationality. The main ones are that:</p>
<ul>
<li>The brain is innately limited in its computational abilities and so it must use heuristics&#xA0;<a href="#heuristics">&#x2193;</a><a style="background-color: #ffffff;" name="heuristicsBack"></a>,&#xA0;which&#xA0;are&#xA0;mental shortcuts that ease the cognitive load of making a&#xA0;decision.&#xA0;</li>
<li>The brain has a tendency to blindly use salient or pre-existing responses to answers rather than developing new answers or thoroughly checking pre-existing solutions&#xA0;<a href="#cachedThoughts">&#x2193;</a><a style="background-color: #ffffff;" name="cachedThoughtsBack"></a>.&#xA0;</li>
<li>The brain does not inherently value truth. One of the main reasons for this is that many of the biases can actually be adaptive. An example of an adaptive bias is the&#xA0;sexual over perception bias&#xA0;<a href="#sexualOverPerceptionBias">&#x2193;</a><a style="background-color: #ffffff;" name="sexualOverPerceptionBiasBack"></a> in men. From a truth-maximization perspective young men who assume that all women want them are showing severe social-cognitive inaccuracies, judgment biases, and probably narcissistic personality disorder. However, from an evolutionary perspective, the same young men are behaving in a more optimal manner. One which has consistently maximized the reproductive success of their male ancestors. Another similar example is the bias for positive perception of partners&#xA0;<a href="#postivePartnersBias">&#x2193;</a><a style="background-color: #ffffff;" name="postivePartnersBiasBack"></a>.</li>
<li>The brain acts more like a coherence maximiser than a truth maximiser, which makes people&#xA0;liable to believing falsehoods&#xA0;<a href="#religionNaturual">&#x2193;</a><a name="religionNaturualBack"></a>. If you want to believe something or you are often in situations in which two things just happen to be related then your brain is often by default going to treat them as if they were right&#xA0;<a href="#sympatheticMagic">&#x2193;</a><a name="sympatheticMagicBack"></a>.&#xA0;</li>
<li>The brain trusts its own version of reality much more than other peoples. This makes people defend their beliefs even when doing so is extremely irrational <a href="#rationalisation">&#x2193;</a><a name="rationalisationBack"></a>. It is also makes it hard for people to change their minds&#xA0;<a href="#weDontChangeOurMinds">&#x2193;</a><a name="weDontChangeOurMindsBack"></a> and to&#xA0;accept when they are wrong <a href="#opps">&#x2193;</a><a name="oppsBack"></a></li>
<li>Disbelief requires System 2 thought&#xA0;<a href="#disbelief">&#x2193;</a><a name="disbeliefBack"></a>. This means that if system 2 is engaged then we are liable to believe pretty much anything. System 1 is gullible and biased to believe. It is system 2 that is in charge of doubting and disbelieving.</li>
</ul>
<p>One important non-brain related factor is that we must make use of and live with our current adaptations&#xA0;<a href="#adaptionExecutors">&#x2193;</a><a name="adaptionExecutorsBack"></a>. People cannot reconform themselves to fulfill purposes suitable to their current environment, but must instead make use of pre-existing machinery that has been optimised for other environments. This means that there is probably never going to be any miracle cures to irrationality because eradicating it would require that you were so fundamentally altered that you were no longer human.</p>
<p>&#xA0;</p>
<p>One of the first major steps on the path to becoming more rational, is the realisation that you are not only by default&#xA0;irrational, but that you&#xA0;are always fundamentally comprimised. This doesn't mean that improving your rationality is impossible. It just means that if you stop applying your knowledge of what improves rationality then you will slip back into irrationality. This is because the brain is a kludge. It works most of the time, but in some cases its innate and natural course of action must be diverted if we are to be rational. The good news is that this kind of diversion is possible. This is because humans possess second order thinking <a href="#flawedLens">&#x2193;</a><a name="flawedLensBack"></a>. This means that they&#xA0;can observe their inherent flaws and&#xA0;systematic errors.&#xA0;They can then through&#xA0;studying the laws of thought and action apply second order corrections and from doing so become more rational. &#xA0;</p>
<p>&#xA0;</p>
<p>The process of applying these second order corrections or training yourself to mitigate the effects of your propensities is called debiasing&#xA0;<a href="#debiasing">&#x2193;</a><a name="debiasingBack"></a>. Debiasing is not a thing that you can do once and then forget about. It is something that you must either be doing constantly&#xA0;or that you must instill into habits so that it occurs without volitional effort. There are generally three main types of debaising and they are described below:&#xA0;</p>
<ul>
<li>Counteracting the effects of bias - this can be done by adjusting your estimates or opinions in order to avoid errors due to biases. This is probably the hardest of the three types of debiasing because&#xA0;to do it correctly you need to know exactly how much you are already biased. This is something that people are rarely aware of.</li>
<li>Catching yourself when you are being or could be biased and applying a cogntive override.&#xA0;The basic idea behind&#xA0;this is that you observe and track your own thoughts and emotions so that you can catch yourself before you move to deeply into irrational modes of thinking. This is hard because it requires that you have superb self-awareness skills and these often take a long time to develop and train. Once you have caught yourself it is often best to resort to using formal thought in algebra, logic, probability theory or decision theory etc. It is also useful to instill habits in yourself that would allow this observation to occur without conscious and volitional effort. It should be noted that incorrectly applying the first two methods of debiasing can actually make you more biased and that this is a common conundrum and problem faced by beginners to rationality training&#xA0;<a href="#rationalityIsHard">&#x2193;</a><a style="background-color: #ffffff;" name="rationalityIsHardBack"></a>.&#xA0;</li>
<li>Understanding the situations which make you biased so that you can avoid them&#xA0;<a href="#shutupAndMultiply">&#x2193;</a><a name="shutupAndMultiplyBack"></a>&#xA0;-&#xA0;the best way to achieve this is simply to ask yourself: how can I become more objective? You do this by taking your biased and faulty perspective as much as possible out of the equation. For example, instead of taking measurements yourself you could get them taken automatically by some scientific instrument.</li>
</ul>
<hr>
<p align="center"><strong>Related Materials</strong></p>
<p><strong>Wikis:</strong></p>
<ul type="disc">
<li><a name="bias"></a><a href="http://wiki.lesswrong.com/wiki/Bias">Bias</a> - refers to the obstacles to truth which are produced by our kludgy and limited wetware (brains) working exactly the way that they should.<strong>&#xA0;</strong><a href="#biasBack">&#x21A9;</a></li>
<li><a name="evolution"></a><a href="http://wiki.lesswrong.com/wiki/Evolutionary_psychology">Evolutionary psychology</a>&#xA0;- the idea of evolution as the idiot designer of humans - that our brains are&#xA0;not&#xA0;consistently well-designed - is a key element of many of the&#xA0;explanations of human errors&#xA0;that appear on this website.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Slowness_of_evolution">Slowness of evolution</a>- The tremendously slow timescale of evolution, especially for creating new complex machinery (as opposed to selecting on&#xA0;existing&#xA0;variance), is why the behavior of evolved organisms is often better interpreted&#xA0;<a href="http://wiki.lesswrong.com/wiki/Adaptation_executers" title="Adaptation executers">in terms of what did in fact work&#xA0;</a>&#xA0;<a href="#evolutionBack">&#x21A9;</a></li>
<li><a name="differentSubStructures"></a><a href="http://wiki.lesswrong.com/wiki/Alief">Alief</a>&#xA0;- an independent source of emotional reaction which can coexist with a contradictory belief. For example, the fear felt when a monster jumps out of the darkness in a scary movie is based on the alief that the monster is about to attack you, even though you believe that it cannot.&#xA0;</li>
<li><a href="http://wiki.lesswrong.com/wiki/Wanting_and_liking">Wanting and liking</a>&#xA0;-&#xA0;The&#xA0;<span style="text-decoration: underline;"><a href="http://en.wikipedia.org/wiki/Reward_system">reward system</a>&#xA0;</span>consists of three major components: <ul type="disc">
<li><em>Liking</em>: The 'hedonic impact' of reward, comprised of (1) neural processes&#xA0;that may or may not be conscious and (2) the conscious experience of pleasure.</li>
<li><em>Wanting</em>: Motivation for reward, comprised of (1) processes of&#xA0;'incentive salience'&#xA0;that may or may not be conscious and (2) conscious desires.</li>
<li><em>Learning</em>: Associations, representations, and predictions about future rewards, comprised of (1)&#xA0;<em>explicit</em>predictions and (2)&#xA0;<em>implicit</em>&#xA0;knowledge and associative conditioning (e.g.&#xA0;<span style="text-decoration: underline;"><a href="http://en.wikipedia.org/wiki/Classical_conditioning">Pavlovian associations</a></span>).&#xA0;<a href="#differentSubStructuresBack">&#x21A9;</a></li>
</ul>
</li>
<li><a name="heuristics"></a><a href="http://wiki.lesswrong.com/wiki/Heuristics_and_biases">Heuristics and biases</a>&#xA0;- program in cognitive psychology tries to work backward from&#xA0;<a href="http://wiki.lesswrong.com/wiki/Biases" title="Biases">biases</a>&#xA0;(experimentally reproducible human errors) to&#xA0;<a href="http://wiki.lesswrong.com/wiki/Heuristic" title="Heuristic">heuristics</a>&#xA0;(the underlying mechanisms at work in the brain).&#xA0;<a href="#heuristicsBack">&#x21A9;</a></li>
<li><a name="cachedThoughts"></a><a href="http://wiki.lesswrong.com/wiki/Cached_thought">Cached thought</a>&#xA0;&#x2013; is an answer that was arrived at by recalling a previously-computed conclusion, rather than performing the reasoning from scratch.&#xA0;<a href="#cachedThoughtsBack">&#x21A9;</a>&#xA0;</li>
<li><a name="sympatheticMagic"></a><a href="/sympatheticMagic">Sympathetic Magic</a> -&#xA0;humans seem to naturally generate a series of concepts known as&#xA0;sympathetic magic, a host of theories and practices which have certain principles in common, two of which are of overriding importance: the&#xA0;<a href="http://wiki.lesswrong.com/wiki/Contagion_heuristic">Law of Contagion</a>&#xA0;holds that two things which have interacted, or were once part of a single entity, retain their connection and can exert influence over each other; the Law of Similarity holds that things which are similar or treated the same establish a connection and can affect each other.&#xA0;<a href="#sympatheticMagicBack">&#x21A9;</a></li>
<li><a name="rationalisation"></a><a href="http://wiki.lesswrong.com/wiki/Motivated_cognition">Motivated Cognition</a> -&#xA0;an academic/technical term for various mental processes that lead to desired conclusions regardless of the veracity of those conclusions.&#xA0;&#xA0;&#xA0;</li>
<li><a href="http://wiki.lesswrong.com/wiki/Rationalization">Rationalization</a> - Rationalization starts from a conclusion, and then works backward to arrive at arguments apparently favoring that conclusion. Rationalization argues for a side already selected; rationality tries to choose between sides.&#xA0;&#xA0;<a href="#rationalisationBack">&#x21A9;</a></li>
<li><a name="opps"></a><a href="http://wiki.lesswrong.com/wiki/Oops">Opps</a> - There is a powerful advantage to admitting you have made a large mistake. It's painful. It can also change your whole life. <a href="#oppsBack">&#x21A9;</a></li>
<li><a name="adaptionExecutors"></a><a href="http://wiki.lesswrong.com/wiki/Adaptation_executors">Adaptation executors</a>&#xA0;- Individual organisms are best thought of as adaptation-executers rather than as fitness-maximizers. Our taste buds do not find lettuce delicious and cheeseburgers distasteful once we are fed a diet too high in calories and too low in micronutrients. Tastebuds are adapted to an ancestral environment in which calories, not micronutrients, were the limiting factor. Evolution operates on&#xA0;<a href="http://wiki.lesswrong.com/wiki/Slowness_of_evolution" title="Slowness of evolution">too slow a timescale</a>&#xA0;to re-adapt to adapt to a new conditions (such as a diet).</li>
<li><a href="http://wiki.lesswrong.com/wiki/Corrupted_hardware">Corrupted hardware</a> - our brains do not always allow us to act the way we should. Corrupted hardware refers to those behaviors and thoughts that act for ancestrally relevant purposes rather than for stated moralities and preferences. <a href="#adaptionExecutorsBack">&#x21A9;</a></li>
<li><a name="debiasing"></a><a href="http://wiki.lesswrong.com/wiki/Debiasing">Debiasing</a>&#xA0;- The process of overcoming&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bias" title="Bias">bias</a>. It takes serious study to gain meaningful benefits, half-hearted attempts may accomplish nothing, and partial knowledge of bias may do more&#xA0;<a href="http://wiki.lesswrong.com/wiki/Dangerous_knowledge" title="Dangerous knowledge">harm</a>&#xA0;than good.&#xA0;<a href="#debiasingBack">&#x21A9;</a></li>
<li><a name="rationalityIsHard"></a><a href="http://wiki.lesswrong.com/wiki/Costs_of_rationality">Costs of rationality</a>&#xA0;- Becoming more&#xA0;<a href="http://wiki.lesswrong.com/wiki/Rationality#Epistemic_rationality" title="Rationality">epistemically rational</a>&#xA0;can only guarantee one thing: what you believe will include more of the&#xA0;<a href="http://wiki.lesswrong.com/wiki/Truth" title="Truth">truth</a>. Knowing that truth might&#xA0;<a href="http://wiki.lesswrong.com/wiki/Instrumental_rationality" title="Instrumental rationality">help you achieve your goals</a>, or cause you to become a pariah. Be sure that you really want to know the truth before you commit to finding it; otherwise, you may flinch from it.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Valley_of_bad_rationality">Valley of bad rationality</a>&#xA0;- It has been observed that when someone is just starting to learn rationality, they appear to be worse off than they were before. Others, with more experience at rationality, claim that after you learn more about rationality, you will be better off than you were before you started. The period before this improvement is known as "the valley of bad rationality".</li>
<li><a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect">Dunning&#x2013;Kruger effect</a>&#xA0;- is a&#xA0;<a href="https://en.wikipedia.org/wiki/Cognitive_bias" title="Cognitive bias">cognitive bias</a>&#xA0;wherein unskilled individuals suffer from&#xA0;<a href="https://en.wikipedia.org/wiki/Illusory_superiority" title="Illusory superiority">illusory superiority</a>, mistakenly assessing their ability to be much higher than is accurate. This bias is attributed to a&#xA0;<a href="https://en.wikipedia.org/wiki/Metacognition" title="Metacognition">metacognitive</a>&#xA0;inability of the unskilled to recognize their ineptitude. Conversely, highly skilled individuals tend to underestimate their relative competence, erroneously assuming that tasks that are easy for them are also easy for others.&#xA0;<a href="#rationalityIsHardBack">&#x21A9;</a></li>
<li><a name="shutupAndMultiply"></a><a href="http://wiki.lesswrong.com/wiki/Shut_up_and_multiply">Shut up and multiply</a> -&#xA0;In cases where we can actually do calculations with the relevant quantities. The ability to&#xA0;shut up and multiply, to trust the math&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bite_the_bullet" title="Bite the bullet">even when it feels wrong</a>&#xA0;is a key rationalist skill.&#xA0;<a href="#shutupAndMultiplyBack">&#x21A9;</a>&#xA0;</li>
</ul>
<p><strong>Posts</strong></p>
<ul>
<li><a name="cognitionTypes"></a><a href="/lw/7e5/the_cognitive_science_of_rationality/">Cognitive science of rationality</a> - discusses fast(Type 1), slow (Type 2) processes of cognition, thinking errors and the three kinds of minds (reflective, algorithmic, autonomous).&#xA0;<a href="#cognitionTypesBack">&#x21A9;</a></li>
<li><a name="flawedLens"></a><a href="/lw/jm/the_lens_that_sees_its_flaws/">The Lens That Sees Its Own Flaws</a> - a human brain is a flawed lens that can understand its own flaws&#x2014;its systematic errors, its biases&#x2014;and apply second-order corrections to them.&#xA0;<a href="#flawedLensBack">&#x21A9;</a></li>
<li><a name="weDontChangeOurMinds"></a><a href="/lw/jx/we_change_our_minds_less_often_than_we_think/">We Change Our Minds Less Than We Think</a>&#xA0;- between <a href="/lw/il/hindsight_bias/">hindsight bias</a>, <a href="/lw/is/fake_causality/">fake causality</a>, <a href="/lw/iw/positive_bias_look_into_the_dark/">positive bias</a>, <a href="/lw/j7/anchoring_and_adjustment/">anchoring</a>/priming, et cetera et cetera, and above all the dreaded <a href="/lw/he/knowing_about_biases_can_hurt_people/">confirmation bias</a>, once an idea gets into your head, it's probably going to stay there. <a href="#weDontChangeOurMindsBack">&#x21A9;</a></li>
<li><a href="/r/discussion/lw/mme/you_are_a_brain_intro_to_lwrationality_concepts/">You Are A Brain</a>&#xA0;-&#xA0;'You Are A Brain' is a presentation by Liron Shapira that is tailored for a general audience and provides an introduction to some of the the core LessWrong concepts.&#xA0;</li>
<li><a href="/lw/2bu/your_intuitions_are_not_magic/">Your intuitions are not magic</a>&#xA0;- blindly following our intuitions can cause our careers, relationships or lives to crash and burn, because we did not think of the possibility that we might be wrong.</li>
<li><a href="/lw/p0/to_spread_science_keep_it_secret/">To Spread Science, Keep It Secret</a>&#xA0;- People seem to have&#xA0;<a href="/lw/oy/is_humanism_a_religionsubstitute/">holes in their minds</a>&#xA0;for Esoteric Knowledge, Deep Secrets, the Hidden Truth.&#xA0;We've gotten into the habit of presenting the Hidden Truth in a very unsatisfying way, wrapped up in false mundanity.</li>
</ul>
<p><strong>Popular Books:</strong></p>
<ul>
<li><a name="kludge"></a>Marcus,<a href="http://www.amazon.com/Kluge-Haphazard-Evolution-Human-Mind/dp/054723824X">Kluge: The Haphazard Evolution of the Human Mind</a>&#xA0;<a href="#kludgeBack">&#x21A9;</a></li>
<li>Chabris, <a href="http://www.amazon.com/The-Invisible-Gorilla-Intuitions-Deceive/dp/0307459667">The Invisible Gorilla: How Our Intuitions Deceive Us</a></li>
<li>Kurzban, <a href="http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748/">Why Everyone (Else) Is a Hypocrite: Evolution and the Modular Mind</a><a href="http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748/"> </a></li>
<li>Dawkins, <a href="http://www.amazon.com/Selfish-Gene-Anniversary----Introduction/dp/0199291152/">The Selfish Gene: 30th Anniversary Edition--with a new Introduction by the Author</a></li>
<li><a name="religionNaturual"></a>McCauley,&#xA0; <a href="http://www.amazon.com/Why-Religion-Natural-Science-Not/dp/0199827265/">Why Religion is Natural and Science is Not</a>&#xA0;<a href="#religionNaturualBack">&#x21A9;</a></li>
</ul>
<p><strong>Papers:</strong></p>
<ul>
<li><a name="sexualOverPerceptionBias"></a>Haselton, M. (2003). The sexual overperception bias: Evidence of a systematic bias in men from a survey of naturally occurring events. Journal of Research in Personality, 34-47.</li>
<li>Hasselton, M., &amp; Buss, D. (2000). Error Management Theory: A New Perspective on Biases in Cross-Sex Mind Reading. Jounral of Personality and Social Psychology, 81-91.&#xA0;<a href="#sexualOverPerceptionBiasBack">&#x21A9;</a></li>
<li><a name="postivePartnersBias"></a>Murray, S., Griffin, D., &amp; Holmes, J. (1996). The Self-Fulfilling Nature of Positive Illusions in Romantic Relationships: Love Is Not Blind, but Prescient. Journal of Personality and Social Psychology,, 1155-1180.&#xA0;<a href="#postivePartnersBiasBack">&#x21A9;</a></li>
<li><a name="disbelief"></a>Gilbert, D.T., &#xA0;Tafarodi, R.W. and Malone, P.S. (1993) You can't not believe everything you read. Journal of Personality and Social Psychology, 65, 221-233&#xA0;<a href="#disbeliefBack">&#x21A9;</a></li>
</ul>
<div><span lang="EN-AU">&#xA0;</span></div>
<p><strong>Notes on decisions I have made while creating this post</strong></p>
<p>&#xA0;(these notes will not be in the final draft):&#xA0;</p>
<ul>
<li>This post doesn't have any specific details on debiasing or the biases. I plan to provide these details in later posts. The main point of this post is convey the idea in the title.</li>
</ul></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mkz/rationality_compendium_principle_2_you_are/#comments">Comments (6)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mkz' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mok" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mok/sensation_perception/">
Sensation &amp; Perception
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mok'
title="100% positive"
>
1
</span>

</span>
<span class="author">
<a id="author_t3_mok" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">26 August 2015 01:13PM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mok" class="content clear">
<div class="md">
<div itemprop="description">
<div><p><span lang="EN-AU" style='font-size: 8.0pt; font-family: "Arial","sans-serif"; color: #bfbfbf; mso-themecolor: background1; mso-themeshade: 191; font-weight: normal; mso-bidi-font-weight: bold;'>(The below notes are pretty much my attempt to summarise the content in this <a href="http://www.pearsonhighered.com/assets/hip/us/hip_us_pearsonhighered/samplechapter/0205183468.pdf"><span style="text-decoration: underline;">sample chapter</span></a><a href="http://www.pearsonhighered.com/assets/hip/us/hip_us_pearsonhighered/samplechapter/0205183468.pdf">&#xA0;</a>from this&#xA0;<a href="http://www.amazon.com/Psychology-Core-Concepts-7th-Edition/dp/0205183468"><span style="text-decoration: underline;">book</span></a>. I am posting this in discussion because I don&#x2019;t think I will get the time/be bothered enough to improve upon this, so I am posting it now and hope someone finds it interesting or useful. If you do find it interesting check out the full <a href="http://www.pearsonhighered.com/assets/hip/us/hip_us_pearsonhighered/samplechapter/0205183468.pdf"><span style="text-decoration: underline;">chapter</span></a>, which goes into more detail)</span><span lang="EN-AU"> </span></p>
<p>We don&#x2019;t experience the world directly, but instead we experience it through a series of &#x201C;filters&#x201D; that we call our senses. We know that this is true because of cases of sensory loss. An example is Jonathan I., a 65-year-old New Yorker painter who following an automobile accident suffered from <a href="http://en.wikipedia.org/wiki/Cerebral_achromatopsia">cerebral achromatopsia</a> as well as the loss of the ability to remember and to imagine colours. He would look at a tomato and instead of seeing colours like red or green would instead see only black and shades of grey. The problem was not that Johnathan's eyes no longer worked it was that his brain was unable to process the neural messages for colour.</p>
<p>To understand why Johnathan cannot see colour, we first have to realise that incoming light travels only as far &#xA0;as the back of the eyes. There the information it contains is converted into neural messages in a process called <a href="http://en.wikipedia.org/wiki/Transduction_(physiology)">transduction</a>. We call these neural messages: "sensations". These sensations only involve neural representations of stimuli, not the actual stimuli themselves. Sensations such as &#x201C;red&#x201D; or &#x201C;sweet&#x201D; or &#x201C;cold&#x201D; can be said to have been made by the brain. They also only occur when the neural signal reaches the cerebral cortex. They do not occur when you first interact with the stimuli. To us, the process seems so immediate and direct that we are often fooled into thinking that the sensation of "red" is a characteristic of tomato or that the sensation of &#x201C;cold&#x201D; is a characteristic of ice cream. But they are not. What we sense is an electrochemical rendition of the world created by our brain and sensory receptors.</p>
<p>There is another separation between reality as it is and how we sense it to be as well. Organisms can only sense some types of stimulus between certain ranges. This is called the <a href="http://en.wikipedia.org/wiki/Absolute_threshold">absolute threshold</a> for different types of stimulation and it is the minimum amount of physical energy needed to produce a sensory experience. It should be noted that a faint stimulus does not abruptly become detectable as its intensity increases. There is instead a fuzzy boundary between detection and non-detection, which means that a person&#x2019;s absolute threshold is in fact not absolute at all. Instead, it varies continually with our mental alertness and physical condition.</p>
<p>To understand the reasons why the thresholds vary, we can turn to the <a href="http://en.wikipedia.org/wiki/Detection_theory">signal detection theory</a>. According to the signal detection theory, sensation depends on the characteristics of the stimulus, the background stimulation and the detector (the brain). Signal detection theory says that the background stimulation makes it less likely, for example, for you to hear someone calling your name on a busy downtown street than in a quiet park. The signal detection theory also tells us that your ability to hear them would depend on the condition of your brain, i.e. detector, and, perhaps, whether it has been aroused by a strong cup of coffee or dulled by drugs or lack of sleep.</p>
<p>The thresholds also change as similar stimuli are continued. This is called <a href="http://en.wikipedia.org/wiki/Neural_adaptation">sensory adaption</a> and it refers to the diminishing responsiveness of sensory systems to prolonged stimulation. An example of this would be when you adapt to the feeling of swimming in cold water. Unchanging stimulation generally shifts to the back of people's awareness, whereas, intense or changing stimulation will immediately draw your attention.</p>
<p>So far, we have talked about how the sensory organs filter incoming stimuli and how they can only pick up certain types of stimuli. But, there is also something more. We don&#x2019;t just sense the world; we perceive it as well. The brain in a process called perception combines sensations with memories, motives and emotions to create a representation of the world that fits our current concerns and interests. In essence, we impose our own meanings on sensory experience. People obviously have different memories, motives and current emotional states and this means that we attach different meanings to our sensations i.e. we have perceptual differences. Two people can look at the same political party or religion and come to starkly different conclusions about them.&#xA0;</p>
<p>The below picture provides a summary of the whole process discussed so far (stimulation to perception):</p>
<p style="padding-left: 120px;"></p>
<p>From simulation to perception, there are a great number of chances for errors to creep in and for you to either misperceive or even not perceive some types stimuli&#xA0;at all. These errors are often exacerbated by mistakes made by the brain. The brain, while brilliant and complex, is not perfect. Some of the mistakes it can make include perceptual phenomena such as: illusions, constancies, change blindness, and inattentional blindness. Illusions, for example, are when your mind deceives you by interpreting a stimulus pattern incorrectly. There are also instances of ambiguity in which some people see a particular colour and others another. This occurs even with people who are not colour blind. It occurs because the brain strives for&#xA0;<a href="http://en.wikipedia.org/wiki/Color_constancy" target="_blank">colour constancy</a>&#xA0;which is seeing the same object as having the same colour under varying illumination conditions. But, this process of colour constancy is not <a href="http://www.abc.net.au/science/articles/2015/03/17/4197384.htm">perfect</a>. It is troubling that despite all we know about sensation and perception many people still uncritically accept the evidence of their senses and perceptions at face value.</p>
<p>Another important aspect of perception is that the different types of sensory stimuli, e.g. hearing and vision, need to be integrated. This process of sensory integration can be another source of perceptual phenomenon. An example of this is the <a href="http://www.nature.com/nature/journal/v264/n5588/abs/264746a0.html">McGurk effect</a>&#xA0;in which &#xA0;the auditory component of one sound is paired with the visual component of another sound. This leads to an illusion, i.e. the perception of a third sound which is not actually spoken. You have to really see (or hear) this in action to understand it, so take a look at this <a href="https://www.youtube.com/watch?v=G-lN8vWm3m0&amp;feature=youtu.be">short video</a> which demonstrates the effect.</p>
<p>That was a quick summary on perception. But, an important question still needs to be asked. Is sensory perception and how its input gets organised in our minds the sole basis of our internal representations of the world or is there something else that might placate any creeping errors from perception? This question was asked by many philosophers. Kant in particular, had a distinction between a priori concepts (things that we know before any experience) and a posteriori concepts (things that we know only from experience). He pointed out that there are some things that we can&#x2019;t know from experience and instead need to be born with them. The work of Konrad Lorenz, though, pointed out that Kant&#x2019;s a priori were really evolutionary a posteriori concepts. That is we didn&#x2019;t learn them, but our ancestors did. We might believe X despite not having seen it with our own eyes, but this is only because our ancestors who believed X survived. If we couldn&#x2019;t navigate the world because our internal representations of the world were too distant from how the world actually is, then we would have been less likely to survive and reproduce. What this means is that we can have a priori concepts i.e. innate knowledge. But, that this innate knowledge is itself based on sensory perceptions of the world, just not yours. The types of a priori knowledge can be differentiated into the naturalistic a priori and the inference-from-premises a priori.</p></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mok/sensation_perception/#comments">Comments (15)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mok' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mky" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mky/rationality_compendium_principle_1_a_rational/">
Rationality Compendium: Principle 1 - A rational agent, given its capabilities and the situation it is in, is one that thinks and acts optimally
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mky'
title="100% positive"
>
7
</span>

</span>
<span class="author">
<a id="author_t3_mky" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">23 August 2015 08:01AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mky" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>A perfect rationalist is an ideal thinker. Rationality&#xA0;<a href="#rationality">&#x2193;</a><a name="rationalityBack"></a>, however, is not the same as perfection. Perfection guarantees optimal outcomes. Rationality only guarantees that the agent will, to the utmost of their abilities, reason optimally. Optimal reasoning cannot, unfortunately, guarantee optimal outcomes. This is because most agents are not omniscient or omnipotent. They are instead fundamentally and inexorably limited. To be fair to such agents, the definition of rationality that we use should take this into account. Therefore, a rational agent will be defined as: an agent that, given its capabilities and the situation it is in, thinks and acts optimally. Although it is noted that rationality does not guarantee the best outcome, a rational agent will most of the time&#xA0;achieve better outcomes than those of an irrational agent.&#xA0;</p>
<p>Rationality is often considered to be split into three parts: normative, descriptive and prescriptive rationality.</p>
<p>Normative rationality describes the laws of thought and action. That is, how a perfectly rational agent with unlimited computing power, omniscience etc. would reason and act. Normative rationality basically describes what is meant by&#xA0;the phrase "optimal reasoning". Of course, for limited agents true optimal reasoning is impossible and they must instead settle for bounded optimal reasoning, which is the closest approximation to optimal reasoning that is possible given the information available to the agent and the computational abilities of the agent. The laws of thought and action (what we currently believe optimal reasoning involves) are::</p>
<ul>
<li>Logic&#xA0;<a href="#logic">&#x2193;</a>&#xA0;<a name="logicBack"></a>- math and logic are deductive systems, where the conclusion of a successful argument follows necessarily from its premises, given the axioms of the system you&#x2019;re using: number theory, geometry, predicate logic, etc.</li>
<li>Probability theory&#xA0;<a href="#probability">&#x2193;</a>&#xA0;<a name="probabilityBack"></a>- is essentially an extension of logic. Probability&#xA0;is a measure of how likely a proposition is to be true, given everything else that you already believe. Perhaps, the most useful rule to be derived from the axioms of probability theory is Bayes&#x2019; Theorem&#xA0;<a href="#bayes">&#x2193;</a><a name="bayesBack"></a>, which tells you exactly how your probability for a statement should change as you encounter new information. Probability is viewed from one of two perspectives: the Bayesian perspective which sees probability as a measure of uncertainty about the world and the Frequentist perspective which sees probability as the proportion of times the event would occur in a long run of repeated experiments. Less wrong follows&#xA0;the Bayesian perspective.&#xA0;</li>
<li>Decision theory&#xA0;<a href="#dt">&#x2193;</a>&#xA0;<a name="dtBack"></a>- is about choosing actions based on the utility function of the possible outcomes. The utility function is a measure of how much you desire a particular outcome. The expected utility of an action is simply the average utility of the action&#x2019;s possible outcomes weighted by the probability that each outcome occurs. Decision theory can be divided into three parts: <ul>
<li>Normative decision theory&#xA0;studies what an ideal agent (a perfect agent, with infinite computing power, etc.) would choose.</li>
<li>Descriptive decision theory studies how non-ideal agents (e.g. humans) actually choose.</li>
<li>Prescriptive decision theory studies how non-ideal agents can improve their decision-making (relative to the normative model) despite their imperfections.</li>
</ul>
</li>
</ul>
<p>Descriptive rationality describes how people normally reason and act. It is about understanding how and why people make decisions. As humans, we have certain limitations and adaptations which&#xA0;quite&#xA0;often makes it impossible for us to be perfectly rational in&#xA0;the normative sense of the word. It is because of this that we must satisfice or approximate the normative rationality model as best we can. We engage in what's called bounded, ecological or grounded rationality <a href="#boundedRationality">&#x2193;</a>&#xA0;<a name="boundedRationalityBack"></a>.&#xA0;Unless explicitly stated otherwise, 'rationality' in this&#xA0;compendium&#xA0;will refer to rationality in the&#xA0;bounded&#xA0;sense of the word.&#xA0;In this sense, it&#xA0;means that&#xA0;the most rational choice&#xA0;for an agent&#xA0;depends on the&#xA0;agents capabilities and the information that is available to it.&#xA0;The most rational choice for an agent is not necessarily the most certain, true or right one. It is just the best one given the information and capabilities that the agent has. This means that an agent that satisfices or uses heuristics&#xA0;may actually be reasoning optimally, given its limitations, even though satisficing and heuristics&#xA0;are&#xA0;shortcuts that are potentially error prone. &#xA0;</p>
<p>Prescriptive or applied rationality&#xA0;is essentially about how to bring the thinking of limited agents closer to what the normative model stipulates. It is described by Baron in Thinking and Deciding <a href="#thinkingAndDeciding">&#x2193;</a><a name="thinkingAndDecidingBack"></a>&#xA0;&#xA0;pg.34:&#xA0;</p>
<blockquote>
<p>In short, normative models tell us how to evaluate judgments and decisions in terms of their departure from an ideal standard. Descriptive models specify what people in a particular culture actually do and how they deviate from the normative models. Prescriptive models are designs or inventions, whose purpose is to bring the results of actual thinking into closer conformity to the normative model. If prescriptive recommendations derived in this way are successful, the study of thinking can help people to become better thinkers.</p>
</blockquote>
<p>The behaviours and thoughts that we consider to be rational for limited agents is much larger than those&#xA0;for the perfect, i.e. unlimited,&#xA0;agents. This is because for the limited agents we need to take into account, not only&#xA0;those&#xA0;thoughts and behaviours&#xA0;which are&#xA0;optimal for the agent, but also those&#xA0;thoughts and behaviours which allow the limited agent to improve their reasoning. It is for this reason that we consider curiousity, for example, to be rational as it often leads to situations in which the&#xA0;agents&#xA0;improve their internal representations or models of the world. We also consider wise resource allocation to be rational because limited agents only have a limited amount of resources available to them. Therefore, if they can get a greater return on investment on the resources that they do use then they will be more likely&#xA0;to be able to get closer to thinking optimally&#xA0;in a greater number of domains.</p>
<p>We also consider the rationality of particuar choices&#xA0;to be&#xA0;something that is in a state of flux. This is because the rationality of choices depends on&#xA0;the information that an agent&#xA0;has access to and this is something&#xA0;which&#xA0;is&#xA0;frequently changing. This hopefully highlights an important fact.&#xA0;If an agent is suboptimal in its ability to gather information, then it will often end up with different information than an agent with optimal informational gathering abilities would. In short, this is a problem for the suboptimal (irrational) agent as it means that its rational choices are going to differ more&#xA0;from the perfect normative agents than the rational agents would. The closer an agents rational choices are to the rational choices of a perfect normative agent the more that the agent is rational.</p>
<p>It can also be said that the&#xA0;rationality of an agent depends in large part on the agents truth seeking abilities. The more accurate and up to date the agents view of the world the closer its rational choices will be to those of the perfect normative agents. It is because of this&#xA0;that a rational agent is one that is inextricably tied to the world as it is. It does not see the world as it wishes it, fears it or has seen it to be, but instead constantly adapts to and seeks out feedback from interactions with the world. The rational agent is&#xA0;attuned to the current state of affairs. One other very important characteristic of rational agents is that they adapt.&#xA0;If the situation has changed and the previously rational choice is no longer the one with the greatest expected utility, then the rational agent will adapt and change its preferred choice to the one that is now the most rational.</p>
<p>The other important part of rationality, besides truth seeking, is that&#xA0;it is about maximising the ability to actually achieve important goals.&#xA0;These two parts or domains of rationality: truth seeking and goal reaching are referred to as&#xA0;epistemic&#xA0;and instrumental&#xA0;rationality.&#xA0;<a href="#rationalityDomains">&#x2193;</a>&#xA0;<a name="rationalityDomainsBack"></a></p>
<ul>
<li>Epistemic rationality is about the ability to form true beliefs. It is governed by the laws of logic and probability theory.</li>
<li>Instrumental rationality is about the ability to actually achieve the things that matter to you. It is governed by the laws of decision theory. In a formal context, it is known as maximizing &#x201C;expected utility&#x201D;. It important to note that it is about more than just reaching goals. It is also about discovering how to develop optimal goals.</li>
</ul>
<p>As you move further and further away from rationality you introduce more and more flaws, inefficiencies and problems into your decision making and information gathering algorithms. These flaws and inefficiencies are the cause of irrational or suboptimal behaviors, choices&#xA0;and decisions. Humans are innately irrational in a large number of areas which is why, in large part, improving our rationality is just about mitigating, as much as possible, the influence of our biases and irrational propensities.</p>
<p>If you wish to truly understand what it means to be rational, then you must also understand what rationality is not. This&#xA0;is important because the concept of rationality is often&#xA0;misconstrued&#xA0;by the media. An epitomy of this&#xA0;misconstrual is the character of Spock from Star Trek. This character does not see rationality as if it was about optimality, but instead as if it means that&#xA0;<a href="#strawVulcan">&#x2193;</a><a name="strawVulcanBack"></a>:&#xA0;</p>
<ul>
<li><span style="text-decoration: underline;">You can expect everyone to react in a reasonable, or what Spock would call rational, way.</span> This is irrational because it leads to faulty models and predictions of other peoples behaviors and thoughts.</li>
<li><span style="text-decoration: underline;">You should never make a decision until you have all the information.</span> This is irrational because humans are not omniscient or omnipotent. Their decisions are constrained by many factors like the amount of information they have, the cognitive limitations of their brains and the time available for them to make decisions. This means that a person if they are to act rationally must often make predictions and assumptions.</li>
<li><span style="text-decoration: underline;">You should never rely on intuition.</span> This is irrational because intuition (system 1 thinking)&#xA0;<a href="#kahnemanReview">&#x2193;</a><a name="kahnemanReviewBack"></a>&#xA0;does have many advantages over conscious and effortful deliberation (system 2 thinking) mainly its speed. Although intuitions can be wrong, to disregard them entirely is to hinder yourself immensely. If your intuitions are based on multiple interactions that are similar to the current situation and these interactions had&#xA0;short feedback cycles, then it is often irrational to not rely on your intuitions.</li>
<li><span style="text-decoration: underline;">You should not become emotional.</span> This is irrational because while it is true that emotions can cause you to use less rational ways of thinking and acting, i.e. ways that are optimised for ancestral or previous environments, it does not mean that we should try to eradicate emotions in ourselves. This is because emotions are essential&#xA0;to rational thinking and normal social behavior&#xA0;<a href="#emotion">&#x2193;</a><a name="emotionBack"></a>. An aspiring rationalist should remember&#xA0;four points in regards to emotions: <ul>
<li>The rationality of emotions depends on the rationality of the thoughts and actions that they induce. It is rational to feel fear when you are actually in a situation where you are threatened. It is irrational to feel fear in situations where are not being threatened. If your fear compels you to take suboptimal actions, then and only then is that fear irrational.</li>
<li>Emotions are the wellspring of value. A large part of instrumental rationality is about finding the best way to achieve your fundamental human needs. A person who can fulfill these needs through simple methods is more rational than someone who can't. In this particular area people tend to become alot less rational as they age. As adults we should be jealous of the innocent exuberance that comes so naturally to children. If we are not as exuberant as children, then we should wonder at how it is that we have become so shackled by our own self restraint.&#xA0;</li>
<li>Emotional control is a virtue, but denial is not.&#xA0;Emotions can be considered a type of internal feedback. A rational person does not be&#xA0;consciously&#xA0;ignore or avoid feedback as this means that would be limiting or distorting the information that they have access to. It is possible that a rational agent may may need to mask or hide their emotions for reasons related to societal norms and status, but they should not repress emotions unless there is some overriding rational reason to do so. If a person volitionally represses their emotions because they wish to perpetually avoid them, then this is both irrational and cowardly.</li>
<li>By ignoring, avoiding and repressing emotions you are limiting the&#xA0;information that you exhibit, which means that other people will not know how you are actually feeling. In some situations this may be helpful, but it is important to remember that people are not mind readers. Their ability to model your mind and your emotional state depends on the information that&#xA0;they know about you and the information, e.g. body language, vocal inflections, that&#xA0;you exhibit. If people do not know that you are vulnerable, then they cannot know that you are courageous. If people do not know that you are in pain, then they cannot know that you need help. &#xA0;&#xA0;</li>
</ul>
</li>
<li><span style="text-decoration: underline;">You should only value quantifiable things like money, productivity, or efficiency.</span> This is irrational because it means that you are reducing the amount of potentially valuable information that you consider. The only reason&#xA0;a rational person ever reduces the amount of information that they consider is&#xA0;because of resource&#xA0;or time limitations.</li>
</ul>
<hr>
<p align="center"><strong>Related Materials</strong></p>
<p><strong>Wikis:</strong></p>
<ul>
<li><a name="rationality"></a><a href="http://wiki.lesswrong.com/wiki/Rationality">Rationality</a>&#xA0;-&#xA0;the characteristic of thinking and acting optimally. An agent is rational if it wields its intelligence in such a way as to maximize the convergence between its beliefs and reality; and acts on these beliefs in such a manner as to maximize its chances of achieving whatever goals it has. For humans, this means mitigating (as much as possible) the influence of&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bias">cognitive biases</a>.&#xA0;<a href="#rationalityBack">&#x21A9;</a></li>
<li><a name="logic"></a><a href="http://wiki.lesswrong.com/wiki/Maths/Logic">Maths/Logic</a>&#xA0;-&#xA0;Math and logic are deductive systems, where the conclusion of a successful argument follows necessarily from its premises, given the axioms of the system you&#x2019;re using: number theory, geometry, predicate logic, etc.&#xA0;<a href="#logicBack">&#x21A9;</a>&#xA0;&#xA0;</li>
<li><a name="probability"></a><a href="http://wiki.lesswrong.com/wiki/Probability_theory">Probability theory</a>&#xA0;-&#xA0;a field of mathematics which studies random variables and processes.&#xA0;<a href="#probabilityBack">&#x21A9;</a></li>
<li><a name="bayes"></a><a href="http://wiki.lesswrong.com/wiki/Bayes'_theorem">Bayes theorem</a> - a law of probability that describes the proper way to incorporate new&#xA0;<a href="http://wiki.lesswrong.com/wiki/Evidence">evidence</a>&#xA0;into&#xA0;<a href="http://wiki.lesswrong.com/wiki/Prior_probabilities">prior probabilities</a>&#xA0;to form an&#xA0;<a href="http://wiki.lesswrong.com/wiki/Belief_update">updated</a>&#xA0;probability estimate.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian">Bayesian</a>&#xA0;- Bayesian&#xA0;<a href="http://wiki.lesswrong.com/wiki/Probability_theory" title="Probability theory">probability theory</a>&#xA0;is the math of&#xA0;<a href="http://wiki.lesswrong.com/wiki/Epistemic_rationality" title="Epistemic rationality">epistemic rationality</a>, Bayesian&#xA0;<a href="http://wiki.lesswrong.com/wiki/Decision_theory" title="Decision theory">decision theory</a>&#xA0;is the math of&#xA0;<a href="http://wiki.lesswrong.com/wiki/Instrumental_rationality" class="mw-redirect" title="Instrumental rationality">instrumental rationality</a>.</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian_probability">Bayesian probability</a> - represents a level of certainty relating to a potential outcome or idea. This is in contrast to a <a href="http://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> probability that represents the frequency with which a particular outcome will occur over any number of trials. An <a href="http://en.wikipedia.org/wiki/Event_(probability_theory)">event</a> with Bayesian probability of .6 (or 60%) should be interpreted as stating "With confidence 60%, this event contains the true outcome", whereas a frequentist interpretation would view it as stating "Over 100 trials, we should observe event X approximately 60 times." The difference is more apparent when discussing ideas. A frequentist will not assign probability to an idea; either it is true or false and it cannot be true 6 times out of 10.&#xA0;</li>
<li><a href="http://wiki.lesswrong.com/wiki/Bayesian_decision_theory">Bayesian Decision theory</a> -&#xA0;Bayesian decision theory&#xA0;refers to a&#xA0;<a href="http://wiki.lesswrong.com/wiki/Decision_theory">decision theory</a>&#xA0;which is informed by&#xA0;<a href="http://wiki.lesswrong.com/wiki/Bayesian_probability">Bayesian probability</a>&#xA0;<a href="#bayesBack">&#x21A9;</a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Decision_theory"></a><a name="dt"></a><a href="http://wiki.lesswrong.com/wiki/Decision_theory">Decision theory</a>&#xA0;&#x2013; is the study of principles and algorithms for making correct decisions&#x2014;that is, decisions that allow an agent to achieve better outcomes with respect to its goals.&#xA0;<a href="#dtBack">&#x21A9;</a></li>
<li><a href="http://wiki.lesswrong.com/wiki/Hollywood_rationality" title="Hollywood rationality">Hollywood rationality</a>- What Spock does, not what actual rationalists do.</li>
</ul>
<p align="justify"><strong>Posts:</strong></p>
<ul>
<li><a name="rationalityDomains"></a><a href="/lw/31/what_do_we_mean_by_rationality/">What do we mean by rationality?</a> - Introduces rationality and the rationality domains (epistemic and instrumental).&#xA0;<a href="#rationalityDomainsBack">&#x21A9;</a> </li>
<li><a href="/lw/nc/newcombs_problem_and_regret_of_rationality/">Newcomb's Problem and Regret of Rationality</a>&#xA0;- introduces the idea that you should never end up envying someone else's mere choices.</li>
<li><a href="/lw/iat/what_bayesianism_taught_me/">What Bayesianism taught me</a>&#xA0;- discusses some specific things that the bayesian thinking has taught or caused the author to learn.&#xA0;</li>
<li><a name="kahnemanReview"></a><a href="/lw/7e5/the_cognitive_science_of_rationality/">Cognitive science of rationality</a>&#xA0;- discusses rationality, (Type1/Type 2) processes of cognition, thinking errors and the three kinds of minds (reflective, algorithmic, autonomous).&#xA0;<a href="#kahnemanReviewBack">&#x21A9;</a></li>
</ul>
<p><strong>Suggested posts to write:</strong></p>
<ul>
<li><a style="background-color: #ffffff;" name="boundedRationality"></a>Bounded/ecological/grounded Rationality - I couldn't find a suitable resource&#xA0;for this on less wrong.&#xA0;<a href="#boundedRationalityBack">&#x21A9;</a>&#xA0;</li>
</ul>
<p><strong>Academic Books:</strong></p>
<ul>
<li><a name="thinkingAndDeciding"></a>Baron,&#xA0;<a href="http://www.amazon.com/Thinking-Deciding-Jonathan-Baron/dp/0521680433/">Thinking and Deciding</a>&#xA0;<a href="#thinkingAndDecidingBack">&#x21A9;</a></li>
<li>Hastie and Dawes,&#xA0;<a href="http://www.amazon.com/Rational-Choice-Uncertain-World-Psychology/dp/1412959039/">Rational Choice in an Uncertain World</a></li>
<li>Bazerman and Moore,&#xA0;<a href="http://www.amazon.com/Judgment-Managerial-Decision-Making-Bazerman/dp/0470049456/">Judgment in Managerial Decision Making</a></li>
<li>Plous,&#xA0;<a href="http://www.amazon.com/Psychology-Judgment-Decision-Making-McGraw-Hill/dp/0070504776/">The Psychology of Judgment and Decision Making</a></li>
<li>Gilboa,&#xA0;<a href="http://www.amazon.com/Making-Better-Decisions-Decision-Practice/dp/1444336525/">Making Better Decisions</a></li>
<li>Stanovich, <a href="http://www.amazon.com/Rationality-Reflective-Mind-Keith-Stanovich/dp/0195341147/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1438858677&amp;sr=1-1&amp;keywords=Rationality+and+the+Reflective+Mind">Rationality and the Reflective Mind</a></li>
<li>Holyoak and Morrison, <a href="http://www.amazon.com/Handbook-Thinking-Reasoning-Library-Psychology/dp/0199313792/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1438858724&amp;sr=1-1&amp;keywords=The+Oxford+Handbook+of+Thinking+and+Reasoning">The Oxford Handbook of Thinking and Reasoning</a></li>
</ul>
<p align="justify"><a href="http://www.amazon.com/Rationality-Reflective-Mind-Keith-Stanovich/dp/0195341147/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1438858677&amp;sr=1-1&amp;keywords=Rationality+and+the+Reflective+Mind"></a></p>
<p align="justify"><strong>Popular Books:</strong></p>
<ul>
<li>&#xA0;Ariely,&#xA0;<span style="text-decoration: underline;"><a href="http://www.amazon.com/Predictably-Irrational-Revised-Expanded-Decisions/dp/0061353248/">Predictably Irrational</a></span></li>
<li>&#xA0;Kahneman,&#xA0;<span style="text-decoration: underline;"><a href="http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/">Thinking, Fast and Slow</a></span></li>
<li>&#xA0;Thaler and Sunstein,&#xA0;<a href="http://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X/">Nudge: Improving Decisions About Health, Wealth, and Happiness</a></li>
<li>&#xA0;Tavris and Aronson,&#xA0;<span style="text-decoration: underline;"><a href="http://www.amazon.com/Mistakes-Were-Made-But-Not/dp/0156033909/">Mistakes Were Made (But Not by Me)</a></span></li>
<li>&#xA0;Stanovich,&#xA0;<a href="http://www.amazon.com/What-Intelligence-Tests-Miss-Psychology/dp/0300164629">What Intelligence Tests Miss</a></li>
<li>&#xA0;Silver,&#xA0;<a href="http://www.amazon.com/The-Signal-Noise-Predictions-Fail-but/dp/0143125087">The Signal and the Noise: Why So Many Predictions Fail &#x2013; But Some Don&#x2019;t</a></li>
<li>&#xA0;Heath,&#xA0;<a href="http://www.amazon.com/Decisive-Make-Better-Choices-Life/dp/0307956393/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1438858584&amp;sr=1-1&amp;keywords=Decisive%3A+How+to+Make+Better+Choices+in+Life+and+Work">Decisive: How to Make Better Choices in Life and Work</a></li>
<li>&#xA0;Rock,&#xA0;<a href="http://www.amazon.com/Your-Brain-Work-Strategies-Distraction/dp/0061771295">Your Brain at Work: Strategies for Overcoming Distraction, Regaining Focus, and Working Smarter All Day Long</a></li>
<li><a name="emotion"></a>Damasio,&#xA0;<a href="http://www.amazon.com/Descartes-Error-Emotion-Reason-Human/dp/014303622X">Descartes' Error: Emotion, Reason, and the Human Brain</a>&#xA0;<a href="#emotionBack">&#x21A9;</a> </li>
</ul>
<div><strong>Talks:</strong></div>
<div>
<ul>
<li><a name="strawVulcan"></a>Galef,&#xA0;<a href="http://measureofdoubt.com/2011/11/26/the-straw-vulcan-hollywoods-illogical-approach-to-logical-decisionmaking/">The Straw Vulcan: Hollywood&#x2019;s illogical approach to logical decisionmaking</a>&#xA0;<a href="#strawVulcanBack">&#x21A9;</a></li>
</ul>
</div>
<p align="justify"><a href="http://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X/"></a></p>
<p align="justify"><a href="http://www.amazon.com/What-Intelligence-Tests-Miss-Psychology/dp/0300164629"></a></p>
<p align="justify"><a href="http://www.amazon.com/The-Signal-Noise-Predictions-Fail-but/dp/0143125087"></a></p>
<p align="justify"><a href="http://www.amazon.com/Decisive-Make-Better-Choices-Life/dp/0307956393/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1438858584&amp;sr=1-1&amp;keywords=Decisive%3A+How+to+Make+Better+Choices+in+Life+and+Work"></a></p>
<p><strong>Notes on decisions I have made while creating this post</strong></p>
<p>&#xA0;(these notes will not be in the final draft):&#xA0;</p>
<ul>
<li>I&#xA0;agree denotationally, but object connotatively&#xA0; with 'rationality is systemized winning', so I left it out. I feel that it would take too long to get rid of the connotation of competition that I believe is associated with 'winning'. The other point that would need to be delved into is: what exactly does the rationalist win at? I believe by winning Elizer meant winning at <a href="http://wiki.lesswrong.com/wiki/Newcomb%27s_problem">newcomb's problem</a>, but the idea of winning is normally extended into everything.&#xA0; I also believe that I have basically covered the idea with: &#x201C;Rationality maximizes expected performance, while perfection maximizes actual performance.&#x201D; </li>
<li>I left out the 12 virtues of rationality because I don&#x2019;t like perfectionism. If it was not in the virtues, then I would have included them. My problem with perfectionism is that having it as a goal makes you liable to premature optimization and developing tendencies for suboptimal levels of adaptability. Everything I have read in complexity theory, for example, makes me think that perfectionism is not really a good thing to be aiming for, at least in uncertain and complex situations. I think truth seeking should be viewed as an optimization process. If it doesn't allow you to become more optimal, then it is not worth it. I have a post about this <a href="/r/discussion/lw/mkh/truth_seeking_as_an_optimization_process/">here</a>.</li>
<li>I couldn't find an appropriate link for bounded/ecological/grounded rationality.&#xA0;</li>
</ul></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mky/rationality_compendium_principle_1_a_rational/#comments">Comments (28)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mky' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mm1" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mm1/rationality_compendium/">
Rationality Compendium
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mm1'
title="100% positive"
>
10
</span>

</span>
<span class="author">
<a id="author_t3_mm1" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">23 August 2015 08:00AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mm1" class="content clear">
<div class="md">
<div itemprop="description">
<div>
<div>
<p>I want to create a rationality compendium (<span style="color: #222222; font-family: arial, sans-serif-light, sans-serif; line-height: 15.6000003814697px;">a collection of concise but detailed information about a particular subject)</span>&#xA0;and I want to know whether you think this would be a good idea. The rationality&#xA0;compendium&#xA0;would essentially be a series of posts that will eventually serve as a guide for less wrong newbies that they can use to discover which resources to look into further, a refresher of the main concepts for less wrong veterans and a guideline or best practices document that will explain techniques that can be used to apply the core less wrong/rationality concepts. These techniques should preferably have been verified to be useful in some way. Perhaps, there will be some training specific posts in which we can track if people are actually finding the techniques to be useful.</p>
<p>I only want to write this because I am <a href="http://threevirtues.com/">lazy</a>. In this context, I mean lazy as it is described by Larry Wall:</p>
<blockquote>
<p>Laziness: The quality that makes you go to great effort to reduce overall energy expenditure.</p>
</blockquote>
<p>I think that a rationality&#xA0;compendium&#xA0;would not only prove that I have correctly understood the available rationality material, but it would also&#xA0;ensure that I am actually making use of this knowledge. That is, applying the rationality materials that I have learnt in ways that allow me to improve my life.</p>
<p>If you think that a rationality&#xA0;compendium&#xA0;is not needed or would not be overly helpful, then please let me know. I also want to point out that I do not think that I am necessarily the best person to do this and that I am only doing it because I don&#x2019;t see it being done by others.</p>
<p>For the rationality&#xA0;compendium, I plan to write a series of posts which should, as much as possible, be:</p>
<ul>
<li>Using standard terms: less wrong specific terms might be linked to&#xA0;in the related materials section, but&#xA0;common or standard terminology will be used wherever possible.</li>
<li>Concise: the posts should just contain quick overviews of the established rationality concepts. They shouldn&#x2019;t be introducing &#x201C;new&#x201D; ideas. The one exception to this is if a new idea allows multiple rationality concepts to be combined and explained together. If existing ideas require refinement, then this should happen in a seperate post which the rationality&#xA0;compendium&#xA0;may provide a link to if the post is deemed to be high quality.</li>
<li>Comprehensive: links to all related posts, wikis or other resources should be provided in a related materials section. This is so that readers can deep dive or just go deeper on materials that pique their interest while still ensuring that the posts are concise. The aim of the rationality&#xA0;compendium&#xA0;is&#xA0;to create&#xA0;a resource that is a condensed and distilled&#xA0;version of&#xA0;the available rationality materials. This means that it is not meant to be light reading as a large number of concepts will be presented in one post.</li>
<li>Collaborative: the posts should go through many series of edits based on the feedback in the comments. I don't think that I will be able to create perfect first posts, but I am willing to expend some effort to iteratively improve the posts until they reach a suitable standard. I hope that enough people will be interested in a rationality&#xA0;compendium&#xA0;so that I can gain enough&#xA0;feedback to improve the posts.&#xA0;I plan for the posts to stay in discussion for a long time and will possibly rerun posts if it is required. I welcome all kinds of feedback, positive or negative, but request that you provide information that I can use to improve the posts.</li>
<li>Be related only to rationality: For example, concepts from&#xA0;AI or quantum mechanics won&#x2019;t be mentioned unless they are required to explain some rationality concepts.</li>
<li>Ordered: the points in the&#xA0;compendium&#xA0;will be grouped according to overarching principles.&#xA0;</li>
</ul>
<div>I will provide a link to the posts created in the&#xA0;compendium&#xA0;here:</div>
<div><ol>
<li> <a href="/r/discussion/lw/mky/rationality_primer_principle_1_a_rational_agent/">A rational agent, given its capabilities, is one that thinks and acts optimally</a> </li>
</ol></div>
</div></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mm1/rationality_compendium/#comments">Comments (5)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mm1' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mkh" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mkh/truth_seeking_as_an_optimization_process/">
Truth seeking as an optimization process
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mkh'
title="100% positive"
>
7
</span>

</span>
<span class="author">
<a id="author_t3_mkh" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">18 August 2015 11:03AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mkh" class="content clear">
<div class="md">
<div itemprop="description">
<div><p>From the <a href="http://wiki.lesswrong.com/wiki/Costs_of_rationality">costs of rationality wiki</a>:</p>
<blockquote>
<p>Becoming more <a href="http://wiki.lesswrong.com/wiki/Rationality#Epistemic_rationality" title="Rationality">epistemically rational</a> can only guarantee one thing: what you believe will include more of the <a href="http://wiki.lesswrong.com/wiki/Truth" title="Truth">truth</a> . Knowing that truth might <a href="http://wiki.lesswrong.com/wiki/Instrumental_rationality" title="Instrumental rationality">help you achieve your goals</a> , or cause you to become a pariah. Be sure that you really want to know the truth before you commit to finding it; otherwise, you may flinch from it.</p>
</blockquote>
<p>The reason that truth seeking is often seen as being integral to rationality is that in order to make optimal decisions you must first be able to make accurate predictions. Delusions, or false beliefs, are self-imposed barriers to accurate prediction. They are surprise inducers. It is because of this that the rational path is often to break delusions, but you should remember that doing so is a slow and hard process that is rife with potential problems.</p>
<p>Below I have listed three scenarios in which a person could benefit from considering the costs of truth seeking. The first scenario is when seeking a more accurate measurement is computationally expensive and not really required. The second scenario is when you know that the truth will be emotionally distressing to another person and that this person is not in an optimal state to handle this truth. The third scenario is when you are trying to change the beliefs of others. It is often beneficial if you can understand the costs involved for them to change their beliefs as well as their perspective. This allows you to become better able to actually change their beliefs rather than to just win an argument.</p>
<p>&#xA0;</p>
<p><strong>Scenario 1: computationally expensive truth</strong></p>
<blockquote>
<p>We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%. &#x2013; Donald Knuth</p>
</blockquote>
<p>If optimization requires significant effort and only results in minimal gains in utility, then it is not worth it. If you only need to be 90% sure that something is true and you are currently 98% sure that it is, then it is not worth spending some extra effort to get to 99% certainty. For example, if you are testing ballistics on Earth then it may be appropriate to use Newtons laws even though they are known to be inexact in some extreme conditions. Now, this does not mean that optimization should never be done. Sometimes that extra 1% certainty is actually extremely important. What it does mean is that you should be spending your resources wisely. The beliefs that you do make should lead to increased abilities to <a href="/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/">anticipate accurately</a>. You should also remember <a href="/lw/k2/a_priori/" target="_blank">occams Razor</a>. If you are committing yourself to a decision procedure that is accurate, but slow and wasteful then you will probably be outcompeted by others who spend their resources on more suitable and worthy activities.</p>
<p>&#xA0;</p>
<p><strong>Scenario 2: emotionally distressing truth</strong></p>
<p>Assume for a moment that you have a child and that you have just finished watching that child fail horribly at a school performance. If your child then asks you, while crying, how the performance was. Do you tell them the truth in full or not? Most people would choose not to and would instead attempt to calm and comfort the child. To do otherwise is not seen as rational, but is instead seen as situationally unaware, rude and impolite. Obviously, some ways of telling the truth are worse than others. But, overall telling the full truth is probably not going to be the most prudent thing to do in this situation. This is because the child is not in an emotional state that will allow them to handle the truth well. The truth in this situation is unlikely to lead to improvement and will instead lead to further stress and trauma which will often cause future performance anxiety, premature optimization and other issues. For these reasons, I think that the truth should not be expressed in this situation. This does not mean that I think the rational person should forget about what has happened. They should instead remember it so that they can bring it up when the child is in an emotional state that would allow them to be better able to implement any advice that is given. For example, when practicing in a safe environment.</p>
<p>I want to point out that avoiding the truth is not what I am advocating. I am instead saying that we should be strategic about telling potentially face-threatening or emotionally distressing truths. I do believe that repression and avoidance of issues that have a persistent nature most often tends to lead to exacerbation or resignation of those issues. Hiding from the truth rarely improves the situation. Consider the child if you don't ever mention the performance because you don't want to cause the child pain then they are still probably going to get picked on at school. Knowing this, we can say that the best thing to do is to bring up the truth and frame it in a particular situation where the child can find it useful and come to be able to better handle it.</p>
<p>&#xA0;</p>
<p><strong>Scenario 3: psychologically exhausting truth</strong></p>
<p>If we remember that truth seeking involves costs, then we are more likely to be aware of how we can reduce this cost when we are trying to change the beliefs of others. If you are trying to convince someone and they do not agree with you, this may not be because your arguments are weak or that the other person is stupid. It may just be that there is a significant cost involved for them to either understand your argument or to update their beliefs. If you want to convince someone and also avoid the <a href="http://wiki.lesswrong.com/wiki/Illusion_of_transparency">illusion of transparency</a>, then it is best to take into account the following:</p>
<ul>
<li>You should try to end arguments well and to avoid vitriol - the emotional contagion heuristic leads people to avoid contact with people or objects viewed as "contaminated" by previous contact with someone or something viewed as bad&#x2014;or, less often, to seek contact with objects that have been in contact with people or things considered good. If someone gets emotional when you are in an argument, then you are going to be less likely to change their minds about that topic in the future. It is also a good idea to consider the&#xA0;<a href="http://wiki.lesswrong.com/wiki/Peak-end_rule">peak-end rule</a>&#xA0;which basically means that you should try to end your arguments well.</li>
<li>If you find that someone is already closed off due to emotional contagion, then you should try a surprising strategy so that your arguments aren't stereotyped and avoided. As elizer said <a href="/lw/3k/how_to_not_lose_an_argument/2ih">here</a>:&#xA0;</li>
<li style="list-style: none">
<blockquote>
<p>The first rule of persuading a negatively disposed audience - rationally or otherwise - is not to say the things they expect you to say. The expected just gets filtered out, or treated as confirmation of pre-existing beliefs regardless of its content.</p>
</blockquote>
</li>
<li><a href="https://en.wikipedia.org/wiki/Processing_fluency">Processing fluency</a> - is the ease with which information is processed. You should ask yourself if your argument worded in such a way that it is fluent and easy to understand?</li>
<li><a href="https://en.wikipedia.org/wiki/Cognitive_dissonance">Cognitive dissonance</a> - is a measure of how much your argument conflicts with the other persons pre-existing beliefs? Perhaps, you need to convince them of a few other points first before your argument will work.&#xA0;<span lang="EN-AU" style="text-indent: -0.25in;">People will try to avoid cognitive dissonance. Therefore, it is better to start off with shared arguments and in general to minimise disagreements. It is often the sounder strategy to modify and extend pre-existing beliefs.</span></li>
<li><a href="http://wiki.lesswrong.com/wiki/Inferential_distance">Inferential distance</a> - is about how much background information that they need access to in order for them to understand your argument?</li>
<li><a href="/lw/o4/leave_a_line_of_retreat/">Leave a line of retreat</a> - think about whether they can admit that they were wrong without also looking stupid or foolish? In winning arguments there are generally two ways that you can go about it. The first is to totally demolish the other persons position. The second is to actually change their minds. The first leaves them feeling wrong, stupid and foolish which is often going to make them start rationalizing. The second just makes them feel wrong. You win arguments the second way by seeming to be reasonable and non face threatening. A good way to do this is through empathy and understanding the argument from the other persons position. It is important to see things as others would see them because <a href="http://quoteinvestigator.com/2014/03/09/as-we-are/">we don't see the world as it is; we see the world as we are</a>. The other person is not stupid or lying they might just in the middle of what I call an 'epistemic contamination cascade' (perhaps there is already a better name for this). It is when false beliefs lead to filters, framing effects and other false beliefs. Another potential benefit from viewing the argument from the other persons perspective is that it is possible that you may come to realise that your own is not as steadfast as you once believed.</li>
<li>Maximise the cost of holding a false belief - ask yourself if there are any costs to them if they continue to hold a belief that you believe is false? One way to cause some cost is to convince their friends and associates of your position. The extra social pressure may help in getting them to change their minds.</li>
<li>Give it time and get them inspecting their maps rather than information that has been filtered through their map. It is possible that there are filtering and framing effects which mean that your arguments are being distorted by the other person? Consider a depressed person: you can argue with them, but this is not likely to be overly helpful. THis is because it is likely that while arguing you will need to contradict them and this will probably lead to them blocking out what you are saying. I think that in these kinds of situations what you really need to do is to get them to inspect their own maps. This can be done by asking "what" or "how does that make you" type of questions. For example,&#x201C;What are you feeling?&#x201D;,&#x201C;What&#x2019;s going on?&#x201D; and&#x201C;What can I do to help?&#x201D;. There are two main benefits to these types of questions over arguments. The first is that it gets them inspecting their maps and the second is that it is much harder for them to block out the responses since they are the ones providing them. This is a related quote from Sarah Silverman's&#xA0;<a href="http://www.amazon.com/The-Bedwetter-Stories-Courage-Redemption/dp/B004AYDAXG">book</a>:</li>
<li style="list-style: none">
<blockquote>
<p>My stepfather, John O'Hara, was the goodest man there was. He was not a man of many words, but of carefully chosen ones. He was the one parent who didn't try to fix me. One night I sat on his lap in his chair by the woodstove, sobbing. He just held me quietly and then asked only, 'What does it feel like?' It was the first time I was prompted to articulate it. I thought about it, then said, "I feel homesick." That still feels like the most accurate description--I felt homesick, but I was home. - Sarah Silverman</p>
</blockquote>
</li>
<li>Remember the <a href="http://wiki.lesswrong.com/wiki/Other-optimizing">other-optimizing bias</a> and that perspectival types of issues need to be resolved by the individual facing them. If you have a goal to change another persons minds, then it often pays dividends to not only understand why they are wrong, but also why they think they are right or at least unaware that they are wrong. This kind of understanding can only come from empathy. Sometimes it is impossible to truly understand what another person is going through, but you should always try, without condoning or condemning, to see things as they are from the other persons perspective. Remember that hatred blinds and so does love. You should always be curious and seek to understand things as they are, not as you wish them, fear them or desire them to be. It is only when you can do this that you can truly understand the costs involved for someone else to change their minds.</li>
</ul>
<p>&#xA0;</p>
<p>If you take the point of view that changing beliefs is costly. Then you are less likely to be surprised when others don't want to change their beliefs. You are also more likely to think about how you can make the process of changing their beliefs easier for them.</p>
<p>&#xA0;</p>
<p>Some other examples of when seeking the truth is not necessarily valuable are:</p>
<ul>
<li>Fiction writing and the cinematic experience</li>
<li>When the pragmatic meaning does not need truth, but the semantic meaning does. An example is "Hi. How are you?" and other similar greetings which are peculiar because they look the same as questions or adjacency pairs, but function slightly differently. They are like a kind of ritualised question in which the answer is normally pre-specified or at least the detail of the answer is. If someone asks: "How are you" it is seen as <a href="/lw/85a/truth_social_graces/">aberrant</a> to answer the question in full detail with the truth rather than simply with fine, which may be a lie. If they actually do want to know how you are, then they will probably ask a follow up question after the greeting like "so, is everything good with the kids".</li>
<li>Evolutionary biases which cause delusions, but may help in perspectival and self confidence issues. For example, the <a href="http://www.sscnet.ucla.edu/comm/haselton/webdocs/sexualoverperception.pdf">sexual over perception bias</a> from men. From a truth-maximization perspective young men who assume that all women want them are showing severe social-cognitive inaccuracies, judgment biases, and probably narcissistic personality disorder. However, from an evolutionary perspective, the same young men are behaving more optimally. That is, the bias is an adaptive bias one which has consistently maximized the reproductive success of their male ancestors. Other examples are the <a href="http://www.sscnet.ucla.edu/comm/haselton/webdocs/haseltonbussjpsp.pdf">women's underestimation of men's commitment bias</a> and <a href="http://faculty.washington.edu/jdb/345/345%20Articles/Chapter%2011%20Murray%20et%20al.%20(1996).pdf">positively biased perceptions of partners</a></li>
</ul>
<p>&#xA0;</p>
<p>tldr: this post posits that truth seeking should be viewed as an optimization process. This means that it may not always be worth it.</p></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mkh/truth_seeking_as_an_optimization_process/#comments">Comments (0)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mkh' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
<div id="thingrow_t3_mmt" class="post list" itemscope itemtype="http://schema.org/BlogPosting">
<h2 itemprop="name"><a href="/lw/mmt/mental_model_theory_illusion_of_possibility/">
Mental Model Theory - Illusion of Possibility Example
</a>
</h2>
<div class="meta clear">
<span class="votes">
<span class="votes " id='score_t3_mmt'
title="100% positive"
>
1
</span>

</span>
<span class="author">
<a id="author_t3_mmt" href="http://lesswrong.com/user/ScottL/">ScottL</a>
</span>
<span class="date">18 August 2015 06:29AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h1>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h1></i>
<br/>
<br/>
</div>
-->
<div id="entry_t3_mmt" class="content clear">
<div class="md">
<div itemprop="description">
<div><div>
<p>(I have written an overview of the mental model theory which is in main and the link is&#xA0;<a href="/lw/mlf/an_overview_of_the_mental_model_theory/">here</a>. You should read this overview before you read this post. You should only read this post&#xA0;if you want&#xA0;more explicit details on the first example which demonstrates the illusion of possibility)</p>
<p>Consider the following problem:</p>
<blockquote>
<p>Before you stands a card-dealing robot. This robot has been programmed to deal one hand of cards. You are going to make a bet with another person on whether the dealt hand will contain an ace or whether it will contain a king. If the dealt hand is just&#xA0;a single queen, it's a draw. Based on what you know about this robot, you deduce correctly that only one of the following statements is true.</p>
<ul>
<li>The dealt hand will contain either a king or an ace (or both).</li>
<li>The dealt hand will contain either a queen or an ace (or both).</li>
</ul>
<p>Based on your deductions, should you bet that the dealt hand will contain an Ace or that it will contain a King?</p>
</blockquote>
<p>If you think that the ace is the better bet, then you would have made a losing bet. In short, this is because&#xA0; it is impossible for an ace to be in the dealt hand.&#xA0;</p>
<p>To see why this is I will list out all of the explicit mental models.</p>
<p>Below are the mental models that people will create in accordance with the principle of truth. (See the article in main for what this is). You can see that Ace is in both rows, which makes it seem like ace must obviously be more likely to be in the dealt hand.</p>
<table cellpadding="1" style="margin: 0px auto;border:none;border-collapse:collapse;" border="0" align="center">
<tbody>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 1 true</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">K</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">K &#x2229; A</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 2 true</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Q</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Q &#x2229; A</p>
</td>
</tr>
</tbody>
</table>
<p>&#xA0;</p>
<p>But, when we look at the full explicit set of potential models (including the models when one of the statements is false) we will realise that it is impossible for an ace to be in the hand. Note that &#xAC; stands for negation. (&#xAC;A) means that the hand does not have an ace. The first possible scenario is when statement one is true and statement two is false. The mental models for this are in the below table:</p>
<table cellpadding="1" style="margin: 0px auto;border:none;border-collapse:collapse;" border="0" align="center">
<tbody>
<tr>
<td style="border:solid windowtext 1.0pt;" rowspan="2">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 1 true</p>
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 2 false</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">K</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">K &#x2229; A</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;Q</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;Q &#x2229; &#xAC;A</p>
</td>
</tr>
</tbody>
</table>
<p>&#xA0;</p>
<p>Consider each column after the first as a potential possibility for how the dealt hand could be.</p>
<ul>
<li>The first column means that the dealt hand will have a king and not have a queen. This looks good. There are no problems with this.</li>
<li>The second column means that the dealt hand will have an ace and not have an ace. We have reached a contradiction, which implies that this possibility is impossible.</li>
<li>The third column is also impossible as the first row has (A) and the second has (&#xAC;A).</li>
</ul>
<p>If we look at the second possible scenario which is when statement&#xA0;two is true and statement&#xA0;one is false, then we get the below table.</p>
<table cellpadding="1" style="margin: 0px auto;border:none;border-collapse:collapse;" border="0" align="center">
<tbody>
<tr>
<td style="border:solid windowtext 1.0pt;" rowspan="2">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 2 true</p>
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 1 false</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Q</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Q &#x2229; A</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;K</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;A</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;K &#x2229; &#xAC;A</p>
</td>
</tr>
</tbody>
</table>
<p>&#xA0;</p>
<p>Once again if we can consider each column after the first as a potential possibility for how the dealt hand could be.</p>
<ul>
<li>The first column means that the dealt hand will have a queen and not have a king. This looks good. There are no problems with this.</li>
<li>The second column like in the first table is a contradiction and so is impossible.</li>
<li>The third column is also a contradiction and so is impossible.</li>
</ul>
<p>If we remove the ace possibilities as this leads to contradictions, we end up with the below table:</p>
<table cellpadding="1" style="margin: 0px auto;border:none;border-collapse:collapse;" border="0" align="center">
<tbody>
<tr>
<td style="border:solid windowtext 1.0pt;" rowspan="2">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 1 true</p>
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 2 false</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">K</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;Q</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;" rowspan="2">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 2 true</p>
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Statement 1 false</p>
</td>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">Q</p>
</td>
</tr>
<tr>
<td style="border:solid windowtext 1.0pt;">
<p style="text-align: center;font-size:10.0pt;margin-bottom: 0.0001pt;">&#xAC;K</p>
</td>
</tr>
</tbody>
</table>
<p>&#xA0;</p>
<p>This table has two possibilities. The dealt hand contains a king or the dealt hand contains a queen. Knowing this, we can know say that it is more likely for there to be a king in the dealt hand as it impossible for an ace to be in the hand. Therefore, we should bet that there is a king in the hand.</p>
</div></div>
</div>
</div>
</div><!-- .content -->
<div class="tools clear">
<a class="comment" href="/lw/mmt/mental_model_theory_illusion_of_possibility/#comments">Comments (2)</a>
<div class="boxright clear">
<ul class="clear">
<li>
<a href="http://creativecommons.org/licenses/by/3.0/" class="license" title="Post licensed under Creative Commons Attribution 3.0 License">CC Licenced</a>
</li>
</ul>
</div>
<span id='status_t3_mmt' class="error" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
</div>
<p class="nextprev"> View more:&#32;
<a href="http://lesswrong.com/user/ScottL/submitted/?count=22&amp;after=t3_mmt" rel="nofollow,next" >Next</a>
</p>
</div>
<div id="sidebar">
<ul class="clear"
id='rightnav'>
<li >
<a href="http://wiki.lesswrong.com" >wiki</a>
&#32;
</li>
<li >
<a href="http://lesswrong.com/sequences/" >Sequences</a>
&#32;
</li>
<li >
<a href="http://lesswrong.com/about/" >About</a>
&#32;
</li>
</ul>
<div class='spacer'>
<div id="side-search" class="sidebox">
<form action="/search/results" id="cse-search-box" onsubmit="return true;">
<div>
<input type="hidden" name="cx" value="015839050583929870010:-802ptn4igi" />
<input type="hidden" name="cof" value="FORID:11" />
<input type="hidden" name="ie" value="UTF-8" />
<label class="fullwidth" for="search-query">Search this user's posts &amp; comments:</label>
<input type="text" class="text" name="q" id="search-query" size="31" />
<input type="submit" class="submit" name="sa" value="Search" />
</div>
</form>
<form style="display:none">
<input type="hidden" id="cse-search-transformed" value="0" />
</form>

</div><!-- #side-search -->
</div>
<div class='spacer'>
<div id="side-user" class="sidebox">
<div id="side-status" class="clear">
<h2><a href="/user/ScottL">ScottL</a></h2>
<div class="userinfo editor">
<span class="label">Karma Score</span>
<span class="score" title="764 Total Karma&lt;br /&gt;98% positive">
764
</span>
<span class="monthly-score"title="5 Karma for the last 30 days&lt;br /&gt;100% positive">
5
</span>
</div>
<dl class="extrainfo">
</dl>
</div>
</div><!-- #side-user -->
</div>
<div class='spacer'>
<div id="side-login" class="sidebox">
<form method="post" action="http://lesswrong.com/post/login" onsubmit="return chklogin(this);" class="login-form-side">
<div class="row">
<label for="username">
<a href="http://lesswrong.com" onclick="return showcover(false);" >Register</a>
/ Login</label>
<input type="hidden" name="op" value="login-main" />
<input name="user_login" id="username" type="text" maxlength="20" tabindex="1"/>
</div>
<div class="row">
<label for="password">Password</label>
<input id="password" name="passwd_login" type="password" maxlength="20" tabindex="2"/>
</div>
<div class="row">
<div id="remember-me">
<label for="rem-login-main">Remember me</label>
<input type="checkbox" name="rem" tabindex="3"
id="rem-login-main" />
</div>
</div>
<div>
<div id="WRONG_PASSWORD_login-main" class="error">
</div>
<div id="status_login-main" class="error"></div>
</div>
<div class="row">
<a href="/password" id="recover">Recover password</a>
<button class="btn" type="submit" tabindex="4">Login</button>
</div>
</form>
</div>
</div>
<div class='spacer'>
<div id="side-feed" class="sidebox">
<a href="http://lesswrong.com/user/ScottL/submitted/.rss"
Subscribe to RSS Feed
</a>
</div>
</div>
<div class='spacer'>
<div id="side-meetups" class="sidebox">
<h2>
<a href="http://lesswrong.com/meetups" >Nearest Meetups</a>
</h2>
</div>
</div>
<div class='spacer'>
<div id="side-comments" class="sidebox">
<h2>
<a href="http://lesswrong.com/comments" >Recent Comments</a>
</h2>
</div>
</div>
<div class='spacer'>
<div id="side-quote" class="sidebox">
<h2>
<a href="http://lesswrong.com/tag/quotes" >Recent Rationality Quotes</a>
</h2>
</div>
</div>
<div class='spacer'>
<div id="side-posts" class="sidebox">
<h2>
<a href="http://lesswrong.com/recentposts" >Recent Posts</a>
</h2>
</div>
</div>
<div class='spacer'>
<div id="recent-wiki-edits" class="sidebox">
<h2><a href="http://wiki.lesswrong.com/wiki/Special:RecentChanges">Recent Wiki Edits</a></h2>
<ul id="https://wiki.lesswrong.com/mediawiki/index.php?title=Special:RecentChanges&amp;feed=rss&amp;hideminor=1&amp;namespace=0"></ul>

</div>
</div>
<div class='spacer'>
<div class="sidebox">
<h2 id="http://www.overcomingbias.com/feed_title"></h2>
<ul id="http://www.overcomingbias.com/feed"></ul>

</div>
</div>
<div class='spacer'>
<div id="side-monthly-contributors" class="sidebox">
<h2>
Top Contributors, 30 Days
</h2>
</div>
</div>
<div class='spacer'>
<div id="karma-awards" class="sidebox">
<h2>
<a href="http://lesswrong.com/karma" >Recent Karma Awards</a>
</h2>
</div>
</div>
</div>
</div><!-- #main -->
<div class="footer clear">
<div class="reddit">
Powered by&nbsp;<strong>Reddit</strong>
<a href="http://code.reddit.com" title="Powered by Reddit"></a>
</div>
<ul class="footer-links">
<li>
<a href="http://lesswrong.com/about" >About Less Wrong</a>
</li>
<li><a href="https://github.com/tricycle/lesswrong/wiki/Issues,-Bugs,-and-Requested-Features">Report Issues</a></li>
<li class="privacy-policy"><a href="http://intelligence.org/files/PrivacyandTerms-Lesswrong.com.pdf" target="_blank">Privacy &amp; Terms <span>(NEW 23/04/15)</span></a></li>
</ul>
</div>
<div id="cover" style="display:none" class="cover"
onclick="hidecover('cover', 'loginpopup')">
</div>
<div id="loginpopup" style="display: none" class="popup">
<h1 id="cover_msg">You'll need to login or register to do that</h1>
<h2 id="cover_disclaim">(Don't worry, it only takes a few seconds)</h2>
<div class="loginform divide">
<h3>Create</h3>
<p class="tagline">
Pick a username and password for your Less Wrong and Less Wrong Wiki accounts. You will receive an email to verify your account.
</p>
<form id="login_reg" method="post"
action="http://lesswrong.com/post/reg"
onsubmit="return chklogin(this);"
target="_top">
<input type="hidden" name="reason" value="" />
<input type="hidden" name="op" value="reg" />
<div>
<ul>
<li>
<label for="user_reg">Username:</label>
<input value="" name="user_reg" id="user_reg"
type="text" maxlength="20"/>
<span id="BAD_USERNAME_reg" class="error">
</span>
<span id="BAD_USERNAME_CHARS_reg" class="error">
</span>
<span id="BAD_USERNAME_SHORT_reg" class="error">
</span>
<span id="BAD_USERNAME_LONG_reg" class="error">
</span>
<span id="USERNAME_TAKEN_reg" class="error">
</span>
</li>
<li>
<label for="email_reg">Email:</label>
<input value="" name="email_reg" id="email_reg"
type="text" maxlength="50"/>
<span id="NO_EMAIL_reg" class="error">
</span>
<span id="BAD_EMAIL_reg" class="error">
</span>
</li>
<li>
<label for="passwd_reg">Password:</label>
<input id="passwd_reg"
name="passwd_reg" type="password" maxlength="20"/>
<span id="BAD_PASSWORD_reg" class="error">
</span>
</li>
<li>
<label for="passwd2_reg">Verify password:</label>
<input name="passwd2_reg" id="passwd2_reg"
type="password" maxlength="20" />
<span id="BAD_PASSWORD_MATCH_reg" class="error">
</span>
</li>
<li>
<table>
<tr>
<td></td>
<td>
</td>
</tr>
<tr>
<td align="right">
</td>
<td>
<input id="capiden" name="iden" type="hidden" value=""/>
<input id="captcha" name="captcha" type="text" size="30" class="cap-text" onfocus="clearTitle(this)"/>

</td>
<td>
<span id="BAD_CAPTCHA" class="error">
</span>
</td>
</tr>
</table>
<span id="DRACONIAN_reg" class="error">
</span>
<span id="RATELIMIT_reg" class="error">
</span>
</li>
<li>
<input type="checkbox" name="rem" id="rem_reg" />
<label for="rem_reg" class="remember">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Create account
</button>
<span id='status_reg' class='error'></span>
</p>
</div>
</form>
</div>
<div class="loginform">
<h3>Login</h3>
<p class="tagline">
Already have an account and just want to login?
</p>
<form id="login_login" method="post"
action="http://lesswrong.com/post/login"
onsubmit="return chklogin(this);"
target="_top">
<input type="hidden" name="reason" value="" />
<input type="hidden" name="op" value="login" />
<div>
<ul>
<li>
<label for="user_login">Username:</label>
<input value="" name="user_login" id="user_login"
type="text" maxlength="20"/>
</li>
<li>
<label for="passwd_login">Password:</label>
<input id="passwd_login"
name="passwd_login" type="password" maxlength="20"/>
<span id="WRONG_PASSWORD_login" class="error">
</span>
</li>
<li>
<input type="checkbox" name="rem" id="rem_login" />
<label for="rem_login" class="remember">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Login
</button>
<span id='status_login' class='error'></span>
</p>
</div>
</form>
<p>
<a href="http://lesswrong.com/password" >Forgot your password?</a>
</p>
</div>
<div class="clear"></div>
<div style="text-align:center">
<a href="javascript:hidecover('cover','loginpopup')">
Close this window
</a>
</div>
</div>
<div id="langcover" style="display:none" class="cover"
onclick="hidecover('langcover', 'langpopup')">
</div>
<div id="langpopup" style="display: none" class="popup">
<div style="text-align:center">
<a href="javascript:hidecover('langcover','langpopup')">
Close this window
</a>
</div>
</div>
</div><!-- #wrapper -->
</body>
</html>